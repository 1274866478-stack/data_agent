"""
æ¨ç†å¼•æ“æœåŠ¡
å®ç°æŸ¥è¯¢ç†è§£ã€ç­”æ¡ˆç”Ÿæˆã€è´¨é‡æ§åˆ¶ç­‰åŠŸèƒ½
"""

import logging
import json
import re
import time
from typing import Dict, Any, Optional, List, Tuple, Union
from datetime import datetime
from dataclasses import dataclass, field
from enum import Enum
import asyncio

from src.app.services.zhipu_client import zhipu_service
from src.app.services.llm_service import llm_service, LLMMessage

logger = logging.getLogger(__name__)


class QueryType(Enum):
    """æŸ¥è¯¢ç±»å‹æšä¸¾"""
    FACTUAL = "factual"  # äº‹å®æŸ¥è¯¢
    ANALYTICAL = "analytical"  # åˆ†ææŸ¥è¯¢
    COMPARATIVE = "comparative"  # æ¯”è¾ƒæŸ¥è¯¢
    TEMPORAL = "temporal"  # æ—¶é—´ç›¸å…³æŸ¥è¯¢
    CAUSAL = "causal"  # å› æœå…³ç³»æŸ¥è¯¢
    PROCEDURAL = "procedural"  # æµç¨‹æŸ¥è¯¢
    PREDICTIVE = "predictive"  # é¢„æµ‹æŸ¥è¯¢
    UNKNOWN = "unknown"


class ReasoningMode(Enum):
    """æ¨ç†æ¨¡å¼æšä¸¾"""
    BASIC = "basic"  # åŸºç¡€æ¨ç†
    ANALYTICAL = "analytical"  # åˆ†ææ¨ç†
    STEP_BY_STEP = "step_by_step"  # é€æ­¥æ¨ç†
    MULTI_SOURCE = "multi_source"  # å¤šæºæ¨ç†
    CONTEXT_AWARE = "context_aware"  # ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¨ç†


@dataclass
class QueryAnalysis:
    """æŸ¥è¯¢åˆ†æç»“æœ"""
    original_query: str
    query_type: QueryType
    intent: str
    entities: List[str]
    keywords: List[str]
    temporal_expressions: List[str]
    complexity_score: float
    confidence: float
    reasoning_mode: ReasoningMode
    suggested_temperature: float
    suggested_max_tokens: int
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ReasoningStep:
    """æ¨ç†æ­¥éª¤"""
    step_number: int
    description: str
    reasoning: str
    evidence: List[str]
    confidence: float
    timestamp: datetime = field(default_factory=datetime.utcnow)


@dataclass
class ReasoningResult:
    """æ¨ç†ç»“æœ"""
    answer: str
    reasoning_steps: List[ReasoningStep]
    confidence: float
    sources: List[Dict[str, Any]]
    query_analysis: QueryAnalysis
    quality_score: float
    safety_filter_triggered: bool
    metadata: Dict[str, Any] = field(default_factory=dict)


class QueryUnderstandingEngine:
    """æŸ¥è¯¢ç†è§£å¼•æ“"""

    def __init__(self):
        self.intent_patterns = {
            QueryType.FACTUAL: [
                r"ä»€ä¹ˆæ˜¯", r"å®šä¹‰", r"è§£é‡Š", r"è°", r"å“ªé‡Œ", r"ä½•æ—¶", r"å¤šå°‘"
            ],
            QueryType.ANALYTICAL: [
                r"åˆ†æ", r"è¯„ä¼°", r"æ£€æŸ¥", r"ç ”ç©¶", r"æ¢è®¨"
            ],
            QueryType.COMPARATIVE: [
                r"æ¯”è¾ƒ", r"å¯¹æ¯”", r"å·®å¼‚", r"ä¼˜ç¼ºç‚¹", r"å“ªä¸ªæ›´å¥½", r"åŒºåˆ«"
            ],
            QueryType.TEMPORAL: [
                r"è¶‹åŠ¿", r"å˜åŒ–", r"å¢é•¿", r"ä¸‹é™", r"å†å²", r"é¢„æµ‹", r"æ—¶é—´"
            ],
            QueryType.CAUSAL: [
                r"ä¸ºä»€ä¹ˆ", r"åŸå› ", r"å¯¼è‡´", r"å½±å“", r"åæœ"
            ],
            QueryType.PROCEDURAL: [
                r"å¦‚ä½•", r"æ€ä¹ˆ", r"æ­¥éª¤", r"æµç¨‹", r"æ–¹æ³•", r"æ“ä½œ"
            ],
            QueryType.PREDICTIVE: [
                r"é¢„æµ‹", r"é¢„æœŸ", r"æœªæ¥", r"å¯èƒ½", r"å°†ä¼š"
            ]
        }

        self.complexity_indicators = [
            "åˆ†æ", "æ¯”è¾ƒ", "è¯„ä¼°", "å½±å“", "åŸå› ", "ç»“æœ",
            "è¶‹åŠ¿", "å…³ç³»", "æ¨¡å¼", "ç­–ç•¥", "æ–¹æ¡ˆ"
        ]

    async def analyze_query(
        self,
        query: str,
        context: Optional[List[Dict[str, Any]]] = None
    ) -> QueryAnalysis:
        """
        åˆ†ææŸ¥è¯¢

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯

        Returns:
            æŸ¥è¯¢åˆ†æç»“æœ
        """
        try:
            logger.info(f"å¼€å§‹åˆ†ææŸ¥è¯¢: {query[:100]}...")

            # åŸºç¡€æ–‡æœ¬åˆ†æ
            query_type = self._classify_query_type(query)
            intent = self._extract_intent(query)
            entities = self._extract_entities(query)
            keywords = self._extract_keywords(query)
            temporal_expressions = self._extract_temporal_expressions(query)

            # å¤æ‚åº¦è¯„ä¼°
            complexity_score = self._calculate_complexity(query, entities, keywords)
            confidence = self._calculate_confidence(query, query_type)

            # æ¨ç†æ¨¡å¼å»ºè®®
            reasoning_mode = self._suggest_reasoning_mode(query_type, complexity_score)
            suggested_temperature = self._suggest_temperature(complexity_score)
            suggested_max_tokens = self._suggest_max_tokens(complexity_score)

            analysis = QueryAnalysis(
                original_query=query,
                query_type=query_type,
                intent=intent,
                entities=entities,
                keywords=keywords,
                temporal_expressions=temporal_expressions,
                complexity_score=complexity_score,
                confidence=confidence,
                reasoning_mode=reasoning_mode,
                suggested_temperature=suggested_temperature,
                suggested_max_tokens=suggested_max_tokens
            )

            logger.info(f"æŸ¥è¯¢åˆ†æå®Œæˆ: ç±»å‹={query_type.value}, å¤æ‚åº¦={complexity_score:.2f}")
            return analysis

        except Exception as e:
            logger.error(f"æŸ¥è¯¢åˆ†æå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤åˆ†æç»“æœ
            return QueryAnalysis(
                original_query=query,
                query_type=QueryType.UNKNOWN,
                intent="æœªçŸ¥æ„å›¾",
                entities=[],
                keywords=[],
                temporal_expressions=[],
                complexity_score=0.5,
                confidence=0.5,
                reasoning_mode=ReasoningMode.BASIC,
                suggested_temperature=0.7,
                suggested_max_tokens=1000
            )

    def _classify_query_type(self, query: str) -> QueryType:
        """åˆ†ç±»æŸ¥è¯¢ç±»å‹"""
        query_lower = query.lower()

        # è®¡ç®—æ¯ç§ç±»å‹çš„åŒ¹é…åˆ†æ•°
        type_scores = {}
        for query_type, patterns in self.intent_patterns.items():
            score = sum(1 for pattern in patterns if re.search(pattern, query_lower))
            type_scores[query_type] = score

        # è¿”å›å¾—åˆ†æœ€é«˜çš„ç±»å‹
        if type_scores:
            best_type = max(type_scores, key=type_scores.get)
            if type_scores[best_type] > 0:
                return best_type

        return QueryType.UNKNOWN

    def _extract_intent(self, query: str) -> str:
        """æå–ç”¨æˆ·æ„å›¾"""
        # ç®€åŒ–çš„æ„å›¾æå–é€»è¾‘
        if "ä»€ä¹ˆæ˜¯" in query or "å®šä¹‰" in query:
            return "å¯»æ±‚å®šä¹‰æˆ–è§£é‡Š"
        elif "å¦‚ä½•" in query or "æ€ä¹ˆ" in query:
            return "å¯»æ±‚æ–¹æ³•æˆ–æµç¨‹"
        elif "ä¸ºä»€ä¹ˆ" in query or "åŸå› " in query:
            return "å¯»æ±‚åŸå› æˆ–è§£é‡Š"
        elif "æ¯”è¾ƒ" in query or "å¯¹æ¯”" in query:
            return "å¯»æ±‚æ¯”è¾ƒåˆ†æ"
        elif "åˆ†æ" in query or "è¯„ä¼°" in query:
            return "å¯»æ±‚åˆ†æè¯„ä¼°"
        else:
            return "ä¸€èˆ¬ä¿¡æ¯æŸ¥è¯¢"

    def _extract_entities(self, query: str) -> List[str]:
        """æå–å®ä½“"""
        # ç®€åŒ–çš„å®ä½“æå–ï¼Œå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨NERæ¨¡å‹
        # æå–æ•°å­—ã€æ—¥æœŸã€ä¸“æœ‰åè¯ç­‰
        entities = []

        # æå–æ•°å­—
        numbers = re.findall(r'\d+(?:\.\d+)?', query)
        entities.extend([f"æ•°å­—:{num}" for num in numbers])

        # æå–æ—¥æœŸæ—¶é—´
        dates = re.findall(r'\d{4}[-/]\d{1,2}[-/]\d{1,2}|\d{1,2}[-/]\d{1,2}[-/]\d{4}', query)
        entities.extend([f"æ—¥æœŸ:{date}" for date in dates])

        # æå–å¼•å·ä¸­çš„å†…å®¹ï¼ˆå¯èƒ½æ˜¯ä¸“æœ‰åè¯ï¼‰
        quoted = re.findall(r'["\"]([^"\"]+)["\"]', query)
        entities.extend(quoted)

        return entities

    def _extract_keywords(self, query: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–
        # ç§»é™¤åœç”¨è¯ï¼Œæå–æœ‰æ„ä¹‰çš„è¯æ±‡
        stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™'}

        # åˆ†è¯ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…åº”ä½¿ç”¨ä¸“ä¸šåˆ†è¯å™¨ï¼‰
        words = re.findall(r'[\w]+', query)
        keywords = [word for word in words if len(word) > 1 and word not in stop_words]

        return keywords[:10]  # é™åˆ¶å…³é”®è¯æ•°é‡

    def _extract_temporal_expressions(self, query: str) -> List[str]:
        """æå–æ—¶é—´è¡¨è¾¾å¼"""
        temporal_patterns = [
            r'\d{4}å¹´',
            r'\d{1,2}æœˆ',
            r'\d{1,2}æ—¥',
            r'æ˜¨å¤©|ä»Šå¤©|æ˜å¤©',
            r'ä¸Šå‘¨|æœ¬å‘¨|ä¸‹å‘¨',
            r'ä¸Šä¸ªæœˆ|è¿™ä¸ªæœˆ|ä¸‹ä¸ªæœˆ',
            r'å»å¹´|ä»Šå¹´|æ˜å¹´',
            r'æœ€è¿‘|è¿‘æœŸ|ç›®å‰',
            r'è¿‡å»|æœªæ¥',
            r'æ˜¥å¤©|å¤å¤©|ç§‹å¤©|å†¬å¤©'
        ]

        expressions = []
        for pattern in temporal_patterns:
            matches = re.findall(pattern, query)
            expressions.extend(matches)

        return expressions

    def _calculate_complexity(self, query: str, entities: List[str], keywords: List[str]) -> float:
        """è®¡ç®—æŸ¥è¯¢å¤æ‚åº¦"""
        complexity = 0.0

        # åŸºäºé•¿åº¦
        length_score = min(len(query) / 200, 1.0) * 0.2
        complexity += length_score

        # åŸºäºå®ä½“æ•°é‡
        entity_score = min(len(entities) / 5, 1.0) * 0.2
        complexity += entity_score

        # åŸºäºå¤æ‚åº¦æŒ‡ç¤ºè¯
        complex_word_count = sum(1 for word in self.complexity_indicators if word in query)
        complexity_score = min(complex_word_count / 3, 1.0) * 0.4
        complexity += complexity_score

        # åŸºäºå¥å­ç»“æ„ï¼ˆé—®å·æ•°é‡ã€é€—å·æ•°é‡ç­‰ï¼‰
        question_marks = query.count('?') + query.count('ï¼Ÿ')
        structure_score = min(question_marks / 2, 1.0) * 0.2
        complexity += structure_score

        return min(complexity, 1.0)

    def _calculate_confidence(self, query: str, query_type: QueryType) -> float:
        """è®¡ç®—åˆ†æç½®ä¿¡åº¦"""
        if query_type == QueryType.UNKNOWN:
            return 0.3

        # åŸºäºæŸ¥è¯¢æ¸…æ™°åº¦
        confidence = 0.7

        # å¦‚æœæŸ¥è¯¢åŒ…å«æ˜ç¡®çš„é—®é¢˜è¯ï¼Œå¢åŠ ç½®ä¿¡åº¦
        if any(word in query for word in ["ä»€ä¹ˆ", "å¦‚ä½•", "ä¸ºä»€ä¹ˆ", "æ€ä¹ˆ", "å“ªä¸ª"]):
            confidence += 0.2

        # å¦‚æœæŸ¥è¯¢é•¿åº¦é€‚ä¸­ï¼Œå¢åŠ ç½®ä¿¡åº¦
        if 10 <= len(query) <= 100:
            confidence += 0.1

        return min(confidence, 1.0)

    def _suggest_reasoning_mode(self, query_type: QueryType, complexity: float) -> ReasoningMode:
        """å»ºè®®æ¨ç†æ¨¡å¼"""
        if complexity > 0.7:
            return ReasoningMode.ANALYTICAL
        elif query_type in [QueryType.COMPARATIVE, QueryType.ANALYTICAL]:
            return ReasoningMode.STEP_BY_STEP
        elif complexity > 0.5:
            return ReasoningMode.CONTEXT_AWARE
        else:
            return ReasoningMode.BASIC

    def _suggest_temperature(self, complexity: float) -> float:
        """å»ºè®®æ¸©åº¦å‚æ•°"""
        if complexity > 0.7:
            return 0.8  # é«˜å¤æ‚åº¦éœ€è¦æ›´é«˜çš„åˆ›é€ æ€§
        elif complexity > 0.5:
            return 0.6
        else:
            return 0.3  # ä½å¤æ‚åº¦ä½¿ç”¨è¾ƒä½æ¸©åº¦ç¡®ä¿å‡†ç¡®æ€§

    def _suggest_max_tokens(self, complexity: float) -> int:
        """å»ºè®®æœ€å¤§Tokenæ•°"""
        if complexity > 0.7:
            return 2000
        elif complexity > 0.5:
            return 1500
        else:
            return 800


class AnswerGenerator:
    """ç­”æ¡ˆç”Ÿæˆå™¨"""

    def __init__(self):
        self.generation_templates = {
            QueryType.FACTUAL: "è¯·åŸºäºæä¾›çš„ä¿¡æ¯ï¼Œå‡†ç¡®å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{query}",
            QueryType.ANALYTICAL: "è¯·æ·±å…¥åˆ†æä»¥ä¸‹é—®é¢˜ï¼Œæä¾›è¯¦ç»†çš„è§è§£ï¼š{query}",
            QueryType.COMPARATIVE: "è¯·æ¯”è¾ƒåˆ†æä»¥ä¸‹å†…å®¹ï¼Œçªå‡ºå¼‚åŒç‚¹ï¼š{query}",
            QueryType.TEMPORAL: "è¯·åˆ†æä»¥ä¸‹æ—¶é—´ç›¸å…³é—®é¢˜ï¼š{query}",
            QueryType.CAUSAL: "è¯·åˆ†æä»¥ä¸‹å› æœå…³ç³»ï¼š{query}",
            QueryType.PROCEDURAL: "è¯·æä¾›è¯¦ç»†çš„æ­¥éª¤è¯´æ˜ï¼š{query}",
            QueryType.PREDICTIVE: "è¯·åŸºäºç°æœ‰ä¿¡æ¯è¿›è¡Œåˆç†é¢„æµ‹ï¼š{query}"
        }

    async def generate_answer(
        self,
        query_analysis: QueryAnalysis,
        context: Optional[List[Dict[str, Any]]] = None,
        data_sources: Optional[List[Dict[str, Any]]] = None,
        tenant_id: Optional[str] = None
    ) -> ReasoningResult:
        """
        ç”Ÿæˆç­”æ¡ˆ

        Args:
            query_analysis: æŸ¥è¯¢åˆ†æç»“æœ
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            data_sources: æ•°æ®æºä¿¡æ¯
            tenant_id: ç§Ÿæˆ·ID

        Returns:
            æ¨ç†ç»“æœ
        """
        try:
            logger.info(f"å¼€å§‹ç”Ÿæˆç­”æ¡ˆ: {query_analysis.original_query[:50]}...")

            # æ„å»ºæ¨ç†æ­¥éª¤
            reasoning_steps = await self._generate_reasoning_steps(query_analysis, context, data_sources)

            # ç”Ÿæˆä¸»ç­”æ¡ˆ
            answer = await self._generate_main_answer(query_analysis, reasoning_steps, context, tenant_id)

            # è®¡ç®—ç½®ä¿¡åº¦å’Œè´¨é‡åˆ†æ•°
            confidence = self._calculate_confidence(reasoning_steps, answer)
            quality_score = self._calculate_quality_score(answer, reasoning_steps)

            # å®‰å…¨è¿‡æ»¤
            safety_triggered = await self._safety_filter(answer)

            # å‡†å¤‡æºä¿¡æ¯
            sources = self._prepare_sources(data_sources)

            result = ReasoningResult(
                answer=answer,
                reasoning_steps=reasoning_steps,
                confidence=confidence,
                sources=sources,
                query_analysis=query_analysis,
                quality_score=quality_score,
                safety_filter_triggered=safety_triggered
            )

            logger.info(f"ç­”æ¡ˆç”Ÿæˆå®Œæˆï¼Œç½®ä¿¡åº¦: {confidence:.2f}, è´¨é‡åˆ†æ•°: {quality_score:.2f}")
            return result

        except Exception as e:
            logger.error(f"ç­”æ¡ˆç”Ÿæˆå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤ç»“æœ
            return ReasoningResult(
                answer="æŠ±æ­‰ï¼Œåœ¨ç”Ÿæˆç­”æ¡ˆæ—¶é‡åˆ°äº†é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                reasoning_steps=[],
                confidence=0.1,
                sources=[],
                query_analysis=query_analysis,
                quality_score=0.1,
                safety_filter_triggered=True
            )

    async def _generate_reasoning_steps(
        self,
        query_analysis: QueryAnalysis,
        context: Optional[List[Dict[str, Any]]],
        data_sources: Optional[List[Dict[str, Any]]]
    ) -> List[ReasoningStep]:
        """ç”Ÿæˆæ¨ç†æ­¥éª¤"""
        steps = []

        try:
            # æ­¥éª¤1ï¼šç†è§£æŸ¥è¯¢æ„å›¾
            step1 = ReasoningStep(
                step_number=1,
                description="ç†è§£æŸ¥è¯¢æ„å›¾å’Œç±»å‹",
                reasoning=f"è¯†åˆ«æŸ¥è¯¢ä¸º{query_analysis.query_type.value}ç±»å‹ï¼Œæ„å›¾ï¼š{query_analysis.intent}",
                evidence=[f"å…³é”®è¯ï¼š{', '.join(query_analysis.keywords)}"],
                confidence=query_analysis.confidence
            )
            steps.append(step1)

            # æ­¥éª¤2ï¼šåˆ†æå®ä½“å’Œå…³é”®ä¿¡æ¯
            if query_analysis.entities:
                step2 = ReasoningStep(
                    step_number=2,
                    description="æå–å…³é”®å®ä½“å’Œæ¦‚å¿µ",
                    reasoning=f"è¯†åˆ«å‡ºé‡è¦å®ä½“ï¼š{', '.join(query_analysis.entities)}",
                    evidence=query_analysis.entities,
                    confidence=0.8
                )
                steps.append(step2)

            # æ­¥éª¤3ï¼šåˆ†ææ—¶é—´ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if query_analysis.temporal_expressions:
                step3 = ReasoningStep(
                    step_number=3,
                    description="åˆ†ææ—¶é—´ç›¸å…³ä¿¡æ¯",
                    reasoning=f"è¯†åˆ«æ—¶é—´è¡¨è¾¾å¼ï¼š{', '.join(query_analysis.temporal_expressions)}",
                    evidence=query_analysis.temporal_expressions,
                    confidence=0.9
                )
                steps.append(step3)

            # æ­¥éª¤4ï¼šæ•´åˆä¸Šä¸‹æ–‡ä¿¡æ¯
            if context:
                step4 = ReasoningStep(
                    step_number=len(steps) + 1,
                    description="æ•´åˆä¸Šä¸‹æ–‡ä¿¡æ¯",
                    reasoning=f"åˆ©ç”¨{len(context)}æ¡ä¸Šä¸‹æ–‡ä¿¡æ¯è¾…åŠ©æ¨ç†",
                    evidence=[f"ä¸Šä¸‹æ–‡æ¶ˆæ¯{len(context)}æ¡"],
                    confidence=0.7
                )
                steps.append(step4)

        except Exception as e:
            logger.error(f"ç”Ÿæˆæ¨ç†æ­¥éª¤å¤±è´¥: {e}")
            # è‡³å°‘è¿”å›ä¸€ä¸ªåŸºç¡€æ­¥éª¤
            steps.append(ReasoningStep(
                step_number=1,
                description="åŸºç¡€åˆ†æ",
                reasoning="å¯¹æŸ¥è¯¢è¿›è¡ŒåŸºç¡€åˆ†æ",
                evidence=[],
                confidence=0.5
            ))

        return steps

    async def _generate_main_answer(
        self,
        query_analysis: QueryAnalysis,
        reasoning_steps: List[ReasoningStep],
        context: Optional[List[Dict[str, Any]]],
        tenant_id: Optional[str]
    ) -> str:
        """ç”Ÿæˆä¸»è¦ç­”æ¡ˆ"""
        try:
            # æ„å»ºæç¤ºè¯
            template = self.generation_templates.get(
                query_analysis.query_type,
                "è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{query}"
            )

            # æ·»åŠ æ¨ç†ä¸Šä¸‹æ–‡
            reasoning_context = ""
            if reasoning_steps:
                reasoning_context = "\n\næ¨ç†è¿‡ç¨‹ï¼š\n" + "\n".join([
                    f"{step.step_number}. {step.description}: {step.reasoning}"
                    for step in reasoning_steps
                ])

            # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
            context_info = ""
            if context:
                context_info = "\n\nç›¸å…³ä¸Šä¸‹æ–‡ï¼š\n" + "\n".join([
                    f"- {msg.get('content', '')[:200]}..."
                    for msg in context[-3:]  # åªä½¿ç”¨æœ€è¿‘3æ¡ä¸Šä¸‹æ–‡
                ])

            prompt = template.format(
                query=query_analysis.original_query
            ) + reasoning_context + context_info

            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·åŸºäºæä¾›çš„æ¨ç†è¿‡ç¨‹å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç”Ÿæˆå‡†ç¡®ã€æœ‰ç”¨çš„ç­”æ¡ˆã€‚"},
                {"role": "user", "content": prompt}
            ]

            # è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆ
            response = await llm_service.chat_completion(
                tenant_id=tenant_id or "default",
                messages=[LLMMessage(role=msg["role"], content=msg["content"]) for msg in messages],
                temperature=query_analysis.suggested_temperature,
                max_tokens=query_analysis.suggested_max_tokens
            )

            if response and hasattr(response, 'content'):
                # ğŸ”¥ğŸ”¥ DEBUG: æ‰“å°æ ‡å‡†æŸ¥è¯¢å¤„ç†çš„ LLM åŸå§‹è¾“å‡º
                import sys
                final_content = response.content
                print("=" * 80, flush=True)
                print("ğŸ”¥ğŸ”¥ FINAL LLM OUTPUT (Standard Query - Raw String):", flush=True)
                print("=" * 80, flush=True)
                print(final_content, flush=True)
                print("=" * 80, flush=True)
                sys.stdout.flush()
                logger.info(f"ğŸ”¥ğŸ”¥ FINAL LLM OUTPUT (Standard Query - length: {len(final_content)}): {final_content[:500]}...")
                return final_content
            else:
                # å›é€€åˆ°zhipuæœåŠ¡
                zhipu_response = await zhipu_service.chat_completion(
                    messages=messages,
                    temperature=query_analysis.suggested_temperature,
                    max_tokens=query_analysis.suggested_max_tokens
                )

                if zhipu_response:
                    return zhipu_response.get("content", "æ— æ³•ç”Ÿæˆç­”æ¡ˆ")
                else:
                    return "æŠ±æ­‰ï¼Œå½“å‰æ— æ³•ç”Ÿæˆç­”æ¡ˆï¼Œè¯·ç¨åé‡è¯•ã€‚"

        except Exception as e:
            logger.error(f"ç”Ÿæˆä¸»è¦ç­”æ¡ˆå¤±è´¥: {e}")
            return "æŠ±æ­‰ï¼Œç”Ÿæˆç­”æ¡ˆæ—¶é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ã€‚"

    def _calculate_confidence(self, reasoning_steps: List[ReasoningStep], answer: str) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦"""
        if not reasoning_steps:
            return 0.1

        # åŸºäºæ¨ç†æ­¥éª¤çš„å¹³å‡ç½®ä¿¡åº¦
        step_confidence = sum(step.confidence for step in reasoning_steps) / len(reasoning_steps)

        # åŸºäºç­”æ¡ˆé•¿åº¦å’Œå®Œæ•´æ€§
        length_score = min(len(answer) / 200, 1.0) * 0.3

        # ç»¼åˆè®¡ç®—
        confidence = step_confidence * 0.7 + length_score
        return min(confidence, 1.0)

    def _calculate_quality_score(self, answer: str, reasoning_steps: List[ReasoningStep]) -> float:
        """è®¡ç®—è´¨é‡åˆ†æ•°"""
        quality = 0.0

        # åŸºäºç­”æ¡ˆå®Œæ•´æ€§
        if len(answer) > 50:
            quality += 0.3

        # åŸºäºç»“æ„åŒ–ç¨‹åº¦
        if any(marker in answer for marker in ["é¦–å…ˆ", "å…¶æ¬¡", "æœ€å", "æ€»ä¹‹", "æ€»ç»“"]):
            quality += 0.2

        # åŸºäºæ¨ç†æ­¥éª¤æ•°é‡
        step_score = min(len(reasoning_steps) / 3, 1.0) * 0.3
        quality += step_score

        # åŸºäºä¸“ä¸šæ€§ï¼ˆæ˜¯å¦åŒ…å«ä¸“ä¸šæœ¯è¯­ï¼‰
        professional_terms = ["åˆ†æ", "è¯„ä¼°", "å»ºè®®", "æ–¹æ¡ˆ", "ç­–ç•¥", "ä¼˜åŒ–"]
        term_count = sum(1 for term in professional_terms if term in answer)
        term_score = min(term_count / 2, 1.0) * 0.2
        quality += term_score

        return min(quality, 1.0)

    async def _safety_filter(self, content: str) -> bool:
        """å®‰å…¨è¿‡æ»¤"""
        try:
            # ç®€å•çš„å®‰å…¨æ£€æŸ¥
            unsafe_patterns = [
                r'æš´åŠ›|è¡€è…¥|ææ€–',
                r'è‰²æƒ…|æˆäººå†…å®¹',
                r'ä»‡æ¨|æ­§è§†|ä¾®è¾±',
                r'è‡ªæ®‹|è‡ªæ€',
                r'è¿æ³•|çŠ¯ç½ª'
            ]

            for pattern in unsafe_patterns:
                if re.search(pattern, content, re.IGNORECASE):
                    logger.warning(f"å®‰å…¨è¿‡æ»¤è§¦å‘ï¼ŒåŒ¹é…æ¨¡å¼: {pattern}")
                    return True

            return False

        except Exception as e:
            logger.error(f"å®‰å…¨è¿‡æ»¤å¤±è´¥: {e}")
            return True  # å‡ºé”™æ—¶é»˜è®¤è¿‡æ»¤

    def _prepare_sources(self, data_sources: Optional[List[Dict[str, Any]]]) -> List[Dict[str, Any]]:
        """å‡†å¤‡æºä¿¡æ¯"""
        if not data_sources:
            return []

        sources = []
        for i, source in enumerate(data_sources[:5]):  # é™åˆ¶æœ€å¤š5ä¸ªæº
            sources.append({
                "id": source.get("id", f"source_{i}"),
                "name": source.get("name", f"æ•°æ®æº{i+1}"),
                "type": source.get("type", "unknown"),
                "relevance": source.get("relevance", 0.8)
            })

        return sources


class ReasoningEngine:
    """æ¨ç†å¼•æ“ä¸»ç±»"""

    def __init__(self):
        self.query_understanding = QueryUnderstandingEngine()
        self.answer_generator = AnswerGenerator()

    async def reason(
        self,
        query: str,
        context: Optional[List[Dict[str, Any]]] = None,
        data_sources: Optional[List[Dict[str, Any]]] = None,
        tenant_id: Optional[str] = None,
        reasoning_mode: Optional[ReasoningMode] = None
    ) -> ReasoningResult:
        """
        æ‰§è¡Œå®Œæ•´æ¨ç†è¿‡ç¨‹

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            data_sources: æ•°æ®æºä¿¡æ¯
            tenant_id: ç§Ÿæˆ·ID
            reasoning_mode: æ¨ç†æ¨¡å¼ï¼ˆå¯é€‰ï¼‰

        Returns:
            æ¨ç†ç»“æœ
        """
        try:
            start_time = time.time()
            logger.info(f"å¼€å§‹æ¨ç†è¿‡ç¨‹: {query[:100]}...")

            # æ­¥éª¤1ï¼šæŸ¥è¯¢åˆ†æ
            query_analysis = await self.query_understanding.analyze_query(query, context)

            # å¦‚æœæŒ‡å®šäº†æ¨ç†æ¨¡å¼ï¼Œè¦†ç›–åˆ†æç»“æœ
            if reasoning_mode:
                query_analysis.reasoning_mode = reasoning_mode

            # æ­¥éª¤2ï¼šç”Ÿæˆç­”æ¡ˆ
            result = await self.answer_generator.generate_answer(
                query_analysis, context, data_sources, tenant_id
            )

            # æ·»åŠ å¤„ç†æ—¶é—´
            processing_time = time.time() - start_time
            result.metadata["processing_time"] = processing_time
            result.metadata["reasoning_mode"] = query_analysis.reasoning_mode.value

            logger.info(f"æ¨ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            return result

        except Exception as e:
            logger.error(f"æ¨ç†è¿‡ç¨‹å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤æ¨ç†ç»“æœ
            default_analysis = QueryAnalysis(
                original_query=query,
                query_type=QueryType.UNKNOWN,
                intent="æœªçŸ¥æ„å›¾",
                entities=[],
                keywords=[],
                temporal_expressions=[],
                complexity_score=0.5,
                confidence=0.1,
                reasoning_mode=ReasoningMode.BASIC,
                suggested_temperature=0.7,
                suggested_max_tokens=1000
            )

            return ReasoningResult(
                answer="æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æŸ¥è¯¢æ—¶é‡åˆ°äº†é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                reasoning_steps=[],
                confidence=0.1,
                sources=[],
                query_analysis=default_analysis,
                quality_score=0.1,
                safety_filter_triggered=True,
                metadata={"error": str(e)}
            )


# å…¨å±€æ¨ç†å¼•æ“å®ä¾‹
reasoning_engine = ReasoningEngine()


class EnhancedReasoningEngine:
    """å¢å¼ºç‰ˆæ¨ç†å¼•æ“ï¼Œé›†æˆèåˆå’ŒXAIåŠŸèƒ½"""

    def __init__(self):
        self.base_engine = reasoning_engine

        # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
        self._fusion_engine = None
        self._xai_service = None

    @property
    def fusion_engine(self):
        """å»¶è¿ŸåŠ è½½èåˆå¼•æ“"""
        if self._fusion_engine is None:
            from src.app.services.fusion_service import fusion_engine
            self._fusion_engine = fusion_engine
        return self._fusion_engine

    @property
    def xai_service(self):
        """å»¶è¿ŸåŠ è½½XAIæœåŠ¡"""
        if self._xai_service is None:
            from src.app.services.xai_service import xai_service
            self._xai_service = xai_service
        return self._xai_service

    async def enhanced_reason(
        self,
        query: str,
        context: Optional[List[Dict[str, Any]]] = None,
        sql_results: Optional[List[Dict[str, Any]]] = None,
        rag_results: Optional[List[Dict[str, Any]]] = None,
        documents: Optional[List[Dict[str, Any]]] = None,
        tenant_id: Optional[str] = None,
        enable_fusion: bool = True,
        enable_xai: bool = True,
        reasoning_mode: Optional[ReasoningMode] = None
    ) -> Dict[str, Any]:
        """
        å¢å¼ºç‰ˆæ¨ç†ï¼Œæ”¯æŒæ•°æ®èåˆå’ŒXAIè§£é‡Š

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            sql_results: SQLæŸ¥è¯¢ç»“æœ
            rag_results: RAGæ£€ç´¢ç»“æœ
            documents: æ–‡æ¡£æ•°æ®
            tenant_id: ç§Ÿæˆ·ID
            enable_fusion: æ˜¯å¦å¯ç”¨æ•°æ®èåˆ
            enable_xai: æ˜¯å¦å¯ç”¨XAIè§£é‡Š
            reasoning_mode: æ¨ç†æ¨¡å¼

        Returns:
            Dict: åŒ…å«æ¨ç†ç»“æœã€èåˆç»“æœå’ŒXAIè§£é‡Šçš„ç»¼åˆç»“æœ
        """
        try:
            start_time = time.time()
            logger.info(f"å¼€å§‹å¢å¼ºæ¨ç†: {query[:100]}...")

            # æ­¥éª¤1ï¼šåŸºç¡€æ¨ç†åˆ†æ
            base_result = await self.base_engine.reason(
                query=query,
                context=context,
                data_sources=self._prepare_data_sources(sql_results, rag_results, documents),
                tenant_id=tenant_id,
                reasoning_mode=reasoning_mode
            )

            # åˆå§‹åŒ–ç»“æœ
            enhanced_result = {
                "query": query,
                "base_reasoning": base_result,
                "fusion_result": None,
                "xai_explanation": None,
                "enhanced_answer": base_result.answer,
                "processing_metadata": {
                    "tenant_id": tenant_id,
                    "reasoning_mode": reasoning_mode.value if reasoning_mode else "auto",
                    "fusion_enabled": enable_fusion,
                    "xai_enabled": enable_xai
                }
            }

            # æ­¥éª¤2ï¼šæ•°æ®èåˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if enable_fusion and (sql_results or rag_results or documents):
                try:
                    fusion_result = await self.fusion_engine.fuse_multi_source_data(
                        query=query,
                        query_analysis=base_result.query_analysis,
                        sql_results=sql_results,
                        rag_results=rag_results,
                        documents=documents,
                        context=context,
                        tenant_id=tenant_id
                    )

                    enhanced_result["fusion_result"] = fusion_result

                    # å¦‚æœèåˆç»“æœè´¨é‡æ›´é«˜ï¼Œä½¿ç”¨èåˆåçš„ç­”æ¡ˆ
                    if fusion_result.answer_quality_score > base_result.quality_score:
                        enhanced_result["enhanced_answer"] = fusion_result.answer
                        logger.info(f"ä½¿ç”¨èåˆç­”æ¡ˆï¼Œè´¨é‡æå‡: {fusion_result.answer_quality_score - base_result.quality_score:.2f}")

                except Exception as e:
                    logger.error(f"æ•°æ®èåˆå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€æ¨ç†ç»“æœ: {e}")

            # æ­¥éª¤3ï¼šXAIè§£é‡Šï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if enable_xai:
                try:
                    xai_explanation = await self.xai_service.generate_explanation(
                        query=query,
                        answer=enhanced_result["enhanced_answer"],
                        fusion_result=enhanced_result["fusion_result"],
                        reasoning_steps=base_result.reasoning_steps,
                        sources=self._prepare_sources_for_xai(sql_results, rag_results, documents),
                        tenant_id=tenant_id
                    )

                    enhanced_result["xai_explanation"] = xai_explanation

                    # æ ¹æ®XAIç»“æœè°ƒæ•´ç­”æ¡ˆï¼ˆå¦‚æœéœ€è¦ï¼‰
                    if xai_explanation.explanation_quality_score < 0.5:
                        logger.warning(f"XAIè§£é‡Šè´¨é‡è¾ƒä½: {xai_explanation.explanation_quality_score:.2f}")

                except Exception as e:
                    logger.error(f"XAIè§£é‡Šç”Ÿæˆå¤±è´¥: {e}")

            # æ­¥éª¤4ï¼šæ·»åŠ å¤„ç†æ—¶é—´å’Œç»Ÿè®¡ä¿¡æ¯
            processing_time = time.time() - start_time
            enhanced_result["processing_metadata"]["total_processing_time"] = processing_time
            enhanced_result["processing_metadata"]["timestamp"] = datetime.utcnow().isoformat()

            # æ·»åŠ è´¨é‡æŒ‡æ ‡
            enhanced_result["quality_metrics"] = self._calculate_quality_metrics(enhanced_result)

            logger.info(f"å¢å¼ºæ¨ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            return enhanced_result

        except Exception as e:
            logger.error(f"å¢å¼ºæ¨ç†å¤±è´¥: {e}")
            # è¿”å›åŸºç¡€æ¨ç†ç»“æœä½œä¸ºåå¤‡
            base_result = await self.base_engine.reason(
                query=query, context=context, tenant_id=tenant_id
            )

            return {
                "query": query,
                "base_reasoning": base_result,
                "fusion_result": None,
                "xai_explanation": None,
                "enhanced_answer": base_result.answer,
                "processing_metadata": {"error": str(e), "fallback_to_base": True},
                "quality_metrics": {}
            }

    def _prepare_data_sources(
        self,
        sql_results: Optional[List[Dict[str, Any]]],
        rag_results: Optional[List[Dict[str, Any]]],
        documents: Optional[List[Dict[str, Any]]]
    ) -> List[Dict[str, Any]]:
        """ä¸ºåŸºç¡€æ¨ç†å¼•æ“å‡†å¤‡æ•°æ®æºæ ¼å¼"""
        data_sources = []

        # è½¬æ¢SQLç»“æœ
        if sql_results:
            for i, result in enumerate(sql_results):
                data_sources.append({
                    "id": f"sql_{i}",
                    "type": "sql_query",
                    "name": f"SQLæŸ¥è¯¢ç»“æœ{i+1}",
                    "content": json.dumps(result.get("data", result), ensure_ascii=False),
                    "confidence": result.get("confidence", 0.9)
                })

        # è½¬æ¢RAGç»“æœ
        if rag_results:
            for i, result in enumerate(rag_results):
                content = result.get("content", "")
                if isinstance(content, list):
                    content = " ".join(str(item) for item in content)

                data_sources.append({
                    "id": f"rag_{i}",
                    "type": "rag_retrieval",
                    "name": f"RAGæ£€ç´¢ç»“æœ{i+1}",
                    "content": content,
                    "confidence": result.get("similarity_score", 0.8)
                })

        # è½¬æ¢æ–‡æ¡£ç»“æœ
        if documents:
            for i, doc in enumerate(documents):
                content = doc.get("content", doc.get("text", ""))
                if isinstance(content, list):
                    content = " ".join(str(item) for item in content)

                data_sources.append({
                    "id": f"doc_{i}",
                    "type": "document",
                    "name": doc.get("title", f"æ–‡æ¡£{i+1}"),
                    "content": content,
                    "confidence": doc.get("confidence", 0.7)
                })

        return data_sources

    def _prepare_sources_for_xai(
        self,
        sql_results: Optional[List[Dict[str, Any]]],
        rag_results: Optional[List[Dict[str, Any]]],
        documents: Optional[List[Dict[str, Any]]]
    ) -> List[Dict[str, Any]]:
        """ä¸ºXAIæœåŠ¡å‡†å¤‡æ•°æ®æºæ ¼å¼"""
        sources = []

        # è½¬æ¢æ‰€æœ‰æ•°æ®æºä¸ºç»Ÿä¸€æ ¼å¼
        all_data = {
            "sql_results": sql_results or [],
            "rag_results": rag_results or [],
            "documents": documents or []
        }

        for source_type, data_list in all_data.items():
            for i, data in enumerate(data_list):
                sources.append({
                    "source_id": f"{source_type}_{i}",
                    "source_type": source_type.rstrip('s'),  # ç§»é™¤å¤æ•°å½¢å¼
                    "name": data.get("name", f"{source_type}_{i}"),
                    "content": data.get("content", ""),
                    "confidence": data.get("confidence", data.get("similarity_score", 0.7)),
                    "relevance_score": data.get("relevance_score", data.get("similarity_score", 0.8)),
                    "metadata": {
                        k: v for k, v in data.items()
                        if k not in ["content", "confidence", "relevance_score"]
                    }
                })

        return sources

    def _calculate_quality_metrics(self, enhanced_result: Dict[str, Any]) -> Dict[str, Any]:
        """è®¡ç®—ç»¼åˆè´¨é‡æŒ‡æ ‡"""
        metrics = {}

        try:
            base_reasoning = enhanced_result.get("base_reasoning")
            fusion_result = enhanced_result.get("fusion_result")
            xai_explanation = enhanced_result.get("xai_explanation")

            # åŸºç¡€æ¨ç†è´¨é‡
            if base_reasoning:
                metrics["base_reasoning_quality"] = base_reasoning.quality_score
                metrics["base_reasoning_confidence"] = base_reasoning.confidence

            # èåˆè´¨é‡
            if fusion_result:
                metrics["fusion_quality"] = fusion_result.answer_quality_score
                metrics["fusion_confidence"] = fusion_result.confidence
                metrics["source_count"] = len(fusion_result.sources)
                metrics["conflict_count"] = len(fusion_result.conflicts)

            # XAIè´¨é‡
            if xai_explanation:
                metrics["xai_quality"] = xai_explanation.explanation_quality_score
                metrics["explanation_steps"] = len(xai_explanation.explanation_steps)
                metrics["source_traces"] = len(xai_explanation.source_traces)

            # ç»¼åˆè´¨é‡åˆ†æ•°
            quality_scores = []
            if "base_reasoning_quality" in metrics:
                quality_scores.append(metrics["base_reasoning_quality"])
            if "fusion_quality" in metrics:
                quality_scores.append(metrics["fusion_quality"])
            if "xai_quality" in metrics:
                quality_scores.append(metrics["xai_quality"])

            if quality_scores:
                metrics["overall_quality"] = sum(quality_scores) / len(quality_scores)
            else:
                metrics["overall_quality"] = 0.5

            # è´¨é‡ç­‰çº§
            overall_quality = metrics["overall_quality"]
            if overall_quality >= 0.8:
                metrics["quality_grade"] = "ä¼˜ç§€"
            elif overall_quality >= 0.6:
                metrics["quality_grade"] = "è‰¯å¥½"
            elif overall_quality >= 0.4:
                metrics["quality_grade"] = "ä¸€èˆ¬"
            else:
                metrics["quality_grade"] = "éœ€è¦æ”¹è¿›"

        except Exception as e:
            logger.error(f"è®¡ç®—è´¨é‡æŒ‡æ ‡å¤±è´¥: {e}")
            metrics["error"] = str(e)

        return metrics

    async def get_reasoning_capabilities(self) -> Dict[str, Any]:
        """è·å–æ¨ç†èƒ½åŠ›ä¿¡æ¯"""
        try:
            capabilities = {
                "reasoning_modes": [mode.value for mode in ReasoningMode],
                "query_types": [qtype.value for qtype in QueryType],
                "supported_features": {
                    "multi_source_fusion": True,
                    "xai_explanation": True,
                    "conflict_resolution": True,
                    "uncertainty_quantification": True,
                    "source_tracing": True,
                    "alternative_answers": True,
                    "decision_tree": True
                },
                "fusion_algorithms": [
                    "weighted_confidence_fusion",
                    "sql_priority_resolution",
                    "conflict_detection",
                    "evidence_based_synthesis"
                ],
                "xai_types": [
                    "data_source", "reasoning_process", "confidence",
                    "alternative", "uncertainty", "assumption"
                ],
                "visualization_types": [
                    "decision_tree", "evidence_chain", "timeline",
                    "confidence_heatmap", "interactive_explorer"
                ]
            }

            return capabilities

        except Exception as e:
            logger.error(f"è·å–æ¨ç†èƒ½åŠ›å¤±è´¥: {e}")
            return {"error": str(e)}

    async def benchmark_reasoning(
        self,
        test_queries: List[str],
        tenant_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """æ¨ç†æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        try:
            benchmark_results = {
                "test_queries_count": len(test_queries),
                "results": [],
                "performance_metrics": {
                    "average_processing_time": 0.0,
                    "average_quality_score": 0.0,
                    "success_rate": 0.0
                }
            }

            total_processing_time = 0.0
            total_quality_score = 0.0
            success_count = 0

            for i, query in enumerate(test_queries):
                try:
                    start_time = time.time()

                    result = await self.enhanced_reason(
                        query=query,
                        tenant_id=tenant_id,
                        enable_fusion=True,
                        enable_xai=True
                    )

                    processing_time = time.time() - start_time
                    quality_score = result.get("quality_metrics", {}).get("overall_quality", 0.0)

                    test_result = {
                        "query_index": i + 1,
                        "query": query,
                        "processing_time": processing_time,
                        "quality_score": quality_score,
                        "success": True,
                        "answer_length": len(result.get("enhanced_answer", "")),
                        "fusion_used": result.get("fusion_result") is not None,
                        "xai_used": result.get("xai_explanation") is not None
                    }

                    benchmark_results["results"].append(test_result)

                    total_processing_time += processing_time
                    total_quality_score += quality_score
                    success_count += 1

                except Exception as e:
                    logger.error(f"åŸºå‡†æµ‹è¯•æŸ¥è¯¢ {i+1} å¤±è´¥: {e}")
                    benchmark_results["results"].append({
                        "query_index": i + 1,
                        "query": query,
                        "processing_time": 0.0,
                        "quality_score": 0.0,
                        "success": False,
                        "error": str(e)
                    })

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            if success_count > 0:
                benchmark_results["performance_metrics"]["average_processing_time"] = (
                    total_processing_time / success_count
                )
                benchmark_results["performance_metrics"]["average_quality_score"] = (
                    total_quality_score / success_count
                )
                benchmark_results["performance_metrics"]["success_rate"] = (
                    success_count / len(test_queries)
                )

            return benchmark_results

        except Exception as e:
            logger.error(f"åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
            return {"error": str(e)}


# å…¨å±€å¢å¼ºæ¨ç†å¼•æ“å®ä¾‹
enhanced_reasoning_engine = EnhancedReasoningEngine()