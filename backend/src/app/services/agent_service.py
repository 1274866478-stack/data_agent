"""
# [AGENT_SERVICE] Agenté›†æˆæœåŠ¡

## [HEADER]
**æ–‡ä»¶å**: agent_service.py
**èŒè´£**: é›†æˆLangGraph SQL Agentåˆ°åç«¯APIï¼Œæä¾›Agentå“åº”è½¬æ¢ã€å›¾è¡¨å¤„ç†ã€æ–‡ä»¶/æ•°æ®åº“æ™ºèƒ½è·¯ç”±å’Œå¹»è§‰æ£€æµ‹åŠŸèƒ½
**ä½œè€…**: Data Agent Team
**ç‰ˆæœ¬**: 1.0.0
**å˜æ›´è®°å½•**:
- v1.0.0 (2026-01-01): åˆå§‹ç‰ˆæœ¬ - Agenté›†æˆæœåŠ¡

## [INPUT]
- **question: str** - ç”¨æˆ·è‡ªç„¶è¯­è¨€é—®é¢˜
- **thread_id: str** - ä¼šè¯çº¿ç¨‹ID
- **database_url: Optional[str]** - æ•°æ®åº“è¿æ¥URLæˆ–æ–‡ä»¶è·¯å¾„ï¼ˆxlsx, csv, /uploads/, /data/ç­‰ï¼‰
- **verbose: bool** - æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡ºï¼ˆé»˜è®¤Falseï¼‰
- **enable_echarts: bool** - æ˜¯å¦å¯ç”¨EChartså›¾è¡¨ç”Ÿæˆï¼ˆé»˜è®¤Trueï¼‰
- **agent_response: VisualizationResponse** - Agentè¿”å›çš„å“åº”å¯¹è±¡
- **query_id: str** - æŸ¥è¯¢ID
- **tenant_id: str** - ç§Ÿæˆ·ID
- **original_query: str** - åŸå§‹æŸ¥è¯¢æ–‡æœ¬
- **processing_time_ms: int** - å¤„ç†æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
- **execution_time: float** - æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
- **chart_path: str** - å›¾è¡¨æ–‡ä»¶è·¯å¾„
- **answer: str** - Agentè¿”å›çš„answeræ–‡æœ¬

## [OUTPUT]
- **VisualizationResponse**: run_agent_queryè¿”å›Agentå“åº”å¯¹è±¡
  - success: bool - æŸ¥è¯¢æ˜¯å¦æˆåŠŸ
  - sql: str - ç”Ÿæˆçš„SQLè¯­å¥
  - answer: str - è‡ªç„¶è¯­è¨€è§£é‡Š
  - data: QueryResult - æŸ¥è¯¢ç»“æœæ•°æ®
  - chart: ChartConfig - å›¾è¡¨é…ç½®
  - echarts_option: Dict - EChartsé…ç½®é€‰é¡¹
  - metadata: Dict - å…ƒæ•°æ®ï¼ˆå¹»è§‰æ£€æµ‹æ ‡å¿—ç­‰ï¼‰
- **Dict[str, Any]**: convert_agent_response_to_query_responseè¿”å›QueryResponseV3æ ¼å¼
  - query_id, tenant_id, original_query
  - generated_sql, results, row_count
  - execution_result: {success, data_columns, chart_type, chart_title, chart_data, echarts_option}
  - explanation, processing_steps, validation_result
  - metadata: {hallucination_detected, hallucination_reason}
- **Dict[str, Any]**: convert_agent_response_to_chat_responseè¿”å›ChatQueryResponseæ ¼å¼
  - answer, sources, reasoning, confidence, execution_time
  - sql, data: {columns, rows, row_count}
  - chart: {chart_type, title, x_field, y_field, chart_image, chart_data}
  - echarts_option: Dict
- **Optional[str]**: extract_chart_path_from_answerè¿”å›æå–çš„å›¾è¡¨è·¯å¾„æˆ–URL
- **Optional[str]**: load_chart_as_base64è¿”å›Base64ç¼–ç çš„å›¾ç‰‡æ•°æ®ï¼ˆdata URIæ ¼å¼ï¼‰
- **bool**: is_agent_availableè¿”å›Agentæ˜¯å¦å¯ç”¨

**ä¸Šæ¸¸ä¾èµ–** (å·²è¯»å–æºç ):
- [Agent/models.py](../../Agent/models.py) - Agentæ•°æ®æ¨¡å‹ï¼ˆVisualizationResponseï¼‰
- [Agent/sql_agent.py](../../Agent/sql_agent.py) - æ—§ç‰ˆAgentï¼ˆrun_agentï¼‰
- [Agent/app/services/agent_service.py](../../Agent/app/services/agent_service.py) - æ–°ç‰ˆAgentï¼ˆæ”¯æŒenable_echartsï¼‰
- [Agent/config.py](../../Agent/config.py) - Agenté…ç½®

**ä¸‹æ¸¸ä¾èµ–** (éœ€è¦åå‘ç´¢å¼•åˆ†æ):
- [../api/v1/endpoints/query.py](../api/v1/endpoints/query.py) - æŸ¥è¯¢APIç«¯ç‚¹
- [../api/v1/endpoints/llm.py](../api/v1/endpoints/llm.py) - LLM APIç«¯ç‚¹
- [llm_service.py](./llm_service.py) - LLMæœåŠ¡ï¼ˆAgentæŸ¥è¯¢é›†æˆï¼‰

**è°ƒç”¨æ–¹**:
- è‡ªç„¶è¯­è¨€æŸ¥è¯¢API
- èŠå¤©å¯¹è¯ä¸­çš„æŸ¥è¯¢åŠŸèƒ½
- AgentæŸ¥è¯¢å¥åº·æ£€æŸ¥

## [STATE]
- **Agentè·¯å¾„ç®¡ç†**: åŠ¨æ€æ·»åŠ Agentç›®å½•åˆ°sys.path
- **ç‰ˆæœ¬å…¼å®¹**: æ”¯æŒæ–°æ—§ä¸¤ä¸ªç‰ˆæœ¬Agentï¼ˆ_use_new_agentæ ‡å¿—ï¼‰
  - æ–°ç‰ˆæœ¬: æ”¯æŒenable_echartså‚æ•°ï¼Œè¿”å›{response: VisualizationResponse}
  - æ—§ç‰ˆæœ¬: ä¸æ”¯æŒenable_echartsï¼Œç›´æ¥è¿”å›VisualizationResponse
- **é™çº§æœºåˆ¶**: Agentå¯¼å…¥å¤±è´¥æ—¶è®¾ç½®_agent_available=Falseï¼Œä¸é˜»å¡åº”ç”¨å¯åŠ¨
- **æ–‡ä»¶/æ•°æ®åº“è·¯ç”±**: æ—©æœŸæ£€æµ‹database_urlç±»å‹ï¼ˆæ–‡ä»¶æ‰©å±•åã€æœ¬åœ°è·¯å¾„ã€æ•°æ®åº“åè®®ï¼‰
- **å¹»è§‰æ£€æµ‹**: ä¸‰é“é˜²çº¿
  1. metadata.hallucination_detectedæ ‡å¿—
  2. answerå­—æ®µå‡æ•°æ®æ¨¡å¼äºŒæ¬¡æ£€æŸ¥ï¼ˆæ­£åˆ™åŒ¹é…æµ‹è¯•åï¼‰
  3. safe_getå®‰å…¨å±æ€§è®¿é—®ï¼ˆé˜²æ­¢Pydantic/å­—å…¸è®¿é—®é”™è¯¯ï¼‰
- **Promptæ³¨å…¥**: æ ¹æ®è·¯ç”±æ¨¡å¼æ³¨å…¥ä¸åŒçš„ç³»ç»ŸæŒ‡ä»¤ï¼ˆæ–‡ä»¶æ¨¡å¼ç¦ç”¨SQLå·¥å…·ï¼‰
- **é…ç½®ä¸´æ—¶è¦†ç›–**: è¿è¡Œæ—¶ä¸´æ—¶è¦†ç›–Agentçš„database_urlé…ç½®ï¼ˆæŸ¥è¯¢åæ¢å¤ï¼‰

## [SIDE-EFFECTS]
- **è·¯å¾„æ“ä½œ**: ä¿®æ”¹sys.pathæ’å…¥Agentç›®å½•
- **æ¨¡å—å¯¼å…¥**: åŠ¨æ€å¯¼å…¥Agentæ¨¡å—ï¼ˆsql_agent, models, config, agent_serviceï¼‰
- **æ–‡ä»¶I/O**: load_chart_as_base64è¯»å–å›¾è¡¨æ–‡ä»¶
- **Base64ç¼–ç **: å›¾è¡¨æ–‡ä»¶è½¬æ¢ä¸ºBase64 data URI
- **æ­£åˆ™åŒ¹é…**: æå–å›¾è¡¨è·¯å¾„ã€æ£€æµ‹å‡æ•°æ®æ¨¡å¼ã€æå–SQLè¡¨å
- **é…ç½®ä¿®æ”¹**: ä¸´æ—¶è¦†ç›–Agent config.database_urlï¼ˆæŸ¥è¯¢åæ¢å¤åŸå€¼ï¼‰
- **Promptå·¥ç¨‹**: æ³¨å…¥ç³»ç»ŸæŒ‡ä»¤åˆ°ç”¨æˆ·é—®é¢˜ï¼ˆenhanced_questionï¼‰
- **å¼‚å¸¸å¤„ç†**: å¤§é‡try-exceptä¿æŠ¤Agentè°ƒç”¨å’Œå±æ€§è®¿é—®
- **æ—¥å¿—è®°å½•**: è¯¦ç»†çš„è·¯ç”±ã€é…ç½®ã€æŸ¥è¯¢æ‰§è¡Œæ—¥å¿—
- **ç±»å‹è½¬æ¢**: Pydanticæ¨¡å‹è½¬å­—å…¸ï¼ˆmetadata, chartç­‰å¯¹è±¡çš„.dict()æˆ–.model_dump()ï¼‰
- **URLæ¸…ç†**: æ–‡ä»¶æ¨¡å¼ä¸‹æ¸…ç†database_urlé˜²æ­¢Postgreså·¥å…·å´©æºƒ

## [POS]
**è·¯å¾„**: backend/src/app/services/agent_service.py
**æ¨¡å—å±‚çº§**: Level 1 (æœåŠ¡å±‚)
**ä¾èµ–æ·±åº¦**: è·¨æ¨¡å—ä¾èµ–Agentç›®å½•ï¼ˆå¤–éƒ¨ä¾èµ–ï¼‰
"""
import sys
import os
import base64
import re
from pathlib import Path
from typing import Dict, Any, Optional
import asyncio
import logging

logger = logging.getLogger(__name__)

# æ·»åŠ  Agent ç›®å½•åˆ° Python è·¯å¾„
# agent_service.py ä½äº backend/src/app/services/
# éœ€è¦å‘ä¸Šåˆ°é¡¹ç›®æ ¹ç›®å½•ï¼Œç„¶åè¿›å…¥ Agent ç›®å½•
_agent_path = Path(__file__).parent.parent.parent.parent.parent / "Agent"
if _agent_path.exists() and str(_agent_path) not in sys.path:
    sys.path.insert(0, str(_agent_path))

try:
    from models import VisualizationResponse
    # ä¼˜å…ˆä½¿ç”¨æ–°ç‰ˆæœ¬çš„ run_agentï¼ˆæ”¯æŒ enable_echartsï¼‰
    try:
        from app.services.agent.agent_service import run_agent
        _use_new_agent = True
        logger.info("ä½¿ç”¨æ–°ç‰ˆæœ¬ Agent (æ”¯æŒ enable_echarts)")
    except ImportError:
        # å›é€€åˆ°æ—§ç‰ˆæœ¬
        from sql_agent import run_agent as run_agent_legacy
        run_agent = run_agent_legacy
        _use_new_agent = False
        logger.info("ä½¿ç”¨æ—§ç‰ˆæœ¬ Agent (ä¸æ”¯æŒ enable_echarts)")
    _agent_available = True
except ImportError as e:
    logger.warning(f"Agentæ¨¡å—å¯¼å…¥å¤±è´¥: {e}ï¼ŒAgentåŠŸèƒ½å°†ä¸å¯ç”¨")
    _agent_available = False
    run_agent = None
    _use_new_agent = False
    VisualizationResponse = None


def extract_chart_path_from_answer(answer: str) -> Optional[str]:
    """
    ä»answeræ–‡æœ¬ä¸­æå–å›¾è¡¨è·¯å¾„
    
    Args:
        answer: Agentè¿”å›çš„answeræ–‡æœ¬
    
    Returns:
        å›¾è¡¨è·¯å¾„ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
    """
    if not answer:
        return None
    
    # åŒ¹é…å›¾è¡¨è·¯å¾„æ¨¡å¼ï¼šå›¾è¡¨å·²ä¿å­˜: <path> æˆ– å›¾è¡¨é“¾æ¥: <url>
    patterns = [
        r'å›¾è¡¨å·²ä¿å­˜:\s*([^\n]+)',
        r'å›¾è¡¨é“¾æ¥:\s*([^\n]+)',
        r'ğŸ“Š\s*å›¾è¡¨å·²ä¿å­˜:\s*([^\n]+)',
        r'ğŸ“Š\s*å›¾è¡¨é“¾æ¥:\s*([^\n]+)',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, answer)
        if match:
            path = match.group(1).strip()
            # å¦‚æœæ˜¯URLï¼Œç›´æ¥è¿”å›
            if path.startswith('http://') or path.startswith('https://'):
                return path
            # å¦‚æœæ˜¯æœ¬åœ°è·¯å¾„ï¼Œè¿”å›ç»å¯¹è·¯å¾„
            if os.path.exists(path):
                return os.path.abspath(path)
            # å°è¯•ç›¸å¯¹äºAgentç›®å½•çš„è·¯å¾„
            agent_charts_dir = _agent_path / "charts"
            if agent_charts_dir.exists():
                chart_path = agent_charts_dir / os.path.basename(path)
                if chart_path.exists():
                    return str(chart_path.absolute())
    
    return None


def load_chart_as_base64(chart_path: str) -> Optional[str]:
    """
    å°†å›¾è¡¨æ–‡ä»¶åŠ è½½ä¸ºBase64ç¼–ç 
    
    Args:
        chart_path: å›¾è¡¨æ–‡ä»¶è·¯å¾„
    
    Returns:
        Base64ç¼–ç çš„å›¾ç‰‡æ•°æ®ï¼ˆdata URIæ ¼å¼ï¼‰ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
    """
    try:
        if not os.path.exists(chart_path):
            logger.warning(f"å›¾è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {chart_path}")
            return None
        
        # è¯»å–æ–‡ä»¶
        with open(chart_path, 'rb') as f:
            image_data = f.read()
        
        # ç¡®å®šMIMEç±»å‹
        ext = os.path.splitext(chart_path)[1].lower()
        mime_types = {
            '.png': 'image/png',
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.gif': 'image/gif',
            '.svg': 'image/svg+xml',
            '.html': 'text/html'
        }
        mime_type = mime_types.get(ext, 'image/png')
        
        # è½¬æ¢ä¸ºBase64
        base64_data = base64.b64encode(image_data).decode('utf-8')
        return f"data:{mime_type};base64,{base64_data}"
    
    except Exception as e:
        logger.error(f"åŠ è½½å›¾è¡¨æ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
        return None


def _build_processing_steps(
    success: bool,
    sql: str,
    results: list,
    row_count: int,
    data_obj: Any,
    echarts_option: Any,
    chart_data: Any,
    chart_obj: Any,
    processing_time_ms: int,
    answer: str = ""
) -> list:
    """
    æ„å»ºåŒ…å«SQLã€è¡¨æ ¼ã€å›¾è¡¨ã€æ•°æ®åˆ†ææ–‡æœ¬çš„å¤„ç†æ­¥éª¤åˆ—è¡¨

    Args:
        success: æŸ¥è¯¢æ˜¯å¦æˆåŠŸ
        sql: SQLè¯­å¥
        results: æŸ¥è¯¢ç»“æœåˆ—è¡¨
        row_count: è¡Œæ•°
        data_obj: æ•°æ®å¯¹è±¡
        echarts_option: EChartsé…ç½®
        chart_data: å›¾è¡¨æ•°æ®
        chart_obj: å›¾è¡¨å¯¹è±¡
        processing_time_ms: å¤„ç†æ—¶é—´
        answer: AIæ•°æ®åˆ†ææ–‡æœ¬ï¼ˆç”¨äºæ­¥éª¤8ï¼‰

    Returns:
        list: å¤„ç†æ­¥éª¤åˆ—è¡¨
    """
    if not success:
        return [{
            "step": 1,
            "title": "æŸ¥è¯¢å¤„ç†å¤±è´¥",
            "description": "æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ï¼Œè¯·æ£€æŸ¥æ•°æ®æºé…ç½®æˆ–é‡æ–°æé—®",
            "status": "error"
        }]

    # è®¡ç®—å„æ­¥éª¤çš„å¤§è‡´è€—æ—¶ï¼ˆä¼°ç®—ï¼‰
    base_time = processing_time_ms / 8  # ç°åœ¨æœ‰8ä¸ªæ­¥éª¤

    # æ„å»ºè¡¨æ ¼æ•°æ®ï¼ˆç”¨äºæ­¥éª¤6ï¼‰
    table_data = None
    if data_obj:
        columns = safe_get_attr(data_obj, 'columns', [])
        rows = safe_get_attr(data_obj, 'rows', [])
        if columns and rows:
            table_data = {
                "columns": columns,
                "rows": rows[:50],  # é™åˆ¶æœ€å¤š50è¡Œ
                "row_count": row_count
            }

    # æ„å»ºå›¾è¡¨æ•°æ®ï¼ˆç”¨äºæ­¥éª¤7ï¼‰
    chart_step_data = None
    if echarts_option:
        chart_step_data = {
            "echarts_option": echarts_option,
            "chart_type": _extract_chart_type(chart_obj)
        }
    elif chart_data:
        chart_step_data = {
            "chart_image": chart_data,
            "chart_type": _extract_chart_type(chart_obj)
        }

    steps = [
        {
            "step": 1,
            "title": "ç†è§£ç”¨æˆ·é—®é¢˜",
            "description": "åˆ†æç”¨æˆ·æŸ¥è¯¢æ„å›¾ï¼Œè¯†åˆ«æ•°æ®éœ€æ±‚",
            "status": "completed",
            "duration": int(base_time)
        },
        {
            "step": 2,
            "title": "è·å–æ•°æ®åº“Schema",
            "description": f"æˆåŠŸåŠ è½½ {safe_get_attr(data_obj, 'row_count', 0)} è¡Œæ•°æ®",
            "status": "completed",
            "duration": int(base_time)
        },
        {
            "step": 3,
            "title": "æ„å»ºAI Prompt",
            "description": "æ ¹æ®é—®é¢˜å’ŒSchemaç”ŸæˆæŸ¥è¯¢æŒ‡ä»¤",
            "status": "completed",
            "duration": int(base_time)
        },
        {
            "step": 4,
            "title": "AIç”ŸæˆSQLè¯­å¥",
            "description": "AIå·²ç”Ÿæˆæ•°æ®åº“æŸ¥è¯¢è¯­å¥",
            "status": "completed",
            "duration": int(base_time * 2),
            "content_type": "sql",
            "content_data": {
                "sql": sql
            } if sql else None
        },
        {
            "step": 5,
            "title": "éªŒè¯SQLè¯­å¥",
            "description": "æ£€æŸ¥SQLè¯­æ³•å’Œå®‰å…¨æ€§",
            "status": "completed",
            "duration": int(base_time * 0.5)
        },
        {
            "step": 6,
            "title": "æ‰§è¡ŒSQLæŸ¥è¯¢",
            "description": f"æŸ¥è¯¢è¿”å› {row_count} è¡Œç»“æœ",
            "status": "completed",
            "duration": int(base_time * 1.5),
            "content_type": "table",
            "content_data": {
                "table": table_data
            } if table_data else None
        },
    ]

    # æ·»åŠ æ­¥éª¤7ï¼ˆå›¾è¡¨ç”Ÿæˆï¼‰
    if chart_step_data:
        steps.append({
            "step": 7,
            "title": "ç”Ÿæˆæ•°æ®å¯è§†åŒ–",
            "description": f"åˆ›å»º {chart_step_data.get('chart_type', 'å›¾è¡¨')} å±•ç¤ºåˆ†æç»“æœ",
            "status": "completed",
            "duration": int(base_time * 2),
            "content_type": "chart",
            "content_data": {
                "chart": chart_step_data
            }
        })

    # æ·»åŠ æ­¥éª¤8ï¼ˆæ•°æ®åˆ†ææ€»ç»“ï¼‰
    if answer and answer.strip():
        steps.append({
            "step": 8,
            "title": "æ•°æ®åˆ†ææ€»ç»“",
            "description": "AIå¯¹æŸ¥è¯¢ç»“æœçš„åˆ†æå’Œè§£è¯»",
            "status": "completed",
            "duration": int(base_time * 1.5),
            "content_type": "text",
            "content_data": {
                "text": answer.strip()
            }
        })

    return steps


def _extract_chart_type(chart_obj: Any) -> str:
    """å®‰å…¨æå–å›¾è¡¨ç±»å‹"""
    if not chart_obj:
        return "å›¾è¡¨"

    # å°è¯•ä»chart_objä¸­æå–ç±»å‹
    if hasattr(chart_obj, 'chart_type'):
        chart_type = getattr(chart_obj, 'chart_type')
        if hasattr(chart_type, 'value'):
            return str(chart_type.value)
        return str(chart_type)

    if isinstance(chart_obj, dict):
        return chart_obj.get('chart_type', 'å›¾è¡¨')

    return "å›¾è¡¨"


def safe_get_attr(obj: Any, attr: str, default: Any = None) -> Any:
    """å®‰å…¨è·å–å¯¹è±¡å±æ€§"""
    try:
        if hasattr(obj, attr):
            return getattr(obj, attr)
        if isinstance(obj, dict):
            return obj.get(attr, default)
        return default
    except Exception:
        return default


def convert_agent_response_to_query_response(
    agent_response: VisualizationResponse,
    query_id: str,
    tenant_id: str,
    original_query: str,
    processing_time_ms: int = 0
) -> Dict[str, Any]:
    """
    å°†Agentçš„VisualizationResponseè½¬æ¢ä¸ºåç«¯QueryResponseV3æ ¼å¼
    
    Args:
        agent_response: Agentè¿”å›çš„å¯è§†åŒ–å“åº”
        query_id: æŸ¥è¯¢ID
        tenant_id: ç§Ÿæˆ·ID
        original_query: åŸå§‹æŸ¥è¯¢
        processing_time_ms: å¤„ç†æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    
    Returns:
        Dict: ç¬¦åˆQueryResponseV3æ ¼å¼çš„å­—å…¸
    """
    # ğŸ›¡ï¸ é€šç”¨å®‰å…¨å±æ€§è®¿é—®è¾…åŠ©å‡½æ•° - æ”¯æŒ Pydantic æ¨¡å‹ã€å­—å…¸å’Œæ™®é€šå¯¹è±¡
    def safe_get(obj, attr, default=None):
        """
        å®‰å…¨è·å–å¯¹è±¡å±æ€§ï¼Œæ”¯æŒå¤šç§æ•°æ®ç±»å‹
        
        Args:
            obj: å¯¹è±¡ï¼ˆå¯ä»¥æ˜¯ Pydantic æ¨¡å‹ã€å­—å…¸æˆ–æ™®é€šå¯¹è±¡ï¼‰
            attr: å±æ€§å
            default: é»˜è®¤å€¼
        
        Returns:
            å±æ€§å€¼ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›é»˜è®¤å€¼
        """
        try:
            # Case 1: å­—å…¸ç±»å‹
            if isinstance(obj, dict):
                return obj.get(attr, default)
            
            # Case 2: Pydantic æ¨¡å‹æˆ–å…¶ä»–å¯¹è±¡
            # æ–¹æ³•1: ç›´æ¥å±æ€§è®¿é—®
            if hasattr(obj, attr):
                value = getattr(obj, attr, default)
                # å¦‚æœå€¼æ˜¯ Noneï¼Œä¹Ÿè¿”å›é»˜è®¤å€¼ï¼ˆå¯é€‰ï¼Œæ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
                return value if value is not None else default
            
            # æ–¹æ³•2: å°è¯•ä½¿ç”¨ Pydantic çš„ .dict() æˆ– .model_dump()
            try:
                if hasattr(obj, 'dict'):
                    obj_dict = obj.dict()
                    return obj_dict.get(attr, default)
                elif hasattr(obj, 'model_dump'):
                    obj_dict = obj.model_dump()
                    return obj_dict.get(attr, default)
            except (AttributeError, TypeError):
                pass
            
            # æ–¹æ³•3: å°è¯• __dict__ å±æ€§
            try:
                if hasattr(obj, '__dict__'):
                    return obj.__dict__.get(attr, default)
            except (AttributeError, TypeError):
                pass
            
            return default
        except Exception as e:
            logger.debug(f"safe_get è®¿é—®å±æ€§ {attr} æ—¶å‡ºé”™: {e}")
            return default
    
    # å°†QueryResultè½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨æ ¼å¼
    results = []
    data_obj = safe_get(agent_response, 'data')
    if data_obj:
        rows = safe_get(data_obj, 'rows', [])
        columns = safe_get(data_obj, 'columns', [])
        if rows:
            for row in rows:
                row_dict = {}
                for i, col in enumerate(columns):
                    if i < len(row):
                        row_dict[col] = row[i]
                results.append(row_dict)
    
    # ğŸ›¡ï¸ å¥å£®çš„å›¾è¡¨å›¾ç‰‡æå– - æ”¯æŒ Pydantic æ¨¡å‹ã€å­—å…¸å’Œæ™®é€šå¯¹è±¡
    chart_data = None
    chart_obj = safe_get(agent_response, 'chart')
    if chart_obj:
        # ä½¿ç”¨ safe_get è·å– chart_image
        chart_data = safe_get(chart_obj, 'chart_image')
    
    # é™çº§ï¼šå¦‚æœ chart_image ä¸å­˜åœ¨ï¼Œå°è¯•ä» answer ä¸­æå–ï¼ˆå‘åå…¼å®¹ï¼‰
    if not chart_data:
        answer = safe_get(agent_response, 'answer', '')
        chart_path = extract_chart_path_from_answer(answer)
        if chart_path:
            # å¦‚æœæ˜¯æœ¬åœ°æ–‡ä»¶ï¼Œè½¬æ¢ä¸ºBase64
            if not (chart_path.startswith('http://') or chart_path.startswith('https://')):
                chart_data = load_chart_as_base64(chart_path)
            else:
                # å¦‚æœæ˜¯URLï¼Œç›´æ¥ä½¿ç”¨
                chart_data = chart_path
    
    # æ„å»ºå“åº”æ•°æ®
    execution_result = None
    success = safe_get(agent_response, 'success', False)
    if success:
        # ğŸ›¡ï¸ å®‰å…¨è®¿é—®æ‰€æœ‰ chart å±æ€§
        chart_type = None
        chart_title = None
        chart_obj = safe_get(agent_response, 'chart')
        if chart_obj:
            chart_type_obj = safe_get(chart_obj, 'chart_type')
            if chart_type_obj:
                if hasattr(chart_type_obj, 'value'):
                    chart_type = chart_type_obj.value
                else:
                    chart_type = str(chart_type_obj)
            chart_title = safe_get(chart_obj, 'title')
        
        # ğŸ›¡ï¸ å®‰å…¨è®¿é—® data å±æ€§
        data_obj = safe_get(agent_response, 'data')
        data_columns = []
        if data_obj:
            data_columns = safe_get(data_obj, 'columns', [])
        
        execution_result = {
            "success": success,
            "data_columns": data_columns,
            "chart_type": chart_type,
            "chart_title": chart_title,
            "chart_data": chart_data,  # æ·»åŠ Base64ç¼–ç çš„å›¾è¡¨æ•°æ®æˆ–URL
            "echarts_option": safe_get(agent_response, 'echarts_option')  # ğŸ›¡ï¸ å®‰å…¨è®¿é—® ECharts é…ç½®é€‰é¡¹
        }
    
    # ğŸ”´ ç¬¬ä¸‰é“é˜²çº¿ï¼šæå–metadataï¼ˆå¦‚æœå­˜åœ¨ï¼‰- ä½¿ç”¨ safe_get
    metadata = safe_get(agent_response, 'metadata')
    if metadata and not isinstance(metadata, dict):
        # å¦‚æœæ˜¯ Pydantic æ¨¡å‹ï¼Œè½¬æ¢ä¸ºå­—å…¸
        try:
            if hasattr(metadata, 'dict'):
                metadata = metadata.dict()
            elif hasattr(metadata, 'model_dump'):
                metadata = metadata.model_dump()
            elif hasattr(metadata, '__dict__'):
                metadata = metadata.__dict__
        except Exception:
            metadata = None
    
    # ğŸ”¥ ä¼˜å…ˆçº§1å’Œ4ï¼šæ£€æŸ¥å¹»è§‰æ£€æµ‹æ ‡å¿—å’Œè¿›è¡ŒäºŒæ¬¡æ£€æŸ¥
    explanation = safe_get(agent_response, 'answer', '')
    hallucination_detected_in_metadata = False
    hallucination_reason_in_metadata = None
    
    # æ£€æŸ¥metadataä¸­çš„å¹»è§‰æ ‡å¿—
    if metadata and isinstance(metadata, dict):
        hallucination_detected_in_metadata = metadata.get("hallucination_detected", False)
        hallucination_reason_in_metadata = metadata.get("hallucination_reason", None)
    
    # å¦‚æœmetadataä¸­æ£€æµ‹åˆ°å¹»è§‰ï¼Œä½¿ç”¨é”™è¯¯æ¶ˆæ¯æ›¿æ¢explanation
    if hallucination_detected_in_metadata:
        error_message = (
            "âš ï¸ **æ•°æ®éªŒè¯å¤±è´¥**\n\n"
            "ç³»ç»Ÿæ£€æµ‹åˆ°AIåŠ©æ‰‹å¯èƒ½è¿”å›äº†ä¸å‡†ç¡®çš„æ•°æ®ã€‚\n\n"
        )
        if hallucination_reason_in_metadata:
            if isinstance(hallucination_reason_in_metadata, list):
                error_message += f"**æ£€æµ‹è¯¦æƒ…ï¼š** {', '.join(hallucination_reason_in_metadata)}\n\n"
            else:
                error_message += f"**æ£€æµ‹è¯¦æƒ…ï¼š** {hallucination_reason_in_metadata}\n\n"
        error_message += (
            "**å¯èƒ½çš„åŸå› ï¼š**\n"
            "- AIæœªèƒ½æ­£ç¡®è°ƒç”¨æ•°æ®æŸ¥è¯¢å·¥å…·\n"
            "- å·¥å…·è¿”å›çš„æ•°æ®ä¸ºç©ºæˆ–é”™è¯¯\n"
            "- AIç”Ÿæˆäº†æµ‹è¯•æ•°æ®è€ŒéçœŸå®æ•°æ®\n\n"
            "**å»ºè®®æ“ä½œï¼š**\n"
            "1. è¯·æ£€æŸ¥æ•°æ®æºæ˜¯å¦æ­£ç¡®é…ç½®\n"
            "2. ç¡®è®¤æ•°æ®æºå·²æˆåŠŸåŠ è½½ï¼ˆçŠ¶æ€æ˜¾ç¤ºä¸ºâœ“ï¼‰\n"
            "3. é‡æ–°æé—®æ‚¨çš„é—®é¢˜\n"
        )
        explanation = error_message
        # æ¸…é™¤å¯èƒ½åŒ…å«å‡æ•°æ®çš„ç»“æœ
        results = []
        logger.error(f"ğŸš« [å“åº”è½¬æ¢] æ£€æµ‹åˆ°metadataä¸­çš„å¹»è§‰æ ‡å¿—ï¼Œå·²æ‹¦æˆªå¹¶æ›¿æ¢explanation")
    
    # ğŸ”¥ ä¼˜å…ˆçº§4ï¼šäºŒæ¬¡æ£€æŸ¥ - å³ä½¿metadataä¸­æ²¡æœ‰æ ‡å¿—ï¼Œä¹Ÿè¦æ£€æŸ¥answerå­—æ®µæ˜¯å¦åŒ…å«å‡æ•°æ®
    if not hallucination_detected_in_metadata and explanation:
        import re
        # æ£€æµ‹å¸¸è§çš„å‡æ•°æ®æ¨¡å¼
        fake_data_patterns = [
            r"å¼ ä¸‰|æå››|ç‹äº”|èµµå…­",  # å¸¸è§çš„ä¸­æ–‡æµ‹è¯•åå­—
            r"ç”¨æˆ·[1-9]\d*",  # ç”¨æˆ·1ã€ç”¨æˆ·2ç­‰
            r"Alice|Bob|Charlie|Diana|Eve",  # å¸¸è§çš„è‹±æ–‡æµ‹è¯•åå­—
        ]
        detected_patterns = []
        for pattern in fake_data_patterns:
            if re.search(pattern, explanation):
                detected_patterns.append(pattern)
        
        # å¦‚æœæ£€æµ‹åˆ°å¤šä¸ªå‡æ•°æ®æ¨¡å¼ï¼Œå¾ˆå¯èƒ½æ˜¯å‡æ•°æ®
        if len(detected_patterns) >= 2:
            error_message = (
                "âš ï¸ **æ•°æ®éªŒè¯å¤±è´¥**\n\n"
                "ç³»ç»Ÿæ£€æµ‹åˆ°å›ç­”ä¸­å¯èƒ½åŒ…å«æµ‹è¯•æ•°æ®è€ŒéçœŸå®æ•°æ®ã€‚\n\n"
                "**æ£€æµ‹åˆ°çš„å¯ç–‘æ¨¡å¼ï¼š**\n"
                f"- {', '.join(detected_patterns)}\n\n"
                "**å¯èƒ½çš„åŸå› ï¼š**\n"
                "- AIæœªèƒ½æ­£ç¡®è°ƒç”¨æ•°æ®æŸ¥è¯¢å·¥å…·\n"
                "- å·¥å…·è¿”å›çš„æ•°æ®ä¸ºç©ºæˆ–é”™è¯¯\n"
                "- AIç”Ÿæˆäº†æµ‹è¯•æ•°æ®è€ŒéçœŸå®æ•°æ®\n\n"
                "**å»ºè®®æ“ä½œï¼š**\n"
                "1. è¯·æ£€æŸ¥æ•°æ®æºæ˜¯å¦æ­£ç¡®é…ç½®\n"
                "2. ç¡®è®¤æ•°æ®æºå·²æˆåŠŸåŠ è½½ï¼ˆçŠ¶æ€æ˜¾ç¤ºä¸ºâœ“ï¼‰\n"
                "3. é‡æ–°æé—®æ‚¨çš„é—®é¢˜\n"
            )
            explanation = error_message
            results = []
            logger.error(f"ğŸš« [å“åº”è½¬æ¢] äºŒæ¬¡æ£€æŸ¥æ£€æµ‹åˆ°å‡æ•°æ®æ¨¡å¼ï¼Œå·²æ‹¦æˆªå¹¶æ›¿æ¢explanation")
    
    # ğŸ›¡ï¸ å®‰å…¨è®¿é—®æ‰€æœ‰å±æ€§
    sql = safe_get(agent_response, 'sql', '')
    data_obj = safe_get(agent_response, 'data')
    row_count = 0
    if data_obj:
        row_count = safe_get(data_obj, 'row_count', 0)
    
    error = safe_get(agent_response, 'error')
    echarts_option = safe_get(agent_response, 'echarts_option')
    
    response_data = {
        "query_id": query_id,
        "tenant_id": tenant_id,
        "original_query": original_query,
        "generated_sql": sql,
        "results": results,
        "row_count": row_count,
        "processing_time_ms": processing_time_ms,
        "confidence_score": 0.9 if success else 0.5,
        "explanation": explanation,
        # ğŸ”¥ æ‰©å±•çš„å¤„ç†æ­¥éª¤ï¼šåŒ…å«SQLã€è¡¨æ ¼ã€å›¾è¡¨æ•°æ®ã€æ•°æ®åˆ†ææ–‡æœ¬
        "processing_steps": _build_processing_steps(
            success=success,
            sql=sql,
            results=results,
            row_count=row_count,
            data_obj=data_obj,
            echarts_option=echarts_option,
            chart_data=chart_data,
            chart_obj=safe_get(agent_response, 'chart'),
            processing_time_ms=processing_time_ms,
            answer=explanation
        ),
        "validation_result": {
            "valid": success,
            "error": error
        } if not success else None,
        "execution_result": execution_result,
        "correction_attempts": 0,
        # ğŸ›¡ï¸ åœ¨é¡¶å±‚ä¹Ÿæ·»åŠ  echarts_optionï¼Œä½¿ç”¨å®‰å…¨è®¿é—®
        "echarts_option": echarts_option,
        # ğŸ”´ ç¬¬ä¸‰é“é˜²çº¿ï¼šæ·»åŠ metadataä¾›å‰ç«¯ä½¿ç”¨
        "metadata": metadata
    }
    
    return response_data


def convert_agent_response_to_chat_response(
    agent_response: VisualizationResponse,
    execution_time: float = 0.0
) -> Dict[str, Any]:
    """
    å°†Agentçš„VisualizationResponseè½¬æ¢ä¸ºå‰ç«¯ChatQueryResponseæ ¼å¼
    
    Args:
        agent_response: Agentè¿”å›çš„å¯è§†åŒ–å“åº”
        execution_time: æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
    
    Returns:
        Dict: ç¬¦åˆChatQueryResponseæ ¼å¼çš„å­—å…¸
    """
    # ğŸ›¡ï¸ é€šç”¨å®‰å…¨å±æ€§è®¿é—®è¾…åŠ©å‡½æ•°ï¼ˆä¸ convert_agent_response_to_query_response ä¸­çš„ç›¸åŒï¼‰
    def safe_get(obj, attr, default=None):
        """å®‰å…¨è·å–å¯¹è±¡å±æ€§ï¼Œæ”¯æŒå¤šç§æ•°æ®ç±»å‹"""
        try:
            if isinstance(obj, dict):
                return obj.get(attr, default)
            if hasattr(obj, attr):
                value = getattr(obj, attr, default)
                return value if value is not None else default
            try:
                if hasattr(obj, 'dict'):
                    obj_dict = obj.dict()
                    return obj_dict.get(attr, default)
                elif hasattr(obj, 'model_dump'):
                    obj_dict = obj.model_dump()
                    return obj_dict.get(attr, default)
            except (AttributeError, TypeError):
                pass
            try:
                if hasattr(obj, '__dict__'):
                    return obj.__dict__.get(attr, default)
            except (AttributeError, TypeError):
                pass
            return default
        except Exception:
            return default
    
    # æå–æ•°æ®æºä¿¡æ¯ï¼ˆä»SQLä¸­æ¨æ–­ï¼‰
    sources = []
    sql = safe_get(agent_response, 'sql', '')
    if sql:
        # ç®€å•æå–è¡¨åï¼ˆå¯ä»¥æ”¹è¿›ï¼‰
        import re
        table_pattern = r'FROM\s+(\w+)'
        tables = re.findall(table_pattern, sql, re.IGNORECASE)
        sources.extend(tables)
    
    # ğŸ›¡ï¸ å®‰å…¨æ„å»º chart å¯¹è±¡ï¼Œé˜²æ­¢ AttributeError
    chart_dict = None
    chart_obj = safe_get(agent_response, 'chart')
    if chart_obj:
        # æ£€æŸ¥æ˜¯å¦æ˜¯ table ç±»å‹ï¼ˆä¸éœ€è¦å›¾è¡¨ï¼‰
        chart_type_obj = safe_get(chart_obj, 'chart_type')
        chart_type_value = None
        if chart_type_obj:
            if hasattr(chart_type_obj, 'value'):
                chart_type_value = chart_type_obj.value
            else:
                chart_type_value = str(chart_type_obj)
        
        # åªæœ‰é table ç±»å‹æ‰æ„å»º chart å¯¹è±¡
        if chart_type_value and chart_type_value != "table":
            # ğŸ›¡ï¸ ä½¿ç”¨ safe_get å®‰å…¨æå–æ‰€æœ‰ chart å±æ€§
            chart_image_attr = safe_get(chart_obj, 'chart_image')
            
            # ä½¿ç”¨æå–çš„ chart_image æˆ–ä» answer ä¸­æå–
            chart_data = None
            if chart_image_attr and isinstance(chart_image_attr, str) and len(chart_image_attr) > 0:
                chart_data = chart_image_attr
            else:
                # é™çº§ï¼šä» answer ä¸­æå–
                answer = safe_get(agent_response, 'answer', '')
                chart_path = extract_chart_path_from_answer(answer)
                if chart_path:
                    if not (chart_path.startswith('http://') or chart_path.startswith('https://')):
                        chart_data = load_chart_as_base64(chart_path)
                    else:
                        chart_data = chart_path
            
            # ğŸ›¡ï¸ å®‰å…¨è®¿é—®æ‰€æœ‰ chart å±æ€§
            chart_dict = {
                "chart_type": chart_type_value,
                "title": safe_get(chart_obj, 'title'),
                "x_field": safe_get(chart_obj, 'x_field'),
                "y_field": safe_get(chart_obj, 'y_field'),
                "chart_image": chart_image_attr if (chart_image_attr and isinstance(chart_image_attr, str) and len(chart_image_attr) > 0) else None,
                "chart_data": chart_data
            }
    
    # ğŸ›¡ï¸ ä½¿ç”¨ safe_get å®‰å…¨è®¿é—®æ‰€æœ‰å±æ€§
    answer = safe_get(agent_response, 'answer', '')
    sql = safe_get(agent_response, 'sql', '')
    success = safe_get(agent_response, 'success', False)
    data_obj = safe_get(agent_response, 'data')
    echarts_option = safe_get(agent_response, 'echarts_option')
    
    # æ„å»ºå“åº”
    response = {
        "answer": answer,
        "sources": sources,
        "reasoning": f"æ‰§è¡Œäº†SQLæŸ¥è¯¢ï¼š{sql}" if sql else "",
        "confidence": 0.9 if success else 0.5,
        "execution_time": execution_time,
        "sql": sql,
        "data": {
            "columns": safe_get(data_obj, 'columns', []) if data_obj else [],
            "rows": safe_get(data_obj, 'rows', []) if data_obj else [],
            "row_count": safe_get(data_obj, 'row_count', 0) if data_obj else 0
        } if data_obj else None,
        "chart": chart_dict,
        "echarts_option": echarts_option  # ğŸ›¡ï¸ å®‰å…¨è®¿é—® ECharts é…ç½®é€‰é¡¹
    }
    
    return response


async def run_agent_query(
    question: str,
    thread_id: str,
    database_url: Optional[str] = None,
    verbose: bool = False,
    enable_echarts: bool = True,  # é»˜è®¤å¯ç”¨ ECharts åŠŸèƒ½
    db_type: str = "postgresql"  # æ•°æ®åº“ç±»å‹
) -> Optional[VisualizationResponse]:
    """
    è¿è¡ŒAgentæŸ¥è¯¢

    Args:
        question: ç”¨æˆ·é—®é¢˜
        thread_id: çº¿ç¨‹IDï¼ˆç”¨äºä¼šè¯ç®¡ç†ï¼‰
        database_url: æ•°æ®åº“è¿æ¥URLï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨Agenté…ç½®ï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
        enable_echarts: æ˜¯å¦å¯ç”¨ ECharts å›¾è¡¨ç”ŸæˆåŠŸèƒ½ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        db_type: æ•°æ®åº“ç±»å‹ï¼ˆpostgresql, mysql, sqlite, xlsx, csvç­‰ï¼‰

    Returns:
        VisualizationResponse: Agentå“åº”ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
    """
    logger.info(
        "run_agent_query called",
        extra={
            "question_preview": question[:100],
            "thread_id": thread_id,
            "has_database_url": bool(database_url),
            "agent_available": _agent_available,
            "db_type": db_type,  # æ·»åŠ æ•°æ®åº“ç±»å‹åˆ°æ—¥å¿—
        },
    )
    if not _agent_available:
        logger.error("Agentæ¨¡å—ä¸å¯ç”¨ï¼Œç›´æ¥è¿”å› None")
        return None
    
    try:
        # -----------------------------------------------------
        # 1ï¸âƒ£ STEP 1: EARLY ROUTING DETECTION (Check raw URL before modification)
        # -----------------------------------------------------
        # å…ˆåˆ¤æ–­æ–‡ä»¶æ¨¡å¼ï¼Œåœ¨æ¸…ç† database_url ä¹‹å‰
        is_file_mode = False
        raw_url_for_check = database_url or ""
        
        if isinstance(raw_url_for_check, str):
            # Check for file extensions or local paths
            if (raw_url_for_check.endswith(('.xlsx', '.xls', '.csv')) or 
                raw_url_for_check.startswith(('/', './', 'file://', 'local://')) or
                '/uploads/' in raw_url_for_check or
                '/data/' in raw_url_for_check):
                is_file_mode = True
        
        logger.info(
            f"ğŸ”§ [Router] æ—©æœŸè·¯ç”±æ£€æµ‹: {'FILE MODE' if is_file_mode else 'DATABASE MODE'}",
            extra={
                "is_file_mode": is_file_mode,
                "raw_url_preview": raw_url_for_check[:100] if raw_url_for_check else None
            }
        )
        
        # -----------------------------------------------------
        # 2ï¸âƒ£ STEP 2: DATABASE URL SANITIZATION (Prevent Postgres Crash)
        # -----------------------------------------------------
        # å¦‚æœæ£€æµ‹åˆ°æ˜¯æ–‡ä»¶æ¨¡å¼ï¼Œæ¸…ç† database_urlï¼Œé˜²æ­¢ Postgres å·¥å…·å´©æºƒ
        original_url = None
        if is_file_mode:
            if database_url:
                logger.warning(
                    f"ğŸ”§ [Sanitization] æ£€æµ‹åˆ°æ–‡ä»¶è·¯å¾„ï¼Œæ¸…ç† database_url é…ç½®ä»¥é˜²æ­¢ Postgres å·¥å…·å´©æºƒ: {database_url[:100]}",
                    extra={
                        "database_url_preview": database_url[:100],
                        "reason": "file_mode_detected"
                    }
                )
            # è®¾ç½®ä¸º Noneï¼Œé˜²æ­¢ Postgres å·¥å…·å°è¯•è¿æ¥
            database_url = None
        elif database_url:
            # è¿™æ˜¯æœ‰æ•ˆçš„æ•°æ®åº“ URLï¼Œå¯ä»¥è®¾ç½®åˆ° config
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æ•°æ®åº“ URLï¼ˆä»¥æ•°æ®åº“åè®®å¼€å¤´ï¼‰
            is_valid_db_url = (
                database_url.startswith('postgresql://') or
                database_url.startswith('postgres://') or
                database_url.startswith('mysql://') or
                database_url.startswith('mysql+pymysql://') or
                database_url.startswith('sqlite://') or
                database_url.startswith('sqlite:///') or
                database_url.startswith('mssql://') or
                database_url.startswith('oracle://')
            )
            
            if is_valid_db_url:
                # è¿™æ˜¯æœ‰æ•ˆçš„æ•°æ®åº“ URLï¼Œå¯ä»¥è®¾ç½®
                from config import config
                original_url = getattr(config, "database_url", None)
                logger.info(
                    "Temporarily overriding Agent database_url",
                    extra={
                        "old_url_preview": str(original_url)[:80] if original_url else None,
                        "new_url_preview": str(database_url)[:80],
                    },
                )
                config.database_url = database_url
            else:
                # ä¸æ˜¯æœ‰æ•ˆçš„æ•°æ®åº“ URLï¼Œä¹Ÿä¸åƒæ˜¯æ–‡ä»¶è·¯å¾„ï¼Œè®°å½•è­¦å‘Š
                logger.warning(
                    f"âš ï¸ database_url å‚æ•°æ ¼å¼å¼‚å¸¸ï¼Œæ—¢ä¸æ˜¯æ–‡ä»¶è·¯å¾„ä¹Ÿä¸æ˜¯æœ‰æ•ˆçš„æ•°æ®åº“ URL: {database_url[:100]}",
                    extra={
                        "database_url_preview": database_url[:100],
                        "reason": "invalid_format"
                    }
                )
        
        # -----------------------------------------------------
        # 3ï¸âƒ£ STEP 3: CONSTRUCT SYSTEM INSTRUCTION (Based on Step 1)
        # -----------------------------------------------------
        
        system_instruction = ""
        
        if is_file_mode:
            # ğŸ“‚ FILE MODE: Aggressive Anti-SQL Prompt (æ ¸å¨æ…‘çº§åˆ«)
            system_instruction = (
                "ã€ğŸ›‘ SYSTEM ALERT: FILE MODE ACTIVEã€‘\n"
                "You are processing a local Excel/CSV file. \n"
                "CRITICAL RULES:\n"
                "1. The 'query' tool and SQL tools are DISCONNECTED and will cause a SYSTEM CRASH.\n"
                "2. You MUST ONLY use `analyze_dataframe` (for data analysis) or `inspect_file` (for schema).\n"
                "3. DO NOT attempt to list tables or schema. The data is already loaded in the dataframe tool.\n"
                "4. If you use 'query', the task will fail immediately.\n"
                "5. The SQL database connection is NOT available in file mode. All SQL tools (`query`, `list_tables`, `get_schema`, `query_database`, `execute_sql_safe`) are DISABLED and will return errors.\n"
                "6. You MUST use file-specific tools: `inspect_file` to see file structure, `analyze_dataframe` to query data."
            )
            logger.info("ğŸ”§ [Router] Detected FILE MODE. Locking SQL tools.")
        else:
            # ğŸ›¢ï¸ DATABASE MODE: Standard SQL behavior
            system_instruction = (
                "ã€SYSTEM MODE: DATABASE ANALYSISã€‘\n"
                "You are connected to a SQL database. \n"
                "RULES:\n"
                "1. Use `list_available_tables` or `list_tables` to see available tables first.\n"
                "2. Query the relevant tables using `execute_sql_safe` or `query_database` tools."
            )
            logger.info("ğŸ›¢ï¸ [Router] Detected DATABASE MODE.")
        
        # -----------------------------------------------------
        # 4ï¸âƒ£ STEP 4: INJECT & EXECUTE
        # -----------------------------------------------------
        # Inject the instruction into the question (Prompt Engineering)
        enhanced_question = f"{system_instruction}\n\nUser Question: {question}"
        logger.info("ğŸ“‹ [Prompt Injection] System instruction added to question.")
        
        # Log full system instruction for debugging
        if system_instruction:
            logger.debug(
                f"ğŸ“‹ [ç³»ç»ŸæŒ‡ä»¤æ³¨å…¥] å®Œæ•´ç³»ç»ŸæŒ‡ä»¤å†…å®¹",
                extra={
                    "system_instruction": system_instruction,
                    "instruction_length": len(system_instruction),
                    "is_file_mode": is_file_mode
                }
            )
        
        # -----------------------------------------------------
        
        # è¿è¡ŒAgent
        logger.info(
            "Starting underlying LangGraph Agent run",
            extra={"thread_id": thread_id, "enable_echarts": enable_echarts},
        )
        # æ ¹æ®ä½¿ç”¨çš„ Agent ç‰ˆæœ¬è°ƒç”¨ä¸åŒçš„å‡½æ•°
        if _use_new_agent:
            # æ–°ç‰ˆæœ¬ï¼šéœ€è¦ä¼ é€’ database_urlï¼Œè¿”å› Dict åŒ…å« response å­—æ®µ
            from config import config as agent_config
            
            # åœ¨æ–‡ä»¶æ¨¡å¼ä¸‹ï¼Œä¼ é€’åŸå§‹æ–‡ä»¶è·¯å¾„ï¼›åœ¨æ•°æ®åº“æ¨¡å¼ä¸‹ï¼Œä¼ é€’æ•°æ®åº“ URL
            if is_file_mode:
                # æ–‡ä»¶æ¨¡å¼ï¼šä¼ é€’åŸå§‹æ–‡ä»¶è·¯å¾„ï¼ˆraw_url_for_checkï¼‰
                effective_db_url = raw_url_for_check if raw_url_for_check else None
                logger.info(
                    f"ğŸ“‚ [æ–‡ä»¶æ¨¡å¼] ä¼ é€’æ–‡ä»¶è·¯å¾„ç»™ run_agent: {effective_db_url[:100] if effective_db_url else None}",
                    extra={"file_path": effective_db_url}
                )
            else:
                # æ•°æ®åº“æ¨¡å¼ï¼šä½¿ç”¨æ¸…ç†åçš„ database_url æˆ–é…ç½®ä¸­çš„é»˜è®¤å€¼
                effective_db_url = database_url or getattr(agent_config, "database_url", None)
                if not effective_db_url:
                    logger.error("æ— æ³•è·å–æ•°æ®åº“è¿æ¥URL")
                    return None
                logger.info(
                    f"ğŸ›¢ï¸ [æ•°æ®åº“æ¨¡å¼] ä¼ é€’æ•°æ®åº“ URL ç»™ run_agent",
                    extra={"database_url_preview": effective_db_url[:80] if effective_db_url else None}
                )
            
            result = await run_agent(
                question=enhanced_question,  # ğŸ”¥ ä½¿ç”¨å¢å¼ºåçš„é—®é¢˜ï¼ˆåŒ…å«æ™ºèƒ½è·¯ç”±æŒ‡ä»¤ï¼‰
                database_url=effective_db_url,  # æ–‡ä»¶æ¨¡å¼ä¸‹ä¼ é€’æ–‡ä»¶è·¯å¾„ï¼Œæ•°æ®åº“æ¨¡å¼ä¸‹ä¼ é€’æ•°æ®åº“ URL
                thread_id=thread_id,
                enable_echarts=enable_echarts,
                verbose=verbose,
                db_type=db_type  # ä¼ é€’æ•°æ®åº“ç±»å‹
            )
            # æ–°ç‰ˆæœ¬è¿”å› Dictï¼Œæå– response å­—æ®µï¼ˆVisualizationResponse å¯¹è±¡ï¼‰
            if result and isinstance(result, dict) and "response" in result:
                response = result["response"]
                # ğŸ”¥ ä¿®å¤ï¼šresponseå¯¹è±¡å·²ç»åŒ…å«metadataå­—æ®µï¼Œä¸éœ€è¦å†åŠ¨æ€æ·»åŠ 
                # metadataå·²ç»åœ¨run_agentä¸­è®¾ç½®åˆ°VisualizationResponseå¯¹è±¡ä¸­
            else:
                response = None
        else:
            # æ—§ç‰ˆæœ¬ï¼šä¸æ”¯æŒ enable_echarts å‚æ•°
            response = await run_agent(enhanced_question, thread_id, verbose=verbose, db_type=db_type)  # ä¼ é€’ db_type
        logger.info(
            "Underlying LangGraph Agent finished",
            extra={
                "success": getattr(response, "success", None) if response else None,
                "sql_preview": (response.sql or "")[:120] if getattr(response, "sql", None) else None,
                "row_count": getattr(getattr(response, "data", None), "row_count", None) if response else None,
                "error": getattr(response, "error", None) if response else None,
            },
        )
        
        # æ¢å¤åŸå§‹é…ç½®ï¼ˆåªæœ‰å½“ original_url è¢«è®¾ç½®æ—¶æ‰æ¢å¤ï¼‰
        if original_url is not None:
            from config import config
            logger.info("Restoring original Agent database_url")
            config.database_url = original_url
        
        return response
    
    except Exception as e:
        logger.error("AgentæŸ¥è¯¢å¤±è´¥", extra={"error": str(e)}, exc_info=True)
        return None


def is_agent_available() -> bool:
    """æ£€æŸ¥Agentæ˜¯å¦å¯ç”¨"""
    return _agent_available

