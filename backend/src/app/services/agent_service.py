"""
# [AGENT_SERVICE] Agenté›†æˆæœåŠ¡

## [HEADER]
**æ–‡ä»¶å**: agent_service.py
**èŒè´£**: é›†æˆLangGraph SQL Agentåˆ°åç«¯APIï¼Œæä¾›Agentå“åº”è½¬æ¢ã€å›¾è¡¨å¤„ç†ã€æ–‡ä»¶/æ•°æ®åº“æ™ºèƒ½è·¯ç”±å’Œå¹»è§‰æ£€æµ‹åŠŸèƒ½
**ä½œè€…**: Data Agent Team
**ç‰ˆæœ¬**: 1.0.0
**å˜æ›´è®°å½•**:
- v1.0.0 (2026-01-01): åˆå§‹ç‰ˆæœ¬ - Agenté›†æˆæœåŠ¡

## [INPUT]
- **question: str** - ç”¨æˆ·è‡ªç„¶è¯­è¨€é—®é¢˜
- **thread_id: str** - ä¼šè¯çº¿ç¨‹ID
- **database_url: Optional[str]** - æ•°æ®åº“è¿æ¥URLæˆ–æ–‡ä»¶è·¯å¾„ï¼ˆxlsx, csv, /uploads/, /data/ç­‰ï¼‰
- **verbose: bool** - æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡ºï¼ˆé»˜è®¤Falseï¼‰
- **enable_echarts: bool** - æ˜¯å¦å¯ç”¨EChartså›¾è¡¨ç”Ÿæˆï¼ˆé»˜è®¤Trueï¼‰
- **agent_response: VisualizationResponse** - Agentè¿”å›çš„å“åº”å¯¹è±¡
- **query_id: str** - æŸ¥è¯¢ID
- **tenant_id: str** - ç§Ÿæˆ·ID
- **original_query: str** - åŸå§‹æŸ¥è¯¢æ–‡æœ¬
- **processing_time_ms: int** - å¤„ç†æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
- **execution_time: float** - æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
- **chart_path: str** - å›¾è¡¨æ–‡ä»¶è·¯å¾„
- **answer: str** - Agentè¿”å›çš„answeræ–‡æœ¬

## [OUTPUT]
- **VisualizationResponse**: run_agent_queryè¿”å›Agentå“åº”å¯¹è±¡
  - success: bool - æŸ¥è¯¢æ˜¯å¦æˆåŠŸ
  - sql: str - ç”Ÿæˆçš„SQLè¯­å¥
  - answer: str - è‡ªç„¶è¯­è¨€è§£é‡Š
  - data: QueryResult - æŸ¥è¯¢ç»“æœæ•°æ®
  - chart: ChartConfig - å›¾è¡¨é…ç½®
  - echarts_option: Dict - EChartsé…ç½®é€‰é¡¹
  - metadata: Dict - å…ƒæ•°æ®ï¼ˆå¹»è§‰æ£€æµ‹æ ‡å¿—ç­‰ï¼‰
- **Dict[str, Any]**: convert_agent_response_to_query_responseè¿”å›QueryResponseV3æ ¼å¼
  - query_id, tenant_id, original_query
  - generated_sql, results, row_count
  - execution_result: {success, data_columns, chart_type, chart_title, chart_data, echarts_option}
  - explanation, processing_steps, validation_result
  - metadata: {hallucination_detected, hallucination_reason}
- **Dict[str, Any]**: convert_agent_response_to_chat_responseè¿”å›ChatQueryResponseæ ¼å¼
  - answer, sources, reasoning, confidence, execution_time
  - sql, data: {columns, rows, row_count}
  - chart: {chart_type, title, x_field, y_field, chart_image, chart_data}
  - echarts_option: Dict
- **Optional[str]**: extract_chart_path_from_answerè¿”å›æå–çš„å›¾è¡¨è·¯å¾„æˆ–URL
- **Optional[str]**: load_chart_as_base64è¿”å›Base64ç¼–ç çš„å›¾ç‰‡æ•°æ®ï¼ˆdata URIæ ¼å¼ï¼‰
- **bool**: is_agent_availableè¿”å›Agentæ˜¯å¦å¯ç”¨

**ä¸Šæ¸¸ä¾èµ–** (å·²è¯»å–æºç ):
- [Agent/models.py](../../Agent/models.py) - Agentæ•°æ®æ¨¡å‹ï¼ˆVisualizationResponseï¼‰
- [Agent/sql_agent.py](../../Agent/sql_agent.py) - æ—§ç‰ˆAgentï¼ˆrun_agentï¼‰
- [Agent/app/services/agent_service.py](../../Agent/app/services/agent_service.py) - æ–°ç‰ˆAgentï¼ˆæ”¯æŒenable_echartsï¼‰
- [Agent/config.py](../../Agent/config.py) - Agenté…ç½®

**ä¸‹æ¸¸ä¾èµ–** (éœ€è¦åå‘ç´¢å¼•åˆ†æ):
- [../api/v1/endpoints/query.py](../api/v1/endpoints/query.py) - æŸ¥è¯¢APIç«¯ç‚¹
- [../api/v1/endpoints/llm.py](../api/v1/endpoints/llm.py) - LLM APIç«¯ç‚¹
- [llm_service.py](./llm_service.py) - LLMæœåŠ¡ï¼ˆAgentæŸ¥è¯¢é›†æˆï¼‰

**è°ƒç”¨æ–¹**:
- è‡ªç„¶è¯­è¨€æŸ¥è¯¢API
- èŠå¤©å¯¹è¯ä¸­çš„æŸ¥è¯¢åŠŸèƒ½
- AgentæŸ¥è¯¢å¥åº·æ£€æŸ¥

## [STATE]
- **Agentè·¯å¾„ç®¡ç†**: åŠ¨æ€æ·»åŠ Agentç›®å½•åˆ°sys.path
- **ç‰ˆæœ¬å…¼å®¹**: æ”¯æŒæ–°æ—§ä¸¤ä¸ªç‰ˆæœ¬Agentï¼ˆ_use_new_agentæ ‡å¿—ï¼‰
  - æ–°ç‰ˆæœ¬: æ”¯æŒenable_echartså‚æ•°ï¼Œè¿”å›{response: VisualizationResponse}
  - æ—§ç‰ˆæœ¬: ä¸æ”¯æŒenable_echartsï¼Œç›´æ¥è¿”å›VisualizationResponse
- **é™çº§æœºåˆ¶**: Agentå¯¼å…¥å¤±è´¥æ—¶è®¾ç½®_agent_available=Falseï¼Œä¸é˜»å¡åº”ç”¨å¯åŠ¨
- **æ–‡ä»¶/æ•°æ®åº“è·¯ç”±**: æ—©æœŸæ£€æµ‹database_urlç±»å‹ï¼ˆæ–‡ä»¶æ‰©å±•åã€æœ¬åœ°è·¯å¾„ã€æ•°æ®åº“åè®®ï¼‰
- **å¹»è§‰æ£€æµ‹**: ä¸‰é“é˜²çº¿
  1. metadata.hallucination_detectedæ ‡å¿—
  2. answerå­—æ®µå‡æ•°æ®æ¨¡å¼äºŒæ¬¡æ£€æŸ¥ï¼ˆæ­£åˆ™åŒ¹é…æµ‹è¯•åï¼‰
  3. safe_getå®‰å…¨å±æ€§è®¿é—®ï¼ˆé˜²æ­¢Pydantic/å­—å…¸è®¿é—®é”™è¯¯ï¼‰
- **Promptæ³¨å…¥**: æ ¹æ®è·¯ç”±æ¨¡å¼æ³¨å…¥ä¸åŒçš„ç³»ç»ŸæŒ‡ä»¤ï¼ˆæ–‡ä»¶æ¨¡å¼ç¦ç”¨SQLå·¥å…·ï¼‰
- **é…ç½®ä¸´æ—¶è¦†ç›–**: è¿è¡Œæ—¶ä¸´æ—¶è¦†ç›–Agentçš„database_urlé…ç½®ï¼ˆæŸ¥è¯¢åæ¢å¤ï¼‰

## [SIDE-EFFECTS]
- **è·¯å¾„æ“ä½œ**: ä¿®æ”¹sys.pathæ’å…¥Agentç›®å½•
- **æ¨¡å—å¯¼å…¥**: åŠ¨æ€å¯¼å…¥Agentæ¨¡å—ï¼ˆsql_agent, models, config, agent_serviceï¼‰
- **æ–‡ä»¶I/O**: load_chart_as_base64è¯»å–å›¾è¡¨æ–‡ä»¶
- **Base64ç¼–ç **: å›¾è¡¨æ–‡ä»¶è½¬æ¢ä¸ºBase64 data URI
- **æ­£åˆ™åŒ¹é…**: æå–å›¾è¡¨è·¯å¾„ã€æ£€æµ‹å‡æ•°æ®æ¨¡å¼ã€æå–SQLè¡¨å
- **é…ç½®ä¿®æ”¹**: ä¸´æ—¶è¦†ç›–Agent config.database_urlï¼ˆæŸ¥è¯¢åæ¢å¤åŸå€¼ï¼‰
- **Promptå·¥ç¨‹**: æ³¨å…¥ç³»ç»ŸæŒ‡ä»¤åˆ°ç”¨æˆ·é—®é¢˜ï¼ˆenhanced_questionï¼‰
- **å¼‚å¸¸å¤„ç†**: å¤§é‡try-exceptä¿æŠ¤Agentè°ƒç”¨å’Œå±æ€§è®¿é—®
- **æ—¥å¿—è®°å½•**: è¯¦ç»†çš„è·¯ç”±ã€é…ç½®ã€æŸ¥è¯¢æ‰§è¡Œæ—¥å¿—
- **ç±»å‹è½¬æ¢**: Pydanticæ¨¡å‹è½¬å­—å…¸ï¼ˆmetadata, chartç­‰å¯¹è±¡çš„.dict()æˆ–.model_dump()ï¼‰
- **URLæ¸…ç†**: æ–‡ä»¶æ¨¡å¼ä¸‹æ¸…ç†database_urlé˜²æ­¢Postgreså·¥å…·å´©æºƒ

## [POS]
**è·¯å¾„**: backend/src/app/services/agent_service.py
**æ¨¡å—å±‚çº§**: Level 1 (æœåŠ¡å±‚)
**ä¾èµ–æ·±åº¦**: è·¨æ¨¡å—ä¾èµ–Agentç›®å½•ï¼ˆå¤–éƒ¨ä¾èµ–ï¼‰
"""
import sys
import os
import base64
import re
from pathlib import Path
from typing import Dict, Any, Optional
import asyncio
import logging

logger = logging.getLogger(__name__)

# å¯¼å…¥ç»Ÿè®¡åˆ†ææœåŠ¡
try:
    from .stats_analysis_service import get_stats_service
    _stats_analysis_available = True
    logger.info("âœ… ç»Ÿè®¡åˆ†ææœåŠ¡å·²åŠ è½½")
except ImportError as e:
    _stats_analysis_available = False
    get_stats_service = None
    logger.warning(f"âš ï¸ ç»Ÿè®¡åˆ†ææœåŠ¡å¯¼å…¥å¤±è´¥: {e}ï¼Œç»Ÿè®¡åŠŸèƒ½å°†ä¸å¯ç”¨")

# æ·»åŠ  Agent ç›®å½•åˆ° Python è·¯å¾„
# agent_service.py ä½äº backend/src/app/services/
# éœ€è¦å‘ä¸Šåˆ°é¡¹ç›®æ ¹ç›®å½•ï¼Œç„¶åè¿›å…¥ Agent ç›®å½•
_agent_path = Path(__file__).parent.parent.parent.parent.parent / "Agent"
if _agent_path.exists() and str(_agent_path) not in sys.path:
    sys.path.insert(0, str(_agent_path))

try:
    from models import VisualizationResponse
    # ä¼˜å…ˆä½¿ç”¨æ–°ç‰ˆæœ¬çš„ run_agentï¼ˆæ”¯æŒ enable_echartsï¼‰
    try:
        from app.services.agent.agent_service import run_agent
        _use_new_agent = True
        logger.info("ä½¿ç”¨æ–°ç‰ˆæœ¬ Agent (æ”¯æŒ enable_echarts)")
    except ImportError:
        # å›é€€åˆ°æ—§ç‰ˆæœ¬
        from sql_agent import run_agent as run_agent_legacy
        run_agent = run_agent_legacy
        _use_new_agent = False
        logger.info("ä½¿ç”¨æ—§ç‰ˆæœ¬ Agent (ä¸æ”¯æŒ enable_echarts)")
    _agent_available = True

    # ğŸ”¥ ã€QAé›†æˆã€‘å¯¼å…¥é”™è¯¯è¿½è¸ªæ¨¡å—
    try:
        from error_tracker import error_tracker, log_agent_error, ErrorCategory
        _error_tracking_available = True
        logger.info("âœ… é”™è¯¯è¿½è¸ªæ¨¡å—å·²åŠ è½½")
    except ImportError as track_err:
        _error_tracking_available = False
        error_tracker = None
        logger.warning(f"âš ï¸ é”™è¯¯è¿½è¸ªæ¨¡å—å¯¼å…¥å¤±è´¥: {track_err}ï¼Œé”™è¯¯è¿½è¸ªåŠŸèƒ½å°†ä¸å¯ç”¨")
except ImportError as e:
    logger.warning(f"Agentæ¨¡å—å¯¼å…¥å¤±è´¥: {e}ï¼ŒAgentåŠŸèƒ½å°†ä¸å¯ç”¨")
    _agent_available = False
    run_agent = None
    _use_new_agent = False
    VisualizationResponse = None


def extract_chart_path_from_answer(answer: str) -> Optional[str]:
    """
    ä»answeræ–‡æœ¬ä¸­æå–å›¾è¡¨è·¯å¾„
    
    Args:
        answer: Agentè¿”å›çš„answeræ–‡æœ¬
    
    Returns:
        å›¾è¡¨è·¯å¾„ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
    """
    if not answer:
        return None
    
    # åŒ¹é…å›¾è¡¨è·¯å¾„æ¨¡å¼ï¼šå›¾è¡¨å·²ä¿å­˜: <path> æˆ– å›¾è¡¨é“¾æ¥: <url>
    patterns = [
        r'å›¾è¡¨å·²ä¿å­˜:\s*([^\n]+)',
        r'å›¾è¡¨é“¾æ¥:\s*([^\n]+)',
        r'ğŸ“Š\s*å›¾è¡¨å·²ä¿å­˜:\s*([^\n]+)',
        r'ğŸ“Š\s*å›¾è¡¨é“¾æ¥:\s*([^\n]+)',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, answer)
        if match:
            path = match.group(1).strip()
            # å¦‚æœæ˜¯URLï¼Œç›´æ¥è¿”å›
            if path.startswith('http://') or path.startswith('https://'):
                return path
            # å¦‚æœæ˜¯æœ¬åœ°è·¯å¾„ï¼Œè¿”å›ç»å¯¹è·¯å¾„
            if os.path.exists(path):
                return os.path.abspath(path)
            # å°è¯•ç›¸å¯¹äºAgentç›®å½•çš„è·¯å¾„
            agent_charts_dir = _agent_path / "charts"
            if agent_charts_dir.exists():
                chart_path = agent_charts_dir / os.path.basename(path)
                if chart_path.exists():
                    return str(chart_path.absolute())
    
    return None


def load_chart_as_base64(chart_path: str) -> Optional[str]:
    """
    å°†å›¾è¡¨æ–‡ä»¶åŠ è½½ä¸ºBase64ç¼–ç 
    
    Args:
        chart_path: å›¾è¡¨æ–‡ä»¶è·¯å¾„
    
    Returns:
        Base64ç¼–ç çš„å›¾ç‰‡æ•°æ®ï¼ˆdata URIæ ¼å¼ï¼‰ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
    """
    try:
        if not os.path.exists(chart_path):
            logger.warning(f"å›¾è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {chart_path}")
            return None
        
        # è¯»å–æ–‡ä»¶
        with open(chart_path, 'rb') as f:
            image_data = f.read()
        
        # ç¡®å®šMIMEç±»å‹
        ext = os.path.splitext(chart_path)[1].lower()
        mime_types = {
            '.png': 'image/png',
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.gif': 'image/gif',
            '.svg': 'image/svg+xml',
            '.html': 'text/html'
        }
        mime_type = mime_types.get(ext, 'image/png')
        
        # è½¬æ¢ä¸ºBase64
        base64_data = base64.b64encode(image_data).decode('utf-8')
        return f"data:{mime_type};base64,{base64_data}"
    
    except Exception as e:
        logger.error(f"åŠ è½½å›¾è¡¨æ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
        return None


def _build_processing_steps(
    success: bool,
    sql: str,
    results: list,
    row_count: int,
    data_obj: Any,
    echarts_option: Any,
    chart_data: Any,
    chart_obj: Any,
    processing_time_ms: int,
    answer: str = ""
) -> list:
    """
    æ„å»ºåŒ…å«SQLã€è¡¨æ ¼ã€å›¾è¡¨ã€æ•°æ®åˆ†ææ–‡æœ¬çš„å¤„ç†æ­¥éª¤åˆ—è¡¨

    Args:
        success: æŸ¥è¯¢æ˜¯å¦æˆåŠŸ
        sql: SQLè¯­å¥
        results: æŸ¥è¯¢ç»“æœåˆ—è¡¨
        row_count: è¡Œæ•°
        data_obj: æ•°æ®å¯¹è±¡
        echarts_option: EChartsé…ç½®
        chart_data: å›¾è¡¨æ•°æ®
        chart_obj: å›¾è¡¨å¯¹è±¡
        processing_time_ms: å¤„ç†æ—¶é—´
        answer: AIæ•°æ®åˆ†ææ–‡æœ¬ï¼ˆç”¨äºæ­¥éª¤8ï¼‰

    Returns:
        list: å¤„ç†æ­¥éª¤åˆ—è¡¨
    """
    if not success:
        return [{
            "step": 1,
            "title": "æŸ¥è¯¢å¤„ç†å¤±è´¥",
            "description": "æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ï¼Œè¯·æ£€æŸ¥æ•°æ®æºé…ç½®æˆ–é‡æ–°æé—®",
            "status": "error"
        }]

    # è®¡ç®—å„æ­¥éª¤çš„å¤§è‡´è€—æ—¶ï¼ˆä¼°ç®—ï¼‰
    base_time = processing_time_ms / 8  # ç°åœ¨æœ‰8ä¸ªæ­¥éª¤

    # æ„å»ºè¡¨æ ¼æ•°æ®ï¼ˆç”¨äºæ­¥éª¤6ï¼‰
    table_data = None
    if data_obj:
        columns = safe_get_attr(data_obj, 'columns', [])
        rows = safe_get_attr(data_obj, 'rows', [])
        if columns and rows:
            table_data = {
                "columns": columns,
                "rows": rows[:50],  # é™åˆ¶æœ€å¤š50è¡Œ
                "row_count": row_count
            }

    # æ„å»ºå›¾è¡¨æ•°æ®ï¼ˆç”¨äºæ­¥éª¤7ï¼‰
    chart_step_data = None
    if echarts_option:
        chart_step_data = {
            "echarts_option": echarts_option,
            "chart_type": _extract_chart_type(chart_obj)
        }
    elif chart_data:
        chart_step_data = {
            "chart_image": chart_data,
            "chart_type": _extract_chart_type(chart_obj)
        }

    steps = [
        {
            "step": 1,
            "title": "ç†è§£ç”¨æˆ·é—®é¢˜",
            "description": "åˆ†æç”¨æˆ·æŸ¥è¯¢æ„å›¾ï¼Œè¯†åˆ«æ•°æ®éœ€æ±‚",
            "status": "completed",
            "duration": int(base_time)
        },
        {
            "step": 2,
            "title": "è·å–æ•°æ®åº“Schema",
            "description": f"æˆåŠŸåŠ è½½ {safe_get_attr(data_obj, 'row_count', 0)} è¡Œæ•°æ®",
            "status": "completed",
            "duration": int(base_time)
        },
        {
            "step": 3,
            "title": "æ„å»ºAI Prompt",
            "description": "æ ¹æ®é—®é¢˜å’ŒSchemaç”ŸæˆæŸ¥è¯¢æŒ‡ä»¤",
            "status": "completed",
            "duration": int(base_time)
        },
        {
            "step": 4,
            "title": "AIç”ŸæˆSQLè¯­å¥",
            "description": "AIå·²ç”Ÿæˆæ•°æ®åº“æŸ¥è¯¢è¯­å¥",
            "status": "completed",
            "duration": int(base_time * 2),
            "content_type": "sql",
            "content_data": {
                "sql": sql
            } if sql else None
        },
        {
            "step": 5,
            "title": "éªŒè¯SQLè¯­å¥",
            "description": "æ£€æŸ¥SQLè¯­æ³•å’Œå®‰å…¨æ€§",
            "status": "completed",
            "duration": int(base_time * 0.5)
        },
        {
            "step": 6,
            "title": "æ‰§è¡ŒSQLæŸ¥è¯¢",
            "description": f"æŸ¥è¯¢è¿”å› {row_count} è¡Œç»“æœ",
            "status": "completed",
            "duration": int(base_time * 1.5),
            "content_type": "table",
            "content_data": {
                "table": table_data
            } if table_data else None
        },
    ]

    # æ·»åŠ æ­¥éª¤7ï¼ˆå›¾è¡¨ç”Ÿæˆï¼‰
    if chart_step_data:
        steps.append({
            "step": 7,
            "title": "ç”Ÿæˆæ•°æ®å¯è§†åŒ–",
            "description": f"åˆ›å»º {chart_step_data.get('chart_type', 'å›¾è¡¨')} å±•ç¤ºåˆ†æç»“æœ",
            "status": "completed",
            "duration": int(base_time * 2),
            "content_type": "chart",
            "content_data": {
                "chart": chart_step_data
            }
        })

    # æ·»åŠ æ­¥éª¤8ï¼ˆæ•°æ®åˆ†ææ€»ç»“ï¼‰
    if answer and answer.strip():
        steps.append({
            "step": 8,
            "title": "æ•°æ®åˆ†ææ€»ç»“",
            "description": "AIå¯¹æŸ¥è¯¢ç»“æœçš„åˆ†æå’Œè§£è¯»",
            "status": "completed",
            "duration": int(base_time * 1.5),
            "content_type": "text",
            "content_data": {
                "text": answer.strip()
            }
        })

    return steps


def _extract_chart_type(chart_obj: Any) -> str:
    """å®‰å…¨æå–å›¾è¡¨ç±»å‹"""
    if not chart_obj:
        return "å›¾è¡¨"

    # å°è¯•ä»chart_objä¸­æå–ç±»å‹
    if hasattr(chart_obj, 'chart_type'):
        chart_type = getattr(chart_obj, 'chart_type')
        if hasattr(chart_type, 'value'):
            return str(chart_type.value)
        return str(chart_type)

    if isinstance(chart_obj, dict):
        return chart_obj.get('chart_type', 'å›¾è¡¨')

    return "å›¾è¡¨"


def safe_get_attr(obj: Any, attr: str, default: Any = None) -> Any:
    """å®‰å…¨è·å–å¯¹è±¡å±æ€§"""
    try:
        if hasattr(obj, attr):
            return getattr(obj, attr)
        if isinstance(obj, dict):
            return obj.get(attr, default)
        return default
    except Exception:
        return default


def _format_stats_analysis(stats: Dict[str, Any]) -> str:
    """
    å°†ç»Ÿè®¡åˆ†æç»“æœæ ¼å¼åŒ–ä¸ºå…³é”®æ•°æ®ç‚¹æ‘˜è¦ï¼ˆéå›ºå®šæ¨¡æ¿ï¼‰

    å…³é”®è®¾è®¡åŸåˆ™ï¼š
    1. åªæä¾›"å€¼å¾—æŠ¥å‘Š"çš„å…³é”®æ•°æ®ç‚¹
    2. æ ¹æ®æ•°æ®ç‰¹å¾åŠ¨æ€é€‰æ‹©æŠ¥å‘Šå†…å®¹
    3. é¿å…æœºæ¢°å¼åˆ—å‡ºæ‰€æœ‰ç»Ÿè®¡æŒ‡æ ‡
    4. è®© LLM åŸºäºè¿™äº›å…³é”®ç‚¹ç”ŸæˆåŠ¨æ€åˆ†æ

    Args:
        stats: ç»Ÿè®¡åˆ†æç»“æœå­—å…¸

    Returns:
        æ ¼å¼åŒ–åçš„å…³é”®æ•°æ®ç‚¹æ‘˜è¦
    """
    if not stats:
        return ""

    key_points = []

    # 1. åŸºç¡€ä¿¡æ¯ï¼ˆå§‹ç»ˆæä¾›ï¼‰
    basic_stats = stats.get('basic_stats', {})
    if basic_stats:
        count = basic_stats.get('count', 0)
        total = basic_stats.get('total', 0)
        mean = basic_stats.get('mean', 0)
        key_points.append(f"æ•°æ®é‡: {count} æ¡, æ€»è®¡: {total}, å¹³å‡: {mean}")

    # 2. è¶‹åŠ¿åˆ†æï¼ˆä»…å½“æœ‰æ˜æ˜¾è¶‹åŠ¿æ—¶æŠ¥å‘Šï¼‰
    trend = stats.get('trend_analysis', {})
    if trend and 'error' not in trend:
        total_growth = trend.get('total_growth_percent', 0)
        volatility = trend.get('volatility', 0)
        trend_dir = trend.get('trend_direction', '')

        # åªæœ‰å½“å˜åŒ–å¹…åº¦ > 5% æˆ–æ³¢åŠ¨æ€§ > 10% æ—¶æ‰æŠ¥å‘Šè¶‹åŠ¿
        if abs(total_growth) > 5 or volatility > 10:
            key_points.append(f"è¶‹åŠ¿: {trend_dir} {total_growth:+.1f}%, æ³¢åŠ¨æ€§: {volatility:.1f}%")

    # 3. å¼‚å¸¸å€¼ï¼ˆä»…å½“å­˜åœ¨å¼‚å¸¸å€¼æ—¶æŠ¥å‘Šï¼‰
    extremes = stats.get('extremes', {})
    if extremes:
        outlier_count = extremes.get('outliers_count', 0)
        if outlier_count > 0:
            key_points.append(f"æ£€æµ‹åˆ° {outlier_count} ä¸ªå¼‚å¸¸å€¼")

    # 4. æå€¼ï¼ˆä»…å½“æå€¼ä¸å¹³å‡å€¼å·®å¼‚è¾ƒå¤§æ—¶æŠ¥å‘Šï¼‰
    if extremes and basic_stats:
        max_val = extremes.get('max_value')
        min_val = extremes.get('min_value')
        mean_val = basic_stats.get('mean', 0)

        # è®¡ç®—æå€¼ä¸å¹³å‡å€¼çš„åç¦»ç¨‹åº¦
        if max_val and mean_val > 0:
            max_deviation = abs(max_val - mean_val) / mean_val * 100
            if max_deviation > 30:  # æœ€å¤§å€¼åç¦»å¹³å‡å€¼è¶…è¿‡30%
                key_points.append(f"å³°å€¼æ˜¾è‘—: {max_val} (åç¦»å¹³å‡ {max_deviation:.0f}%)")

        if min_val and mean_val > 0:
            min_deviation = abs(min_val - mean_val) / mean_val * 100
            if min_deviation > 30:  # æœ€å°å€¼åç¦»å¹³å‡å€¼è¶…è¿‡30%
                key_points.append(f"è°·å€¼æ˜¾è‘—: {min_val} (åç¦»å¹³å‡ {min_deviation:.0f}%)")

    # 5. æ•°æ®ç¨³å®šæ€§ï¼ˆä»…å½“å˜å¼‚ç³»æ•°è¾ƒé«˜æ—¶æŠ¥å‘Šï¼‰
    if basic_stats:
        cv_percent = basic_stats.get('cv_percent', 0)
        if cv_percent > 20:  # å˜å¼‚ç³»æ•°è¶…è¿‡20%è¡¨ç¤ºæ•°æ®ä¸ç¨³å®š
            key_points.append(f"æ•°æ®æ³¢åŠ¨è¾ƒå¤§ (å˜å¼‚ç³»æ•°: {cv_percent:.1f}%)")

    # å¦‚æœæ²¡æœ‰å…³é”®æ•°æ®ç‚¹ï¼Œæä¾›æœ€åŸºæœ¬çš„ä¿¡æ¯
    if not key_points:
        count = basic_stats.get('count', 'N/A')
        total = basic_stats.get('total', 'N/A')
        mean = basic_stats.get('mean', 'N/A')
        return f"\nã€ç»Ÿè®¡ã€‘ {count} æ¡æ•°æ®, æ€»è®¡ {total}, å¹³å‡ {mean}" if basic_stats else ""

    return "\nã€å…³é”®æ•°æ®ç‚¹ã€‘\n" + "\n".join(f"â€¢ {p}" for p in key_points)


def convert_agent_response_to_query_response(
    agent_response: VisualizationResponse,
    query_id: str,
    tenant_id: str,
    original_query: str,
    processing_time_ms: int = 0
) -> Dict[str, Any]:
    """
    å°†Agentçš„VisualizationResponseè½¬æ¢ä¸ºåç«¯QueryResponseV3æ ¼å¼
    
    Args:
        agent_response: Agentè¿”å›çš„å¯è§†åŒ–å“åº”
        query_id: æŸ¥è¯¢ID
        tenant_id: ç§Ÿæˆ·ID
        original_query: åŸå§‹æŸ¥è¯¢
        processing_time_ms: å¤„ç†æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    
    Returns:
        Dict: ç¬¦åˆQueryResponseV3æ ¼å¼çš„å­—å…¸
    """
    # ğŸ›¡ï¸ é€šç”¨å®‰å…¨å±æ€§è®¿é—®è¾…åŠ©å‡½æ•° - æ”¯æŒ Pydantic æ¨¡å‹ã€å­—å…¸å’Œæ™®é€šå¯¹è±¡
    def safe_get(obj, attr, default=None):
        """
        å®‰å…¨è·å–å¯¹è±¡å±æ€§ï¼Œæ”¯æŒå¤šç§æ•°æ®ç±»å‹
        
        Args:
            obj: å¯¹è±¡ï¼ˆå¯ä»¥æ˜¯ Pydantic æ¨¡å‹ã€å­—å…¸æˆ–æ™®é€šå¯¹è±¡ï¼‰
            attr: å±æ€§å
            default: é»˜è®¤å€¼
        
        Returns:
            å±æ€§å€¼ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›é»˜è®¤å€¼
        """
        try:
            # Case 1: å­—å…¸ç±»å‹
            if isinstance(obj, dict):
                return obj.get(attr, default)
            
            # Case 2: Pydantic æ¨¡å‹æˆ–å…¶ä»–å¯¹è±¡
            # æ–¹æ³•1: ç›´æ¥å±æ€§è®¿é—®
            if hasattr(obj, attr):
                value = getattr(obj, attr, default)
                # å¦‚æœå€¼æ˜¯ Noneï¼Œä¹Ÿè¿”å›é»˜è®¤å€¼ï¼ˆå¯é€‰ï¼Œæ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
                return value if value is not None else default
            
            # æ–¹æ³•2: å°è¯•ä½¿ç”¨ Pydantic çš„ .dict() æˆ– .model_dump()
            try:
                if hasattr(obj, 'dict'):
                    obj_dict = obj.dict()
                    return obj_dict.get(attr, default)
                elif hasattr(obj, 'model_dump'):
                    obj_dict = obj.model_dump()
                    return obj_dict.get(attr, default)
            except (AttributeError, TypeError):
                pass
            
            # æ–¹æ³•3: å°è¯• __dict__ å±æ€§
            try:
                if hasattr(obj, '__dict__'):
                    return obj.__dict__.get(attr, default)
            except (AttributeError, TypeError):
                pass
            
            return default
        except Exception as e:
            logger.debug(f"safe_get è®¿é—®å±æ€§ {attr} æ—¶å‡ºé”™: {e}")
            return default
    
    # å°†QueryResultè½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨æ ¼å¼
    results = []
    data_obj = safe_get(agent_response, 'data')
    if data_obj:
        rows = safe_get(data_obj, 'rows', [])
        columns = safe_get(data_obj, 'columns', [])
        if rows:
            for row in rows:
                row_dict = {}
                for i, col in enumerate(columns):
                    if i < len(row):
                        row_dict[col] = row[i]
                results.append(row_dict)
    
    # ğŸ›¡ï¸ å¥å£®çš„å›¾è¡¨å›¾ç‰‡æå– - æ”¯æŒ Pydantic æ¨¡å‹ã€å­—å…¸å’Œæ™®é€šå¯¹è±¡
    chart_data = None
    chart_obj = safe_get(agent_response, 'chart')
    if chart_obj:
        # ä½¿ç”¨ safe_get è·å– chart_image
        chart_data = safe_get(chart_obj, 'chart_image')
    
    # é™çº§ï¼šå¦‚æœ chart_image ä¸å­˜åœ¨ï¼Œå°è¯•ä» answer ä¸­æå–ï¼ˆå‘åå…¼å®¹ï¼‰
    if not chart_data:
        answer = safe_get(agent_response, 'answer', '')
        chart_path = extract_chart_path_from_answer(answer)
        if chart_path:
            # å¦‚æœæ˜¯æœ¬åœ°æ–‡ä»¶ï¼Œè½¬æ¢ä¸ºBase64
            if not (chart_path.startswith('http://') or chart_path.startswith('https://')):
                chart_data = load_chart_as_base64(chart_path)
            else:
                # å¦‚æœæ˜¯URLï¼Œç›´æ¥ä½¿ç”¨
                chart_data = chart_path
    
    # æ„å»ºå“åº”æ•°æ®
    execution_result = None
    success = safe_get(agent_response, 'success', False)
    if success:
        # ğŸ›¡ï¸ å®‰å…¨è®¿é—®æ‰€æœ‰ chart å±æ€§
        chart_type = None
        chart_title = None
        chart_obj = safe_get(agent_response, 'chart')
        if chart_obj:
            chart_type_obj = safe_get(chart_obj, 'chart_type')
            if chart_type_obj:
                if hasattr(chart_type_obj, 'value'):
                    chart_type = chart_type_obj.value
                else:
                    chart_type = str(chart_type_obj)
            chart_title = safe_get(chart_obj, 'title')
        
        # ğŸ›¡ï¸ å®‰å…¨è®¿é—® data å±æ€§
        data_obj = safe_get(agent_response, 'data')
        data_columns = []
        if data_obj:
            data_columns = safe_get(data_obj, 'columns', [])
        
        execution_result = {
            "success": success,
            "data_columns": data_columns,
            "chart_type": chart_type,
            "chart_title": chart_title,
            "chart_data": chart_data,  # æ·»åŠ Base64ç¼–ç çš„å›¾è¡¨æ•°æ®æˆ–URL
            "echarts_option": safe_get(agent_response, 'echarts_option')  # ğŸ›¡ï¸ å®‰å…¨è®¿é—® ECharts é…ç½®é€‰é¡¹
        }
    
    # ğŸ”´ ç¬¬ä¸‰é“é˜²çº¿ï¼šæå–metadataï¼ˆå¦‚æœå­˜åœ¨ï¼‰- ä½¿ç”¨ safe_get
    metadata = safe_get(agent_response, 'metadata')
    if metadata and not isinstance(metadata, dict):
        # å¦‚æœæ˜¯ Pydantic æ¨¡å‹ï¼Œè½¬æ¢ä¸ºå­—å…¸
        try:
            if hasattr(metadata, 'dict'):
                metadata = metadata.dict()
            elif hasattr(metadata, 'model_dump'):
                metadata = metadata.model_dump()
            elif hasattr(metadata, '__dict__'):
                metadata = metadata.__dict__
        except Exception:
            metadata = None
    
    # ğŸ”¥ ä¼˜å…ˆçº§1å’Œ4ï¼šæ£€æŸ¥å¹»è§‰æ£€æµ‹æ ‡å¿—å’Œè¿›è¡ŒäºŒæ¬¡æ£€æŸ¥
    explanation = safe_get(agent_response, 'answer', '')
    hallucination_detected_in_metadata = False
    hallucination_reason_in_metadata = None
    
    # æ£€æŸ¥metadataä¸­çš„å¹»è§‰æ ‡å¿—
    if metadata and isinstance(metadata, dict):
        hallucination_detected_in_metadata = metadata.get("hallucination_detected", False)
        hallucination_reason_in_metadata = metadata.get("hallucination_reason", None)
    
    # å¦‚æœmetadataä¸­æ£€æµ‹åˆ°å¹»è§‰ï¼Œä½¿ç”¨é”™è¯¯æ¶ˆæ¯æ›¿æ¢explanation
    if hallucination_detected_in_metadata:
        error_message = (
            "âš ï¸ **æ•°æ®éªŒè¯å¤±è´¥**\n\n"
            "ç³»ç»Ÿæ£€æµ‹åˆ°AIåŠ©æ‰‹å¯èƒ½è¿”å›äº†ä¸å‡†ç¡®çš„æ•°æ®ã€‚\n\n"
        )
        if hallucination_reason_in_metadata:
            if isinstance(hallucination_reason_in_metadata, list):
                error_message += f"**æ£€æµ‹è¯¦æƒ…ï¼š** {', '.join(hallucination_reason_in_metadata)}\n\n"
            else:
                error_message += f"**æ£€æµ‹è¯¦æƒ…ï¼š** {hallucination_reason_in_metadata}\n\n"
        error_message += (
            "**å¯èƒ½çš„åŸå› ï¼š**\n"
            "- AIæœªèƒ½æ­£ç¡®è°ƒç”¨æ•°æ®æŸ¥è¯¢å·¥å…·\n"
            "- å·¥å…·è¿”å›çš„æ•°æ®ä¸ºç©ºæˆ–é”™è¯¯\n"
            "- AIç”Ÿæˆäº†æµ‹è¯•æ•°æ®è€ŒéçœŸå®æ•°æ®\n\n"
            "**å»ºè®®æ“ä½œï¼š**\n"
            "1. è¯·æ£€æŸ¥æ•°æ®æºæ˜¯å¦æ­£ç¡®é…ç½®\n"
            "2. ç¡®è®¤æ•°æ®æºå·²æˆåŠŸåŠ è½½ï¼ˆçŠ¶æ€æ˜¾ç¤ºä¸ºâœ“ï¼‰\n"
            "3. é‡æ–°æé—®æ‚¨çš„é—®é¢˜\n"
        )
        explanation = error_message
        # æ¸…é™¤å¯èƒ½åŒ…å«å‡æ•°æ®çš„ç»“æœ
        results = []
        logger.error(f"ğŸš« [å“åº”è½¬æ¢] æ£€æµ‹åˆ°metadataä¸­çš„å¹»è§‰æ ‡å¿—ï¼Œå·²æ‹¦æˆªå¹¶æ›¿æ¢explanation")
    
    # ğŸ”¥ ä¼˜å…ˆçº§4ï¼šäºŒæ¬¡æ£€æŸ¥ - å³ä½¿metadataä¸­æ²¡æœ‰æ ‡å¿—ï¼Œä¹Ÿè¦æ£€æŸ¥answerå­—æ®µæ˜¯å¦åŒ…å«å‡æ•°æ®
    if not hallucination_detected_in_metadata and explanation:
        import re
        # æ£€æµ‹å¸¸è§çš„å‡æ•°æ®æ¨¡å¼
        fake_data_patterns = [
            r"å¼ ä¸‰|æå››|ç‹äº”|èµµå…­",  # å¸¸è§çš„ä¸­æ–‡æµ‹è¯•åå­—
            r"ç”¨æˆ·[1-9]\d*",  # ç”¨æˆ·1ã€ç”¨æˆ·2ç­‰
            r"Alice|Bob|Charlie|Diana|Eve",  # å¸¸è§çš„è‹±æ–‡æµ‹è¯•åå­—
        ]
        detected_patterns = []
        for pattern in fake_data_patterns:
            if re.search(pattern, explanation):
                detected_patterns.append(pattern)

        # å¦‚æœæ£€æµ‹åˆ°å¤šä¸ªå‡æ•°æ®æ¨¡å¼ï¼Œå¾ˆå¯èƒ½æ˜¯å‡æ•°æ®
        if len(detected_patterns) >= 2:
            error_message = (
                "âš ï¸ **æ•°æ®éªŒè¯å¤±è´¥**\n\n"
                "ç³»ç»Ÿæ£€æµ‹åˆ°å›ç­”ä¸­å¯èƒ½åŒ…å«æµ‹è¯•æ•°æ®è€ŒéçœŸå®æ•°æ®ã€‚\n\n"
                "**æ£€æµ‹åˆ°çš„å¯ç–‘æ¨¡å¼ï¼š**\n"
                f"- {', '.join(detected_patterns)}\n\n"
                "**å¯èƒ½çš„åŸå› ï¼š**\n"
                "- AIæœªèƒ½æ­£ç¡®è°ƒç”¨æ•°æ®æŸ¥è¯¢å·¥å…·\n"
                "- å·¥å…·è¿”å›çš„æ•°æ®ä¸ºç©ºæˆ–é”™è¯¯\n"
                "- AIç”Ÿæˆäº†æµ‹è¯•æ•°æ®è€ŒéçœŸå®æ•°æ®\n\n"
                "**å»ºè®®æ“ä½œï¼š**\n"
                "1. è¯·æ£€æŸ¥æ•°æ®æºæ˜¯å¦æ­£ç¡®é…ç½®\n"
                "2. ç¡®è®¤æ•°æ®æºå·²æˆåŠŸåŠ è½½ï¼ˆçŠ¶æ€æ˜¾ç¤ºä¸ºâœ“ï¼‰\n"
                "3. é‡æ–°æé—®æ‚¨çš„é—®é¢˜\n"
            )
            explanation = error_message
            results = []
            logger.error(f"ğŸš« [å“åº”è½¬æ¢] äºŒæ¬¡æ£€æŸ¥æ£€æµ‹åˆ°å‡æ•°æ®æ¨¡å¼ï¼Œå·²æ‹¦æˆªå¹¶æ›¿æ¢explanation")

    # ğŸ›¡ï¸ğŸ›¡ï¸ğŸ›¡ï¸ å®‰å…¨ä¼˜å…ˆçº§0ï¼šå±é™© SQL æ£€æŸ¥ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œåœ¨å‡æ•°æ®æ£€æŸ¥ä¹‹å‰ï¼‰
    # æ£€æŸ¥ explanation ä¸­æ˜¯å¦åŒ…å«å±é™©çš„ DML/DDL æ“ä½œ
    if explanation:
        import re
        explanation_upper = explanation.upper()

        # å±é™©å…³é”®å­—é»‘åå•
        dangerous_keywords = [
            (r'\bUPDATE\b', 'UPDATE'),
            (r'\bDELETE\b', 'DELETE'),
            (r'\bINSERT\b', 'INSERT'),
            (r'\bDROP\b', 'DROP'),
            (r'\bTRUNCATE\b', 'TRUNCATE'),
            (r'\bALTER\b', 'ALTER'),
            (r'\bCREATE\s+TABLE\b', 'CREATE TABLE'),
            (r'\bGRANT\b', 'GRANT'),
            (r'\bREVOKE\b', 'REVOKE'),
        ]

        detected_dangerous = []
        for pattern, keyword in dangerous_keywords:
            if re.search(pattern, explanation_upper):
                detected_dangerous.append(keyword)

        # æ£€æµ‹åˆ°å±é™© SQL - æ›¿æ¢ä¸ºæ‹’ç»æ¶ˆæ¯
        if detected_dangerous:
            security_message = (
                "â›” **æ“ä½œè¢«æ‹’ç»**\n\n"
                "æ‚¨è¯·æ±‚çš„æ“ä½œæ¶‰åŠæ•°æ®ä¿®æ”¹ï¼Œè¿™è¿åäº†å®‰å…¨ç­–ç•¥ã€‚\n\n"
                "ğŸ›¡ï¸ ä½œä¸ºä¸€ä¸ªåªè¯»æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œæˆ‘åªèƒ½ï¼š\n"
                "- âœ… æŸ¥è¯¢å’Œå±•ç¤ºæ•°æ®ï¼ˆSELECTï¼‰\n"
                "- âœ… åˆ†ææ•°æ®è¶‹åŠ¿å’Œæ¨¡å¼\n"
                "- âœ… ç”Ÿæˆæ•°æ®å¯è§†åŒ–å›¾è¡¨\n"
                "- âŒ ä¸èƒ½ä¿®æ”¹ã€åˆ é™¤æˆ–æ–°å¢æ•°æ®\n\n"
                "å¦‚æœæ‚¨éœ€è¦ä¿®æ”¹æ•°æ®ï¼Œè¯·è”ç³»æ•°æ®åº“ç®¡ç†å‘˜æˆ–ä½¿ç”¨ä¸“é—¨çš„ç®¡ç†å·¥å…·ã€‚"
            )
            explanation = security_message
            results = []  # æ¸…é™¤å¯èƒ½åŒ…å«å±é™©æ“ä½œçš„ç»“æœ
            logger.error(
                f"ğŸš« [å“åº”å®‰å…¨æ£€æŸ¥] æ£€æµ‹åˆ°å±é™©SQLå…³é”®å­—å¹¶å·²æ‹¦æˆª: {', '.join(detected_dangerous)}",
                extra={
                    "detected_keywords": detected_dangerous,
                    "original_query": original_query[:100]
                }
            )

    # ğŸ†• æ·±åº¦ç»Ÿè®¡åˆ†æå¢å¼ºï¼šä» response å¯¹è±¡è·å–ç»Ÿè®¡ç»“æœï¼Œè¿½åŠ åˆ° explanation ä¸­
    # å°è¯•ä» response å¯¹è±¡çš„ _stats_analysis å±æ€§è·å–ç»Ÿè®¡ç»“æœ
    stats_analysis = getattr(agent_response, '_stats_analysis', None)

    # è°ƒè¯•æ—¥å¿—
    logger.info(f"ğŸ” [è°ƒè¯•] æ£€æŸ¥ç»Ÿè®¡ç»“æœ: stats_analysis æ˜¯å¦å­˜åœ¨ = {stats_analysis is not None}")
    if stats_analysis:
        logger.info(f"ğŸ” [è°ƒè¯•] ç»Ÿè®¡ç»“æœç±»å‹: {type(stats_analysis)}, é”®: {list(stats_analysis.keys()) if isinstance(stats_analysis, dict) else 'N/A'}")

    if not stats_analysis and metadata and isinstance(metadata, dict):
        # å…¼å®¹æ—§æ–¹å¼ï¼šä» metadata ä¸­è·å–
        stats_analysis = metadata.get('stats_analysis')
        logger.info(f"ğŸ” [è°ƒè¯•] ä» metadata è·å–ç»Ÿè®¡ç»“æœ: {stats_analysis is not None}")

    if stats_analysis and isinstance(stats_analysis, dict) and 'error' not in stats_analysis:
        # ç”Ÿæˆç»Ÿè®¡ç»“æœçš„å¯è¯»æ–‡æœ¬
        stats_text = _format_stats_analysis(stats_analysis)

        # è°ƒè¯•æ—¥å¿—
        logger.info(f"ğŸ” [è°ƒè¯•] æ ¼å¼åŒ–åç»Ÿè®¡æ–‡æœ¬é•¿åº¦: {len(stats_text)}, å‰100å­—ç¬¦: {stats_text[:100]}")

        # å¦‚æœ stats_text ä¸ä¸ºç©ºï¼Œè¿½åŠ åˆ° explanation
        if stats_text and explanation:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åœ¨å‰é¢æ·»åŠ åˆ†éš”ç¬¦
            if not explanation.endswith('\n'):
                explanation += '\n\n'
            explanation += stats_text
            logger.info("âœ… [ç»Ÿè®¡åˆ†æ] å·²å°†ç»Ÿè®¡ç»“æœè¿½åŠ åˆ° explanation ä¸­")
    else:
        if stats_analysis:
            logger.warning(f"âš ï¸ [ç»Ÿè®¡åˆ†æ] ç»Ÿè®¡ç»“æœåŒ…å«é”™è¯¯: {stats_analysis.get('error', 'Unknown error')}")
        else:
            logger.info("â„¹ï¸ [ç»Ÿè®¡åˆ†æ] æ²¡æœ‰å¯ç”¨çš„ç»Ÿè®¡ç»“æœéœ€è¦è¿½åŠ ")

    # ğŸ›¡ï¸ å®‰å…¨è®¿é—®æ‰€æœ‰å±æ€§
    sql = safe_get(agent_response, 'sql', '')
    data_obj = safe_get(agent_response, 'data')
    row_count = 0
    if data_obj:
        row_count = safe_get(data_obj, 'row_count', 0)

    error = safe_get(agent_response, 'error')
    echarts_option = safe_get(agent_response, 'echarts_option')
    
    response_data = {
        "query_id": query_id,
        "tenant_id": tenant_id,
        "original_query": original_query,
        "generated_sql": sql,
        "results": results,
        "row_count": row_count,
        "processing_time_ms": processing_time_ms,
        "confidence_score": 0.9 if success else 0.5,
        "explanation": explanation,
        # ğŸ”¥ æ‰©å±•çš„å¤„ç†æ­¥éª¤ï¼šåŒ…å«SQLã€è¡¨æ ¼ã€å›¾è¡¨æ•°æ®ã€æ•°æ®åˆ†ææ–‡æœ¬
        "processing_steps": _build_processing_steps(
            success=success,
            sql=sql,
            results=results,
            row_count=row_count,
            data_obj=data_obj,
            echarts_option=echarts_option,
            chart_data=chart_data,
            chart_obj=safe_get(agent_response, 'chart'),
            processing_time_ms=processing_time_ms,
            answer=explanation
        ),
        "validation_result": {
            "valid": success,
            "error": error
        } if not success else None,
        "execution_result": execution_result,
        "correction_attempts": 0,
        # ğŸ›¡ï¸ åœ¨é¡¶å±‚ä¹Ÿæ·»åŠ  echarts_optionï¼Œä½¿ç”¨å®‰å…¨è®¿é—®
        "echarts_option": echarts_option,
        # ğŸ”´ ç¬¬ä¸‰é“é˜²çº¿ï¼šæ·»åŠ metadataä¾›å‰ç«¯ä½¿ç”¨
        "metadata": metadata
    }
    
    return response_data


def convert_agent_response_to_chat_response(
    agent_response: VisualizationResponse,
    execution_time: float = 0.0
) -> Dict[str, Any]:
    """
    å°†Agentçš„VisualizationResponseè½¬æ¢ä¸ºå‰ç«¯ChatQueryResponseæ ¼å¼
    
    Args:
        agent_response: Agentè¿”å›çš„å¯è§†åŒ–å“åº”
        execution_time: æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
    
    Returns:
        Dict: ç¬¦åˆChatQueryResponseæ ¼å¼çš„å­—å…¸
    """
    # ğŸ›¡ï¸ é€šç”¨å®‰å…¨å±æ€§è®¿é—®è¾…åŠ©å‡½æ•°ï¼ˆä¸ convert_agent_response_to_query_response ä¸­çš„ç›¸åŒï¼‰
    def safe_get(obj, attr, default=None):
        """å®‰å…¨è·å–å¯¹è±¡å±æ€§ï¼Œæ”¯æŒå¤šç§æ•°æ®ç±»å‹"""
        try:
            if isinstance(obj, dict):
                return obj.get(attr, default)
            if hasattr(obj, attr):
                value = getattr(obj, attr, default)
                return value if value is not None else default
            try:
                if hasattr(obj, 'dict'):
                    obj_dict = obj.dict()
                    return obj_dict.get(attr, default)
                elif hasattr(obj, 'model_dump'):
                    obj_dict = obj.model_dump()
                    return obj_dict.get(attr, default)
            except (AttributeError, TypeError):
                pass
            try:
                if hasattr(obj, '__dict__'):
                    return obj.__dict__.get(attr, default)
            except (AttributeError, TypeError):
                pass
            return default
        except Exception:
            return default
    
    # æå–æ•°æ®æºä¿¡æ¯ï¼ˆä»SQLä¸­æ¨æ–­ï¼‰
    sources = []
    sql = safe_get(agent_response, 'sql', '')
    if sql:
        # ç®€å•æå–è¡¨åï¼ˆå¯ä»¥æ”¹è¿›ï¼‰
        import re
        table_pattern = r'FROM\s+(\w+)'
        tables = re.findall(table_pattern, sql, re.IGNORECASE)
        sources.extend(tables)
    
    # ğŸ›¡ï¸ å®‰å…¨æ„å»º chart å¯¹è±¡ï¼Œé˜²æ­¢ AttributeError
    chart_dict = None
    chart_obj = safe_get(agent_response, 'chart')
    if chart_obj:
        # æ£€æŸ¥æ˜¯å¦æ˜¯ table ç±»å‹ï¼ˆä¸éœ€è¦å›¾è¡¨ï¼‰
        chart_type_obj = safe_get(chart_obj, 'chart_type')
        chart_type_value = None
        if chart_type_obj:
            if hasattr(chart_type_obj, 'value'):
                chart_type_value = chart_type_obj.value
            else:
                chart_type_value = str(chart_type_obj)
        
        # åªæœ‰é table ç±»å‹æ‰æ„å»º chart å¯¹è±¡
        if chart_type_value and chart_type_value != "table":
            # ğŸ›¡ï¸ ä½¿ç”¨ safe_get å®‰å…¨æå–æ‰€æœ‰ chart å±æ€§
            chart_image_attr = safe_get(chart_obj, 'chart_image')
            
            # ä½¿ç”¨æå–çš„ chart_image æˆ–ä» answer ä¸­æå–
            chart_data = None
            if chart_image_attr and isinstance(chart_image_attr, str) and len(chart_image_attr) > 0:
                chart_data = chart_image_attr
            else:
                # é™çº§ï¼šä» answer ä¸­æå–
                answer = safe_get(agent_response, 'answer', '')
                chart_path = extract_chart_path_from_answer(answer)
                if chart_path:
                    if not (chart_path.startswith('http://') or chart_path.startswith('https://')):
                        chart_data = load_chart_as_base64(chart_path)
                    else:
                        chart_data = chart_path
            
            # ğŸ›¡ï¸ å®‰å…¨è®¿é—®æ‰€æœ‰ chart å±æ€§
            chart_dict = {
                "chart_type": chart_type_value,
                "title": safe_get(chart_obj, 'title'),
                "x_field": safe_get(chart_obj, 'x_field'),
                "y_field": safe_get(chart_obj, 'y_field'),
                "chart_image": chart_image_attr if (chart_image_attr and isinstance(chart_image_attr, str) and len(chart_image_attr) > 0) else None,
                "chart_data": chart_data
            }
    
    # ğŸ›¡ï¸ ä½¿ç”¨ safe_get å®‰å…¨è®¿é—®æ‰€æœ‰å±æ€§
    answer = safe_get(agent_response, 'answer', '')
    sql = safe_get(agent_response, 'sql', '')
    success = safe_get(agent_response, 'success', False)
    data_obj = safe_get(agent_response, 'data')
    echarts_option = safe_get(agent_response, 'echarts_option')

    # ğŸ›¡ï¸ğŸ›¡ï¸ğŸ›¡ï¸ å®‰å…¨æ£€æŸ¥ï¼šæ£€æŸ¥ answer ä¸­æ˜¯å¦åŒ…å«å±é™©çš„ DML/DDL æ“ä½œ
    if answer:
        import re
        answer_upper = answer.upper()

        # å±é™©å…³é”®å­—é»‘åå•
        dangerous_keywords = [
            (r'\bUPDATE\b', 'UPDATE'),
            (r'\bDELETE\b', 'DELETE'),
            (r'\bINSERT\b', 'INSERT'),
            (r'\bDROP\b', 'DROP'),
            (r'\bTRUNCATE\b', 'TRUNCATE'),
            (r'\bALTER\b', 'ALTER'),
            (r'\bCREATE\s+TABLE\b', 'CREATE TABLE'),
            (r'\bGRANT\b', 'GRANT'),
            (r'\bREVOKE\b', 'REVOKE'),
        ]

        detected_dangerous = []
        for pattern, keyword in dangerous_keywords:
            if re.search(pattern, answer_upper):
                detected_dangerous.append(keyword)

        # æ£€æµ‹åˆ°å±é™© SQL - æ›¿æ¢ä¸ºæ‹’ç»æ¶ˆæ¯
        if detected_dangerous:
            security_message = (
                "â›” **æ“ä½œè¢«æ‹’ç»**\n\n"
                "æ‚¨è¯·æ±‚çš„æ“ä½œæ¶‰åŠæ•°æ®ä¿®æ”¹ï¼Œè¿™è¿åäº†å®‰å…¨ç­–ç•¥ã€‚\n\n"
                "ğŸ›¡ï¸ ä½œä¸ºä¸€ä¸ªåªè¯»æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œæˆ‘åªèƒ½ï¼š\n"
                "- âœ… æŸ¥è¯¢å’Œå±•ç¤ºæ•°æ®ï¼ˆSELECTï¼‰\n"
                "- âœ… åˆ†ææ•°æ®è¶‹åŠ¿å’Œæ¨¡å¼\n"
                "- âœ… ç”Ÿæˆæ•°æ®å¯è§†åŒ–å›¾è¡¨\n"
                "- âŒ ä¸èƒ½ä¿®æ”¹ã€åˆ é™¤æˆ–æ–°å¢æ•°æ®\n\n"
                "å¦‚æœæ‚¨éœ€è¦ä¿®æ”¹æ•°æ®ï¼Œè¯·è”ç³»æ•°æ®åº“ç®¡ç†å‘˜æˆ–ä½¿ç”¨ä¸“é—¨çš„ç®¡ç†å·¥å…·ã€‚"
            )
            answer = security_message
            logger.error(
                f"ğŸš« [Chatå“åº”å®‰å…¨æ£€æŸ¥] æ£€æµ‹åˆ°å±é™©SQLå…³é”®å­—å¹¶å·²æ‹¦æˆª: {', '.join(detected_dangerous)}",
                extra={
                    "detected_keywords": detected_dangerous
                }
            )

    # æ„å»ºå“åº”
    response = {
        "answer": answer,
        "sources": sources,
        "reasoning": f"æ‰§è¡Œäº†SQLæŸ¥è¯¢ï¼š{sql}" if sql else "",
        "confidence": 0.9 if success else 0.5,
        "execution_time": execution_time,
        "sql": sql,
        "data": {
            "columns": safe_get(data_obj, 'columns', []) if data_obj else [],
            "rows": safe_get(data_obj, 'rows', []) if data_obj else [],
            "row_count": safe_get(data_obj, 'row_count', 0) if data_obj else 0
        } if data_obj else None,
        "chart": chart_dict,
        "echarts_option": echarts_option  # ğŸ›¡ï¸ å®‰å…¨è®¿é—® ECharts é…ç½®é€‰é¡¹
    }
    
    return response


async def run_agent_query(
    question: str,
    thread_id: str,
    database_url: Optional[str] = None,
    verbose: bool = False,
    enable_echarts: bool = True,  # é»˜è®¤å¯ç”¨ ECharts åŠŸèƒ½
    db_type: str = "postgresql"  # æ•°æ®åº“ç±»å‹
) -> Optional[VisualizationResponse]:
    """
    è¿è¡ŒAgentæŸ¥è¯¢

    Args:
        question: ç”¨æˆ·é—®é¢˜
        thread_id: çº¿ç¨‹IDï¼ˆç”¨äºä¼šè¯ç®¡ç†ï¼‰
        database_url: æ•°æ®åº“è¿æ¥URLï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨Agenté…ç½®ï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
        enable_echarts: æ˜¯å¦å¯ç”¨ ECharts å›¾è¡¨ç”ŸæˆåŠŸèƒ½ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        db_type: æ•°æ®åº“ç±»å‹ï¼ˆpostgresql, mysql, sqlite, xlsx, csvç­‰ï¼‰

    Returns:
        VisualizationResponse: Agentå“åº”ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
    """
    logger.info(
        "run_agent_query called",
        extra={
            "question_preview": question[:100],
            "thread_id": thread_id,
            "has_database_url": bool(database_url),
            "agent_available": _agent_available,
            "db_type": db_type,  # æ·»åŠ æ•°æ®åº“ç±»å‹åˆ°æ—¥å¿—
        },
    )
    if not _agent_available:
        logger.error("Agentæ¨¡å—ä¸å¯ç”¨ï¼Œç›´æ¥è¿”å› None")
        return None
    
    try:
        # -----------------------------------------------------
        # 1ï¸âƒ£ STEP 1: EARLY ROUTING DETECTION (Check raw URL before modification)
        # -----------------------------------------------------
        # å…ˆåˆ¤æ–­æ–‡ä»¶æ¨¡å¼ï¼Œåœ¨æ¸…ç† database_url ä¹‹å‰
        is_file_mode = False
        raw_url_for_check = database_url or ""
        
        if isinstance(raw_url_for_check, str):
            # Check for file extensions or local paths
            if (raw_url_for_check.endswith(('.xlsx', '.xls', '.csv')) or 
                raw_url_for_check.startswith(('/', './', 'file://', 'local://')) or
                '/uploads/' in raw_url_for_check or
                '/data/' in raw_url_for_check):
                is_file_mode = True
        
        logger.info(
            f"ğŸ”§ [Router] æ—©æœŸè·¯ç”±æ£€æµ‹: {'FILE MODE' if is_file_mode else 'DATABASE MODE'}",
            extra={
                "is_file_mode": is_file_mode,
                "raw_url_preview": raw_url_for_check[:100] if raw_url_for_check else None
            }
        )
        
        # -----------------------------------------------------
        # 2ï¸âƒ£ STEP 2: DATABASE URL SANITIZATION (Prevent Postgres Crash)
        # -----------------------------------------------------
        # å¦‚æœæ£€æµ‹åˆ°æ˜¯æ–‡ä»¶æ¨¡å¼ï¼Œæ¸…ç† database_urlï¼Œé˜²æ­¢ Postgres å·¥å…·å´©æºƒ
        original_url = None
        if is_file_mode:
            if database_url:
                logger.warning(
                    f"ğŸ”§ [Sanitization] æ£€æµ‹åˆ°æ–‡ä»¶è·¯å¾„ï¼Œæ¸…ç† database_url é…ç½®ä»¥é˜²æ­¢ Postgres å·¥å…·å´©æºƒ: {database_url[:100]}",
                    extra={
                        "database_url_preview": database_url[:100],
                        "reason": "file_mode_detected"
                    }
                )
            # è®¾ç½®ä¸º Noneï¼Œé˜²æ­¢ Postgres å·¥å…·å°è¯•è¿æ¥
            database_url = None
        elif database_url:
            # è¿™æ˜¯æœ‰æ•ˆçš„æ•°æ®åº“ URLï¼Œå¯ä»¥è®¾ç½®åˆ° config
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æ•°æ®åº“ URLï¼ˆä»¥æ•°æ®åº“åè®®å¼€å¤´ï¼‰
            is_valid_db_url = (
                database_url.startswith('postgresql://') or
                database_url.startswith('postgres://') or
                database_url.startswith('mysql://') or
                database_url.startswith('mysql+pymysql://') or
                database_url.startswith('sqlite://') or
                database_url.startswith('sqlite:///') or
                database_url.startswith('mssql://') or
                database_url.startswith('oracle://')
            )
            
            if is_valid_db_url:
                # è¿™æ˜¯æœ‰æ•ˆçš„æ•°æ®åº“ URLï¼Œå¯ä»¥è®¾ç½®
                from config import config
                original_url = getattr(config, "database_url", None)
                logger.info(
                    "Temporarily overriding Agent database_url",
                    extra={
                        "old_url_preview": str(original_url)[:80] if original_url else None,
                        "new_url_preview": str(database_url)[:80],
                    },
                )
                config.database_url = database_url
            else:
                # ä¸æ˜¯æœ‰æ•ˆçš„æ•°æ®åº“ URLï¼Œä¹Ÿä¸åƒæ˜¯æ–‡ä»¶è·¯å¾„ï¼Œè®°å½•è­¦å‘Š
                logger.warning(
                    f"âš ï¸ database_url å‚æ•°æ ¼å¼å¼‚å¸¸ï¼Œæ—¢ä¸æ˜¯æ–‡ä»¶è·¯å¾„ä¹Ÿä¸æ˜¯æœ‰æ•ˆçš„æ•°æ®åº“ URL: {database_url[:100]}",
                    extra={
                        "database_url_preview": database_url[:100],
                        "reason": "invalid_format"
                    }
                )
        
        # -----------------------------------------------------
        # 3ï¸âƒ£ STEP 3: CONSTRUCT SYSTEM INSTRUCTION (Based on Step 1)
        # -----------------------------------------------------
        
        system_instruction = ""
        
        if is_file_mode:
            # ğŸ“‚ FILE MODE: Aggressive Anti-SQL Prompt (æ ¸å¨æ…‘çº§åˆ«)
            system_instruction = (
                "ã€ğŸ›‘ SYSTEM ALERT: FILE MODE ACTIVEã€‘\n"
                "You are processing a local Excel/CSV file. \n"
                "CRITICAL RULES:\n"
                "1. The 'query' tool and SQL tools are DISCONNECTED and will cause a SYSTEM CRASH.\n"
                "2. You MUST ONLY use `analyze_dataframe` (for data analysis) or `inspect_file` (for schema).\n"
                "3. DO NOT attempt to list tables or schema. The data is already loaded in the dataframe tool.\n"
                "4. If you use 'query', the task will fail immediately.\n"
                "5. The SQL database connection is NOT available in file mode. All SQL tools (`query`, `list_tables`, `get_schema`, `query_database`, `execute_sql_safe`) are DISABLED and will return errors.\n"
                "6. You MUST use file-specific tools: `inspect_file` to see file structure, `analyze_dataframe` to query data."
            )
            logger.info("ğŸ”§ [Router] Detected FILE MODE. Locking SQL tools.")
        else:
            # ğŸ›¢ï¸ DATABASE MODE: Standard SQL behavior with enhanced analysis requirements
            system_instruction = (
                "ã€SYSTEM MODE: DATABASE ANALYSISã€‘\n"
                "You are connected to a SQL database. \n"
                "RULES:\n"
                "1. Use `list_available_tables` or `list_tables` to see available tables first.\n"
                "2. Query the relevant tables using `execute_sql_safe` or `query_database` tools.\n"
                "\n\nğŸ”´ã€CRITICAL: DEEP DATA ANALYSIS REQUIREMENTã€‘\n"
                "After executing SQL, you MUST provide detailed analysis including:\n"
                "\n"
                "**1. Statistical Metrics (å¿…å¡«)**:\n"
                "- Total, Mean, Median, Standard Deviation\n"
                "- Min/Max values and Range\n"
                "- Growth rates (åŒæ¯”/ç¯æ¯”) if time series data\n"
                "- Coefficient of Variation (data stability)\n"
                "\n"
                "**2. Trend & Pattern Analysis (å¿…å¡«)**:\n"
                "- Overall trend direction (ä¸Šå‡/ä¸‹é™/å¹³ç¨³)\n"
                "- Key fluctuations and volatility\n"
                "- Seasonal patterns (if applicable)\n"
                "- Outliers and anomalies detection\n"
                "\n"
                "**3. Numerical Insights (å¿…å¡«)**:\n"
                "- What the numbers actually mean\n"
                "- Percentage changes and comparisons\n"
                "- Rankings (top/bottom performers)\n"
                "- Correlations between metrics\n"
                "\n"
                "**4. Business Intelligence (å¿…å¡«)**:\n"
                "- Actionable recommendations\n"
                "- Risk identification\n"
                "- Opportunity detection\n"
                "- Strategic suggestions\n"
                "\n"
                "âš ï¸ Example format for time series:\n"
                "â€¢ æ€»é”€å”®é¢ï¼šX ä¸‡å…ƒï¼Œå¹³å‡æ¯æœˆ Y ä¸‡å…ƒ\n"
                "â€¢ æ•´ä½“è¶‹åŠ¿ï¼šä¸Šå‡/ä¸‹é™ Z%ï¼ˆä» A ä¸‡å¢é•¿åˆ° B ä¸‡ï¼‰\n"
                "â€¢ å³°å€¼ï¼šC ä¸‡å…ƒï¼ˆæŸæœˆï¼‰ï¼Œè°·å€¼ï¼šD ä¸‡å…ƒï¼ˆæŸæœˆï¼‰\n"
                "â€¢ æ³¢åŠ¨æ€§ï¼šæ ‡å‡†å·® Eï¼Œå˜å¼‚ç³»æ•° F%\n"
                "â€¢ å»ºè®®ï¼šåŸºäºä»¥ä¸Šå‘ç°...\n"
                "\n"
                "âš ï¸ Even for simple queries, calculate and present statistics.\n"
                "âš ï¸ Do NOT just list data rows - provide insights!\n"
            )
            logger.info("ğŸ›¢ï¸ [Router] Detected DATABASE MODE.")
        
        # -----------------------------------------------------
        # 4ï¸âƒ£ STEP 4: INJECT & EXECUTE
        # -----------------------------------------------------
        # Inject the instruction into the question (Prompt Engineering)
        enhanced_question = f"{system_instruction}\n\nUser Question: {question}"
        logger.info("ğŸ“‹ [Prompt Injection] System instruction added to question.")
        
        # Log full system instruction for debugging
        if system_instruction:
            logger.debug(
                f"ğŸ“‹ [ç³»ç»ŸæŒ‡ä»¤æ³¨å…¥] å®Œæ•´ç³»ç»ŸæŒ‡ä»¤å†…å®¹",
                extra={
                    "system_instruction": system_instruction,
                    "instruction_length": len(system_instruction),
                    "is_file_mode": is_file_mode
                }
            )
        
        # -----------------------------------------------------
        
        # è¿è¡ŒAgent
        logger.info(
            "Starting underlying LangGraph Agent run",
            extra={"thread_id": thread_id, "enable_echarts": enable_echarts},
        )

        # ğŸ”¥ ã€QAé›†æˆã€‘å¼€å§‹è®¡æ—¶
        import time as _time_module
        _qa_start_time = _time_module.time()
        _qa_context = {
            "source": "backend_api",
            "endpoint": "/api/v1/llm/query-with-agent",
            "user_question": question,  # åŸå§‹é—®é¢˜ï¼ˆæœªå¢å¼ºï¼‰
            "thread_id": thread_id,
            "db_type": db_type,
            "enable_echarts": enable_echarts,
        }

        # æ ¹æ®ä½¿ç”¨çš„ Agent ç‰ˆæœ¬è°ƒç”¨ä¸åŒçš„å‡½æ•°
        if _use_new_agent:
            # æ–°ç‰ˆæœ¬ï¼šéœ€è¦ä¼ é€’ database_urlï¼Œè¿”å› Dict åŒ…å« response å­—æ®µ
            from config import config as agent_config
            
            # åœ¨æ–‡ä»¶æ¨¡å¼ä¸‹ï¼Œä¼ é€’åŸå§‹æ–‡ä»¶è·¯å¾„ï¼›åœ¨æ•°æ®åº“æ¨¡å¼ä¸‹ï¼Œä¼ é€’æ•°æ®åº“ URL
            if is_file_mode:
                # æ–‡ä»¶æ¨¡å¼ï¼šä¼ é€’åŸå§‹æ–‡ä»¶è·¯å¾„ï¼ˆraw_url_for_checkï¼‰
                effective_db_url = raw_url_for_check if raw_url_for_check else None
                logger.info(
                    f"ğŸ“‚ [æ–‡ä»¶æ¨¡å¼] ä¼ é€’æ–‡ä»¶è·¯å¾„ç»™ run_agent: {effective_db_url[:100] if effective_db_url else None}",
                    extra={"file_path": effective_db_url}
                )
            else:
                # æ•°æ®åº“æ¨¡å¼ï¼šä½¿ç”¨æ¸…ç†åçš„ database_url æˆ–é…ç½®ä¸­çš„é»˜è®¤å€¼
                effective_db_url = database_url or getattr(agent_config, "database_url", None)
                if not effective_db_url:
                    logger.error("æ— æ³•è·å–æ•°æ®åº“è¿æ¥URL")
                    return None
                logger.info(
                    f"ğŸ›¢ï¸ [æ•°æ®åº“æ¨¡å¼] ä¼ é€’æ•°æ®åº“ URL ç»™ run_agent",
                    extra={"database_url_preview": effective_db_url[:80] if effective_db_url else None}
                )
            
            result = await run_agent(
                question=enhanced_question,  # ğŸ”¥ ä½¿ç”¨å¢å¼ºåçš„é—®é¢˜ï¼ˆåŒ…å«æ™ºèƒ½è·¯ç”±æŒ‡ä»¤ï¼‰
                database_url=effective_db_url,  # æ–‡ä»¶æ¨¡å¼ä¸‹ä¼ é€’æ–‡ä»¶è·¯å¾„ï¼Œæ•°æ®åº“æ¨¡å¼ä¸‹ä¼ é€’æ•°æ®åº“ URL
                thread_id=thread_id,
                enable_echarts=enable_echarts,
                verbose=verbose,
                db_type=db_type  # ä¼ é€’æ•°æ®åº“ç±»å‹
            )
            # æ–°ç‰ˆæœ¬è¿”å› Dictï¼Œæå– response å­—æ®µï¼ˆVisualizationResponse å¯¹è±¡ï¼‰
            if result and isinstance(result, dict) and "response" in result:
                response = result["response"]
                # ğŸ”¥ ä¿®å¤ï¼šresponseå¯¹è±¡å·²ç»åŒ…å«metadataå­—æ®µï¼Œä¸éœ€è¦å†åŠ¨æ€æ·»åŠ 
                # metadataå·²ç»åœ¨run_agentä¸­è®¾ç½®åˆ°VisualizationResponseå¯¹è±¡ä¸­
            else:
                response = None
        else:
            # æ—§ç‰ˆæœ¬ï¼šä¸æ”¯æŒ enable_echarts å‚æ•°
            response = await run_agent(enhanced_question, thread_id, verbose=verbose, db_type=db_type)  # ä¼ é€’ db_type
        logger.info(
            "Underlying LangGraph Agent finished",
            extra={
                "success": getattr(response, "success", None) if response else None,
                "sql_preview": (response.sql or "")[:120] if getattr(response, "sql", None) else None,
                "row_count": getattr(getattr(response, "data", None), "row_count", None) if response else None,
                "error": getattr(response, "error", None) if response else None,
            },
        )

        # ğŸ”¥ ã€QAé›†æˆã€‘è®°å½•æˆåŠŸ
        if _error_tracking_available and error_tracker:
            _qa_elapsed = _time_module.time() - _qa_start_time
            _response_success = getattr(response, "success", False) if response else False
            _response_answer = getattr(response, "answer", "")[:500] if response else ""
            _response_sql = getattr(response, "sql", "")[:200] if response else ""
            _response_error = getattr(response, "error", None) if response else None

            if _response_success:
                error_tracker.log_success(
                    question=question,
                    response=_response_answer or "æŸ¥è¯¢æˆåŠŸ",
                    context={
                        **_qa_context,
                        "sql": _response_sql,
                        "chart_type": getattr(getattr(response, "chart", None), "chart_type", None) if response else None,
                    },
                    execution_time=_qa_elapsed
                )
                logger.info(f"âœ… [QA] æˆåŠŸè®°å½•å·²ä¿å­˜ (è€—æ—¶: {_qa_elapsed:.2f}s)")
            elif _response_error:
                # æœ‰é”™è¯¯ä½†æ²¡æŠ›å¼‚å¸¸çš„æƒ…å†µ
                log_agent_error(
                    question=question,
                    error=Exception(_response_error),
                    category=ErrorCategory.UNKNOWN,
                    context={**_qa_context, "execution_time": _qa_elapsed}
                )
                logger.info(f"âš ï¸ [QA] é”™è¯¯è®°å½•å·²ä¿å­˜ (Agentè¿”å›é”™è¯¯: {_response_error[:100]})")

        # ğŸ†• æ·±åº¦ç»Ÿè®¡åˆ†æé›†æˆ
        stats_result = None  # åœ¨å¤–éƒ¨å˜é‡ä¸­ä¿å­˜ç»Ÿè®¡ç»“æœ
        if _stats_analysis_available and response and getattr(response, 'success', False):
            try:
                # è·å–æŸ¥è¯¢æ•°æ®
                data_obj = getattr(response, 'data', None)
                if data_obj and hasattr(data_obj, 'rows') and data_obj.rows:
                    # å‡†å¤‡æ•°æ®æ ¼å¼
                    data_for_stats = {
                        "columns": list(data_obj.columns) if hasattr(data_obj, 'columns') else [],
                        "rows": data_obj.rows
                    }

                    # è°ƒç”¨ç»Ÿè®¡åˆ†ææœåŠ¡
                    stats_service = get_stats_service()
                    stats_result = stats_service.analyze_query_result(data_for_stats)

                    # å°†ç»Ÿè®¡ç»“æœæ·»åŠ åˆ° response å¯¹è±¡ä¸­ï¼ˆä½¿ç”¨ç§æœ‰å±æ€§é¿å…å†²çªï¼‰
                    if stats_result and 'error' not in stats_result:
                        setattr(response, '_stats_analysis', stats_result)
                        logger.info(
                            "âœ… [ç»Ÿè®¡åˆ†æ] æ·±åº¦ç»Ÿè®¡æŒ‡æ ‡è®¡ç®—å®Œæˆ",
                            extra={
                                "stats_basic": stats_result.get('basic_stats', {}),
                                "stats_trend": stats_result.get('trend_analysis', {})
                            }
                        )
            except Exception as stats_error:
                logger.warning(f"ç»Ÿè®¡åˆ†æå¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {stats_error}", exc_info=True)

        # æ¢å¤åŸå§‹é…ç½®ï¼ˆåªæœ‰å½“ original_url è¢«è®¾ç½®æ—¶æ‰æ¢å¤ï¼‰
        if original_url is not None:
            from config import config
            logger.info("Restoring original Agent database_url")
            config.database_url = original_url

        return response
    
    except Exception as e:
        logger.error("AgentæŸ¥è¯¢å¤±è´¥", extra={"error": str(e)}, exc_info=True)

        # ğŸ”¥ ã€QAé›†æˆã€‘è®°å½•å¼‚å¸¸é”™è¯¯
        if _error_tracking_available and error_tracker:
            try:
                _qa_elapsed = _time_module.time() - _qa_start_time
                # è‡ªåŠ¨æ¨æ–­é”™è¯¯ç±»åˆ«
                _error_category = ErrorCategory.UNKNOWN
                error_str = str(e).lower()
                if "connection" in error_str or "connect" in error_str:
                    _error_category = ErrorCategory.DATABASE_CONNECTION
                elif "timeout" in error_str:
                    _error_category = ErrorCategory.TIMEOUT
                elif "schema" in error_str or "table" in error_str or "column" in error_str:
                    _error_category = ErrorCategory.SCHEMA_NOT_FOUND
                elif "mcp" in error_str or "tool" in error_str:
                    _error_category = ErrorCategory.MCP_TOOL_FAILURE
                elif "api" in error_str or "llm" in error_str or "rate" in error_str:
                    _error_category = ErrorCategory.LLM_API_ERROR

                log_agent_error(
                    question=question,
                    error=e,
                    category=_error_category,
                    context={**_qa_context, "execution_time": _qa_elapsed}
                )
                logger.info(f"âŒ [QA] å¼‚å¸¸é”™è¯¯å·²è®°å½• (ç±»åˆ«: {_error_category.value})")
            except Exception as track_error:
                logger.warning(f"é”™è¯¯è¿½è¸ªè®°å½•å¤±è´¥: {track_error}")

        return None


def is_agent_available() -> bool:
    """æ£€æŸ¥Agentæ˜¯å¦å¯ç”¨"""
    return _agent_available

