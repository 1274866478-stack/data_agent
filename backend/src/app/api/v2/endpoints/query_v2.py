# -*- coding: utf-8 -*-
"""
Query V2 Endpoint - AgentV2 æŸ¥è¯¢ç«¯ç‚¹
===================================

æ–°ç‰ˆæŸ¥è¯¢ç«¯ç‚¹ï¼ŒåŸºäº AgentV2 (DeepAgents æ¡†æ¶)ã€‚

API: POST /api/v2/query

ç‰¹æ€§:
    - ç§Ÿæˆ·éš”ç¦»
    - SQL å®‰å…¨éªŒè¯
    - SubAgent å§”æ´¾
    - å¯è§£é‡Šæ€§æ—¥å¿—

ä½œè€…: BMad Master
ç‰ˆæœ¬: 2.0.0
"""

from fastapi import APIRouter, Depends, HTTPException, status
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from sqlalchemy.orm import Session
import logging

# AgentV2 imports
import sys
from pathlib import Path

# åˆ›å»º logger
logger = logging.getLogger(__name__)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ - æ›´å¥å£®çš„æ–¹æ³•
def find_project_root():
    """æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŒ…å« AgentV2 å’Œ backend çš„ç›®å½•ï¼‰"""
    current = Path(__file__).resolve()

    # æ–¹æ³•1ï¼šå‘ä¸ŠæŸ¥æ‰¾ç›´åˆ°æ‰¾åˆ°åŒ…å« AgentV2 çš„ç›®å½•
    for _ in range(10):  # æœ€å¤šå‘ä¸ŠæŸ¥æ‰¾10å±‚
        parent = current.parent
        if (parent / "AgentV2").exists() or (parent / "backend").exists():
            return parent
        current = parent

    # æ–¹æ³•2ï¼šä»å½“å‰æ–‡ä»¶è·¯å¾„æ¨ç®—
    # backend/src/app/api/v2/endpoints/query_v2.py
    # å‘ä¸Š7å±‚åº”è¯¥æ˜¯é¡¹ç›®æ ¹ç›®å½•
    project_root = Path(__file__).resolve().parent.parent.parent.parent.parent.parent.parent
    if str(project_root).endswith("backend"):
        project_root = project_root.parent

    # æ–¹æ³•3ï¼šå¦‚æœä»¥ä¸Šéƒ½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ cwd
    import os
    cwd = Path(os.getcwd())
    # å¦‚æœå½“å‰åœ¨ backend ç›®å½•ä¸‹
    if (cwd / "src").exists() and (cwd.parent / "AgentV2").exists():
        return cwd.parent
    # å¦‚æœå½“å‰åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹
    if (cwd / "AgentV2").exists() and (cwd / "backend").exists():
        return cwd

    return project_root

project_root = find_project_root()
sys.path.insert(0, str(project_root))

# è°ƒè¯•ï¼šæ‰“å°è·¯å¾„ä¿¡æ¯
logger.info(f"[query_v2] Project root: {project_root}")
logger.info(f"[query_v2] AgentV2 exists: {(project_root / 'AgentV2').exists()}")
logger.info(f"[query_v2] sys.path[0]: {sys.path[0]}")

# æ•°æ®åº“ä¼šè¯å¯¼å…¥
try:
    from src.app.data.database import get_db
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œæä¾›å›é€€
    def get_db():
        raise NotImplementedError("Database session not available")

try:
    # è°ƒè¯•ï¼šæ‰“å°å½“å‰çš„ sys.path
    logger.info(f"[query_v2 import] sys.path[0:3]: {sys.path[0:3]}")
    logger.info(f"[query_v2 import] project_root in sys.path: {project_root in sys.path}")
    from AgentV2.core import AgentFactory, get_default_factory, get_response_cache
    from AgentV2.middleware import TenantIsolationMiddleware, SQLSecurityMiddleware
    AGENTV2_AVAILABLE = True
    logger.info("[query_v2 import] SUCCESS: AgentV2 imported successfully")
except ImportError as e:
    AGENTV2_AVAILABLE = False
    logger.error(f"[query_v2 import] ERROR: Failed to import AgentV2: {e}")
    # æä¾›å›é€€çš„ç±»å‹å®šä¹‰ï¼ˆå½“ AgentV2 ä¸å¯ç”¨æ—¶ï¼‰
    from typing import Any, Optional

    class AgentFactory:
        """å›é€€çš„ AgentFactory ç±»å‹"""
        def get_or_create_agent(self, tenant_id: str, user_id: str, session_id: Optional[str] = None):
            """è¿”å›æ¨¡æ‹Ÿçš„ agent å®ä¾‹"""
            return MockAgent()

    class MockAgent:
        """æ¨¡æ‹Ÿ Agent å®ä¾‹"""
        async def ainvoke(self, inputs: dict, config: Optional[dict] = None) -> dict:
            return {"messages": [{"role": "assistant", "content": "AgentV2 ä¸å¯ç”¨"}]}

    def get_default_factory():
        """å›é€€çš„å·¥å‚å‡½æ•°"""
        return AgentFactory()

    class TenantIsolationMiddleware:
        """å›é€€çš„ç§Ÿæˆ·éš”ç¦»ä¸­é—´ä»¶"""
        pass

    class SQLSecurityMiddleware:
        """å›é€€çš„ SQL å®‰å…¨ä¸­é—´ä»¶"""
        pass

    logging.warning("AgentV2 module not available, using mock mode")

# ============================================================================
# è¯·æ±‚/å“åº”æ¨¡å‹
# ============================================================================

class QueryRequestV2(BaseModel):
    """æŸ¥è¯¢è¯·æ±‚æ¨¡å‹ V2"""
    query: str = Field(..., description="è‡ªç„¶è¯­è¨€æŸ¥è¯¢", min_length=1)
    connection_id: Optional[str] = Field(None, description="æ•°æ®æºè¿æ¥ ID")
    session_id: Optional[str] = Field(None, description="ä¼šè¯ ID")

    # å¯é€‰å‚æ•°
    max_results: int = Field(100, ge=1, le=1000, description="æœ€å¤§ç»“æœæ•°")
    include_chart: bool = Field(False, description="æ˜¯å¦ç”Ÿæˆå›¾è¡¨")
    chart_type: Optional[str] = Field(None, description="å›¾è¡¨ç±»å‹")

    class Config:
        json_schema_extra = {
            "example": {
                "query": "æŸ¥è¯¢é”€å”®é¢å‰10çš„äº§å“",
                "connection_id": "conn_123",
                "session_id": "session_abc",
                "max_results": 100,
                "include_chart": True,
                "chart_type": "bar"
            }
        }


class QueryResponseV2(BaseModel):
    """æŸ¥è¯¢å“åº”æ¨¡å‹ V2"""
    success: bool
    answer: str
    sql: Optional[str] = None
    data: Optional[List[Dict[str, Any]]] = None
    row_count: int = 0

    # æ–°å¢ V2 ç‰¹æ€§
    processing_steps: List[str] = Field(default_factory=list)
    subagent_calls: List[str] = Field(default_factory=list)
    reasoning_log: Optional[Dict[str, Any]] = None

    # å›¾è¡¨
    chart_config: Optional[Dict[str, Any]] = None

    # å…ƒæ•°æ®
    tenant_id: str
    processing_time_ms: int = 0
    from_cache: bool = False  # æ˜¯å¦æ¥è‡ªç¼“å­˜

    class Config:
        json_schema_extra = {
            "example": {
                "success": True,
                "answer": "æŸ¥è¯¢æˆåŠŸï¼Œæ‰¾åˆ°10ä¸ªäº§å“",
                "sql": "SELECT * FROM products ORDER BY sales DESC LIMIT 10",
                "data": [],
                "row_count": 10,
                "processing_steps": ["è§£ææŸ¥è¯¢", "ç”ŸæˆSQL", "æ‰§è¡ŒæŸ¥è¯¢"],
                "tenant_id": "tenant_123",
                "processing_time_ms": 1234
            }
        }


class ErrorResponse(BaseModel):
    """é”™è¯¯å“åº”æ¨¡å‹"""
    success: bool = False
    error: str
    error_type: str  # "security", "database", "agent", etc.
    details: Optional[Dict[str, Any]] = None


# ============================================================================
# è·¯ç”±å™¨
# ============================================================================

router = APIRouter(prefix="/query", tags=["query-v2"])

# ============================================================================
# ä¾èµ–é¡¹
# ============================================================================

def get_agent_factory() -> AgentFactory:
    """è·å– AgentFactory å®ä¾‹"""
    return get_default_factory()


def get_tenant_from_request(request: QueryRequestV2) -> str:
    """
    ä»è¯·æ±‚ä¸­æå–ç§Ÿæˆ· ID

    TODO: é›†æˆå®é™…çš„è®¤è¯ç³»ç»Ÿ
    ç›®å‰ä½¿ç”¨é»˜è®¤ç§Ÿæˆ·
    """
    # å®é™…å®ç°åº”è¯¥ä» JWT token ä¸­æå–
    return "default_tenant"


def get_user_from_request(request: QueryRequestV2) -> str:
    """ä»è¯·æ±‚ä¸­æå–ç”¨æˆ· ID"""
    # å®é™…å®ç°åº”è¯¥ä» JWT token ä¸­æå–
    return "default_user"


# ============================================================================
# ç«¯ç‚¹
# ============================================================================

@router.post("/", response_model=QueryResponseV2)
async def create_query_v2(
    request: QueryRequestV2,
    tenant_id: str = Depends(get_tenant_from_request),
    user_id: str = Depends(get_user_from_request),
    db: Session = Depends(get_db),
    agent_factory: AgentFactory = Depends(get_agent_factory)
):
    """
    Data Agent V2 æŸ¥è¯¢ç«¯ç‚¹

    ä½¿ç”¨ DeepAgents æ¡†æ¶æ‰§è¡Œè‡ªç„¶è¯­è¨€æŸ¥è¯¢ã€‚

    ## åŠŸèƒ½ç‰¹æ€§
    - ç§Ÿæˆ·éš”ç¦»ï¼šæ¯ä¸ªç§Ÿæˆ·çš„æ•°æ®å®Œå…¨éš”ç¦»
    - SQL å®‰å…¨ï¼šè‡ªåŠ¨æ‹¦æˆªå±é™© SQL
    - SubAgentï¼šæ™ºèƒ½ä»»åŠ¡å§”æ´¾
    - å¯è§£é‡Šæ€§ï¼šå®Œæ•´çš„æ¨ç†è¿‡ç¨‹è®°å½•

    ## è¯·æ±‚ç¤ºä¾‹
    ```json
    {
        "query": "æŸ¥è¯¢é”€å”®é¢å‰10çš„äº§å“",
        "connection_id": "conn_123",
        "include_chart": true
    }
    ```

    ## å“åº”ç¤ºä¾‹
    ```json
    {
        "success": true,
        "answer": "æŸ¥è¯¢æˆåŠŸ",
        "sql": "SELECT * FROM products ...",
        "data": [...],
        "processing_steps": ["è§£ææŸ¥è¯¢", "ç”ŸæˆSQL"],
        "tenant_id": "tenant_123"
    }
    ```
    """
    import time

    start_time = time.time()

    try:
        # 1. éªŒè¯ç§Ÿæˆ·
        if not tenant_id:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="ç§Ÿæˆ· ID ç¼ºå¤±"
            )

        # 2. åˆ›å»º Agent (å¸¦ç§Ÿæˆ·éš”ç¦»å’Œæ•°æ®æºè¿æ¥)
        try:
            # DEBUG: æ‰“å°ä¸­é—´ä»¶ç±»ä¿¡æ¯
            import AgentV2.middleware as mid_module
            logger.info(f"[DEBUG] TenantIsolationMiddleware ç±»æ£€æŸ¥:")
            logger.info(f"  - æœ‰ wrap_tool_call: {hasattr(mid_module.TenantIsolationMiddleware, 'wrap_tool_call')}")
            logger.info(f"  - æœ‰ wrap_model_call: {hasattr(mid_module.TenantIsolationMiddleware, 'wrap_model_call')}")
            logger.info(f"  - æ‰€æœ‰æ–¹æ³•: {[a for a in dir(mid_module.TenantIsolationMiddleware) if not a.startswith('_')]}")

            logger.info(f"[DEBUG] å¼€å§‹åˆ›å»º agent... connection_id={request.connection_id}")
            agent = agent_factory.get_or_create_agent(
                tenant_id=tenant_id,
                user_id=user_id,
                session_id=request.session_id,
                connection_id=request.connection_id,
                db_session=db
            )
            logger.info(f"[DEBUG] Agent åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            # æ·»åŠ è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            import traceback
            error_detail = f"{str(e)}\n\nTraceback:\n{traceback.format_exc()}"
            logger.error(f"[ERROR] Agent åˆ›å»ºå¤±è´¥: {error_detail}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail={
                    "success": False,
                    "error": error_detail,
                    "error_type": "agent_initialization_error",
                    "tenant_id": tenant_id
                }
            )

        # 4. å‡†å¤‡è¾“å…¥
        agent_input = {
            "messages": [
                {"role": "user", "content": request.query}
            ]
        }

        # 5. SQL å®‰å…¨é¢„æ£€æŸ¥ï¼ˆæš‚æ—¶ç¦ç”¨ï¼Œç­‰å¾…ä¸­é—´ä»¶ä¿®å¤ï¼‰
        # sql_middleware = SQLSecurityMiddleware()
        # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–äº†å®é™…çš„ SQL æå–é€»è¾‘
        # å®é™…å®ç°éœ€è¦ä»æ¶ˆæ¯ä¸­æå– SQL

        # 5.5. æ£€æŸ¥å“åº”ç¼“å­˜
        if AGENTV2_AVAILABLE:
            response_cache = get_response_cache()
            cached_response = response_cache.get(
                query=request.query,
                tenant_id=tenant_id,
                connection_id=request.connection_id,
                context={"data_sources": []}  # å¯ä» request è·å–
            )
            if cached_response:
                logger.info(f"[V2] ä½¿ç”¨ç¼“å­˜å“åº”: {request.query[:30]}...")
                # æ·»åŠ ç¼“å­˜æ ‡è®°åˆ°å¤„ç†æ­¥éª¤
                cached_response["processing_steps"] = ["ç¼“å­˜å‘½ä¸­"] + cached_response.get("processing_steps", [])
                cached_response["from_cache"] = True
                return QueryResponseV2(**cached_response)

        # 6. æ‰§è¡ŒçœŸå®æŸ¥è¯¢ï¼ˆä½¿ç”¨åŒæ­¥è°ƒç”¨åœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­è¿è¡Œï¼‰
        logger.info(f"[V2] æ‰§è¡ŒæŸ¥è¯¢: {request.query}")
        # æ³¨æ„ï¼šç”±äºä¸­é—´ä»¶æš‚æœªå®ç°å¼‚æ­¥æ–¹æ³•ï¼Œä½¿ç”¨ to_thread è¿è¡ŒåŒæ­¥è°ƒç”¨
        import asyncio
        result = await asyncio.to_thread(agent.invoke, agent_input)
        logger.info(f"[V2] æŸ¥è¯¢å®Œæˆï¼Œç»“æœç±»å‹: {type(result)}")

        # 7. è§£æè¿”å›ç»“æœ
        processing_time = int((time.time() - start_time) * 1000)

        # DeepAgents è¿”å›çš„ç»“æœé€šå¸¸åŒ…å« messages å­—æ®µ
        answer = ""
        processing_steps = []
        subagent_calls = []

        if hasattr(result, "get"):
            # å­—å…¸ç±»å‹ç»“æœ
            messages = result.get("messages", [])
        elif isinstance(result, list):
            # åˆ—è¡¨ç±»å‹ç»“æœ
            messages = result
        else:
            messages = []

        # ========== [æ•°æ®éªŒè¯æ¨¡å—] ä»æ¶ˆæ¯ä¸­æå– SQL å’Œæ•°æ® ==========
        extracted_sql = None
        extracted_data = None
        chart_config = None

        # å¯¼å…¥æ•°æ®éªŒè¯æ¨¡å—
        DATA_VALIDATION_AVAILABLE = False
        try:
            # å°è¯•å¤šç§å¯¼å…¥è·¯å¾„ä»¥æ”¯æŒä¸åŒç¯å¢ƒ
            try:
                from backend.src.app.services.agent.data_validator import (
                    validate_sql_data_consistency,
                    smart_field_mapping,
                    recommend_chart,
                )
            except ImportError:
                from src.app.services.agent.data_validator import (
                    validate_sql_data_consistency,
                    smart_field_mapping,
                    recommend_chart,
                )
            DATA_VALIDATION_AVAILABLE = True
            logger.info("[V2] æ•°æ®éªŒè¯æ¨¡å—å·²åŠ è½½")
        except ImportError as e:
            DATA_VALIDATION_AVAILABLE = False
            logger.warning(f"[V2] æ•°æ®éªŒè¯æ¨¡å—ä¸å¯ç”¨: {e}")

        # ğŸ” è°ƒè¯•ï¼šæ‰“å°æ¶ˆæ¯ç»“æ„
        logger.info(f"[V2] æ¶ˆæ¯æ•°é‡: {len(messages)}")
        for i, msg in enumerate(messages):
            msg_type = type(msg).__name__
            msg_class_str = str(msg.__class__) if hasattr(msg, '__class__') else 'N/A'
            logger.info(f"[V2] æ¶ˆæ¯ {i}: type={msg_type}, class={msg_class_str}")
            if hasattr(msg, 'tool_calls'):
                logger.info(f"[V2]   - tool_calls: {msg.tool_calls}")
            if hasattr(msg, 'content'):
                content_preview = str(msg.content)[:200] if msg.content else None
                logger.info(f"[V2]   - content: {content_preview}")

        # ä»æ¶ˆæ¯ä¸­æå– SQL å’Œæ•°æ®
        for msg in messages:
            # æå– SQLï¼ˆä» AIMessage çš„ tool_calls ä¸­ï¼‰
            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                for tc in msg.tool_calls:
                    tc_name = tc.get('name') if isinstance(tc, dict) else getattr(tc, 'name', None)
                    logger.info(f"[V2] æ£€æŸ¥å·¥å…·è°ƒç”¨: {tc_name}")
                    # AgentV2 ä½¿ç”¨ execute_query å·¥å…·ï¼Œå‚æ•°åæ˜¯ 'query'
                    if tc_name in ('execute_query', 'query', 'mcp_postgres_query'):
                        tc_args = tc.get('args') if isinstance(tc, dict) else getattr(tc, 'args', {})
                        # å°è¯•å¤šç§å‚æ•°å
                        if tc_args:
                            extracted_sql = (
                                tc_args.get('query') or
                                tc_args.get('sql') or
                                tc_args.get('q')
                            )
                        if extracted_sql:
                            logger.info(f"[V2] æå–åˆ° SQL: {extracted_sql[:100] if extracted_sql else None}...")
                            break  # æ‰¾åˆ° SQL åè·³å‡º

            # æå–æ•°æ®ï¼ˆä» ToolMessage ä¸­ï¼‰
            msg_class_name = str(msg.__class__) if hasattr(msg, '__class__') else ''
            if 'ToolMessage' in msg_class_name or 'Tool' in msg_class_name:
                try:
                    import json
                    content = msg.content
                    logger.info(f"[V2] ToolMessage content ç±»å‹: {type(content)}")
                    if isinstance(content, str):
                        # å°è¯•è§£æ JSON æ•°æ®
                        data = json.loads(content)

                        # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡å‡†çš„æŸ¥è¯¢ç»“æœæ ¼å¼ {"columns": [...], "rows": [...], ...}
                        if isinstance(data, dict) and 'columns' in data and 'rows' in data:
                            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨æ ¼å¼ [{"col1": val1, "col2": val2}, ...]
                            columns = data.get('columns', [])
                            rows = data.get('rows', [])
                            if rows and columns:
                                extracted_data = [
                                    {col: val for col, val in zip(columns, row)}
                                    for row in rows
                                ]
                                logger.info(f"[V2] æå–åˆ°æ•°æ®: {len(extracted_data)} è¡Œ, åˆ—: {columns}")
                            break

                        # æ£€æŸ¥æ˜¯å¦æ˜¯ç›´æ¥çš„å­—å…¸åˆ—è¡¨
                        elif isinstance(data, list) and len(data) > 0:
                            if all(isinstance(row, dict) for row in data):
                                extracted_data = data
                                logger.info(f"[V2] æå–åˆ°æ•°æ®: {len(data)} è¡Œ, åˆ—: {list(data[0].keys())}")
                                break
                        elif isinstance(data, dict) and 'error' in data:
                            # é”™è¯¯å“åº”ï¼Œè·³è¿‡
                            logger.debug(f"[V2] è·³è¿‡é”™è¯¯å“åº”: {data.get('error', 'Unknown error')}")
                        elif isinstance(data, dict) and 'tables' in data:
                            # list_tables å“åº”ï¼Œè·³è¿‡
                            logger.debug(f"[V2] è·³è¿‡ list_tables å“åº”")
                    elif isinstance(content, list):
                        if all(isinstance(row, dict) for row in content):
                            extracted_data = content
                            logger.info(f"[V2] æå–åˆ°æ•°æ®: {len(content)} è¡Œ")
                            break
                except (ValueError, TypeError, AttributeError, json.JSONDecodeError) as e:
                    logger.debug(f"[V2] æ•°æ®æå–è·³è¿‡: {e}")

        # åº”ç”¨æ•°æ®éªŒè¯
        if DATA_VALIDATION_AVAILABLE and extracted_data and len(extracted_data) > 0:
            try:
                logger.info("[V2] åº”ç”¨æ•°æ®ä¸€è‡´æ€§éªŒè¯...")

                # 1. éªŒè¯æ•°æ®ä¸€è‡´æ€§
                validation_result = validate_sql_data_consistency(
                    executed_sql=extracted_sql or "SELECT * FROM unknown",
                    query_results=extracted_data
                )
                logger.info(f"[V2] éªŒè¯ç»“æœ: is_valid={validation_result.is_valid}, actual_columns={validation_result.actual_columns}")

                # 2. æ™ºèƒ½å­—æ®µæ˜ å°„
                field_mapping = smart_field_mapping(extracted_data, extracted_sql)
                logger.info(f"[V2] å­—æ®µæ˜ å°„: x_field={field_mapping.x_field}, y_field={field_mapping.y_field}, confidence={field_mapping.confidence}")

                # 3. å›¾è¡¨æ¨è
                chart_rec = recommend_chart(extracted_data, extracted_sql, request.query)
                logger.info(f"[V2] å›¾è¡¨æ¨è: chart_type={chart_rec.chart_type}")

                # 4. æ„å»ºå›¾è¡¨é…ç½®
                if field_mapping.x_field and field_mapping.y_field:
                    chart_config = {
                        "chart_type": chart_rec.chart_type,
                        "x_field": field_mapping.x_field,
                        "y_field": field_mapping.y_field,
                        "title": chart_rec.title,
                        "reasoning": chart_rec.reasoning
                    }
                    logger.info(f"[V2] å›¾è¡¨é…ç½®å·²ç”Ÿæˆ: {chart_config}")

            except Exception as e:
                logger.error(f"[V2] æ•°æ®éªŒè¯å¤±è´¥: {e}")
                import traceback
                logger.debug(traceback.format_exc())

        # ========== [æ•°æ®éªŒè¯æ¨¡å—ç»“æŸ] ==========

        # æå–æœ€åä¸€æ¡æ¶ˆæ¯ä½œä¸ºå›ç­”
        if messages:
            last_message = messages[-1]
            if hasattr(last_message, "content"):
                answer = last_message.content
            elif isinstance(last_message, dict):
                answer = last_message.get("content", str(last_message))
            else:
                answer = str(last_message)

        # æ„å»ºå¤„ç†æ­¥éª¤
        processing_steps = [
            "æ¥æ”¶æŸ¥è¯¢",
            "ç§Ÿæˆ·éš”ç¦»éªŒè¯",
            "AgentV2 å¤„ç†",
            "DeepSeek LLM è°ƒç”¨",
        ]

        # å¦‚æœå¯ç”¨äº†æ•°æ®éªŒè¯ï¼Œæ·»åŠ ç›¸åº”æ­¥éª¤
        if DATA_VALIDATION_AVAILABLE and extracted_data:
            processing_steps.extend([
                "æ•°æ®ä¸€è‡´æ€§éªŒè¯",
                "æ™ºèƒ½å­—æ®µæ˜ å°„",
                "å›¾è¡¨é…ç½®ç”Ÿæˆ",
            ])

        processing_steps.append("è¿”å›ç»“æœ")

        logger.info(f"[V2] å›ç­”é•¿åº¦: {len(answer)} å­—ç¬¦")

        # è®¡ç®—è¡Œæ•°
        row_count = len(extracted_data) if extracted_data else 0

        # æ„å»ºå“åº”å¯¹è±¡
        response_obj = QueryResponseV2(
            success=True,
            answer=answer,
            sql=extracted_sql,  # è¿”å›æå–çš„ SQL
            data=extracted_data,  # è¿”å›æå–çš„æ•°æ®
            row_count=row_count,
            processing_steps=processing_steps,
            subagent_calls=subagent_calls,
            reasoning_log={
                "timestamp": start_time,
                "steps": len(processing_steps),
                "query": request.query,
                "answer_length": len(answer),
                "data_validation_enabled": DATA_VALIDATION_AVAILABLE,
            },
            chart_config=chart_config,  # è¿”å›å›¾è¡¨é…ç½®
            tenant_id=tenant_id,
            processing_time_ms=processing_time
        )

        # å­˜å‚¨åˆ°ç¼“å­˜
        if AGENTV2_AVAILABLE:
            response_cache = get_response_cache()
            response_cache.set(
                query=request.query,
                response=response_obj.model_dump(),
                tenant_id=tenant_id,
                connection_id=request.connection_id,
                context={"data_sources": []}
            )
            logger.info(f"[V2] å“åº”å·²ç¼“å­˜: {request.query[:30]}...")

        return response_obj

    except HTTPException:
        raise

    except Exception as e:
        processing_time = int((time.time() - start_time) * 1000)

        # è¿”å›é”™è¯¯å“åº”
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={
                "success": False,
                "error": str(e),
                "error_type": "internal_error",
                "tenant_id": tenant_id,
                "processing_time_ms": processing_time
            }
        )


@router.get("/cache/stats")
async def get_cache_stats_v2():
    """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    if not AGENTV2_AVAILABLE:
        return {"error": "AgentV2 not available"}

    try:
        from AgentV2.core import get_cache_stats
        stats = get_cache_stats()
        return {
            "success": True,
            "cache_stats": stats
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@router.get("/health")
async def health_check_v2():
    """V2 å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "healthy",
        "version": "2.0.0",
        "framework": "DeepAgents",
        "features": [
            "tenant_isolation",
            "sql_security",
            "subagent_architecture",
            "xai_logging"
        ]
    }


@router.get("/capabilities")
async def get_capabilities_v2():
    """è·å– V2 èƒ½åŠ›åˆ—è¡¨"""
    return {
        "version": "2.0.0",
        "features": {
            "tenant_isolation": {
                "enabled": True,
                "description": "å¤šç§Ÿæˆ·æ•°æ®å®Œå…¨éš”ç¦»"
            },
            "sql_security": {
                "enabled": True,
                "description": "è‡ªåŠ¨ SQL å®‰å…¨éªŒè¯ï¼Œæ‹¦æˆªå±é™©æ“ä½œ"
            },
            "subagent_architecture": {
                "enabled": True,
                "description": "ä¸“ä¸šåŒ–å­ä»£ç†å§”æ´¾",
                "available_subagents": ["sql_expert", "chart_expert", "file_expert"]
            },
            "xai_logging": {
                "enabled": True,
                "description": "å¯è§£é‡Šæ€§ AI æ—¥å¿—ï¼Œè®°å½•æ¨ç†è¿‡ç¨‹"
            },
            "mcp_integration": {
                "enabled": True,
                "description": "Model Context Protocol å·¥å…·é›†æˆ"
            }
        },
        "supported_query_types": [
            "natural_language",
            "sql_generation",
            "data_analysis",
            "chart_generation"
        ]
    }


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def _extract_sql_from_response(response: str) -> Optional[str]:
    """ä»å“åº”ä¸­æå– SQL è¯­å¥"""
    import re

    # ç®€å•çš„ SQL æå–ï¼ˆå®é™…å®ç°éœ€è¦æ›´å¤æ‚çš„è§£æï¼‰
    sql_pattern = r"```sql\n?(SELECT.*?)\n?```"
    match = re.search(sql_pattern, response, re.DOTALL | re.IGNORECASE)

    if match:
        return match.group(1).strip()

    # å°è¯•ç›´æ¥æŸ¥æ‰¾ SELECT è¯­å¥
    lines = response.split('\n')
    for line in lines:
        line = line.strip()
        if line.upper().startswith('SELECT'):
            return line

    return None


def _sanitize_response_for_tenant(response: str, tenant_id: str) -> str:
    """ç¡®ä¿å“åº”ä¸­ä¸åŒ…å«å…¶ä»–ç§Ÿæˆ·çš„æ•°æ®"""
    # è¿™é‡Œå¯ä»¥æ·»åŠ é¢å¤–çš„è¿‡æ»¤é€»è¾‘
    return response


# ============================================================================
# æµ‹è¯•ä»£ç 
# ============================================================================

if __name__ == "__main__":
    import uvicorn

    print("=" * 60)
    print("å¯åŠ¨ AgentV2 Query API æµ‹è¯•æœåŠ¡å™¨")
    print("=" * 60)

    print("\n[INFO] å¯ç”¨ç«¯ç‚¹:")
    print("  - POST /api/v2/query/")
    print("  - GET  /api/v2/query/health")
    print("  - GET  /api/v2/query/capabilities")

    print("\n[INFO] å¯åŠ¨æœåŠ¡å™¨...")
    uvicorn.run(
        "query_v2:router",
        host="0.0.0.0",
        port=8005,
        log_level="info"
    )
