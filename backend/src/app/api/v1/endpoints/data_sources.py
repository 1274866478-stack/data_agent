"""
æ•°æ®æºè¿æ¥ç®¡ç†ç«¯ç‚¹
å®ç°Story 2.3è¦æ±‚çš„å®Œæ•´APIåŠŸèƒ½
"""

from fastapi import APIRouter, Depends, HTTPException, status, UploadFile, File, Form, Request
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session
from typing import List, Optional, Dict, Any
from datetime import datetime
import logging
import uuid
import os
import tempfile
import json

from src.app.data.database import get_db
from src.app.data.models import DataSourceConnection, Tenant, DataSourceConnectionStatus, TenantStatus
from src.app.services.data_source_service import data_source_service
from src.app.services.connection_test_service import connection_test_service
from src.app.services.minio_client import minio_service

logger = logging.getLogger(__name__)
router = APIRouter()


# Pydanticæ¨¡å‹å®šä¹‰
class DataSourceCreateRequest(BaseModel):
    """åˆ›å»ºæ•°æ®æºè¯·æ±‚æ¨¡å‹"""
    name: str = Field(..., min_length=1, max_length=255, description="æ•°æ®æºåç§°")
    connection_string: str = Field(..., min_length=1, description="æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²")
    db_type: str = Field(default="postgresql", description="æ•°æ®åº“ç±»å‹")


class DataSourceUpdateRequest(BaseModel):
    """æ›´æ–°æ•°æ®æºè¯·æ±‚æ¨¡å‹"""
    name: Optional[str] = Field(None, min_length=1, max_length=255, description="æ•°æ®æºåç§°")
    connection_string: Optional[str] = Field(None, min_length=1, description="æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²")
    db_type: Optional[str] = Field(None, description="æ•°æ®åº“ç±»å‹")
    is_active: Optional[bool] = Field(None, description="æ˜¯å¦æ¿€æ´»")


class ConnectionTestRequest(BaseModel):
    """è¿æ¥æµ‹è¯•è¯·æ±‚æ¨¡å‹"""
    connection_string: str = Field(..., min_length=1, description="æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²")
    db_type: str = Field(default="postgresql", description="æ•°æ®åº“ç±»å‹")


class DataSourceResponse(BaseModel):
    """æ•°æ®æºå“åº”æ¨¡å‹"""
    id: str
    tenant_id: str
    name: str
    db_type: str
    status: str
    host: Optional[str]
    port: Optional[int]
    database_name: Optional[str]
    last_tested_at: Optional[datetime]
    test_result: Optional[Dict[str, Any]]
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True


# APIç«¯ç‚¹å®ç°
@router.get("/", summary="è·å–æ•°æ®æºè¿æ¥åˆ—è¡¨", response_model=List[DataSourceResponse])
async def get_data_sources(
    tenant_id: str = None,  # å®é™…åº”è¯¥ä»è®¤è¯ä¸­é—´ä»¶è·å–
    db_type: Optional[str] = None,
    skip: int = 0,
    limit: int = 100,
    active_only: bool = True,
    db: Session = Depends(get_db)
):
    """
    è·å–æ•°æ®æºè¿æ¥åˆ—è¡¨
    æ”¯æŒç§Ÿæˆ·éš”ç¦»å’Œç­›é€‰åŠŸèƒ½
    """
    # TODO: ä»JWT tokenæˆ–è®¤è¯ä¸­é—´ä»¶è·å–tenant_id
    if not tenant_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="tenant_id is required"
        )

    try:
        connections = await data_source_service.get_data_sources(
            tenant_id=tenant_id,
            db=db,
            active_only=active_only,
            skip=skip,
            limit=limit
        )

        # è¿‡æ»¤æ•°æ®åº“ç±»å‹
        if db_type:
            connections = [conn for conn in connections if conn.db_type == db_type]

        return [DataSourceResponse.from_orm(conn) for conn in connections]

    except Exception as e:
        logger.error(f"Failed to fetch data sources: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to fetch data sources: {str(e)}"
        )


# ============================================================================
# å›ºå®šè·¯å¾„ç«¯ç‚¹ï¼ˆå¿…é¡»åœ¨ /{connection_id} ä¹‹å‰å®šä¹‰ï¼Œå¦åˆ™ä¼šè¢«åŠ¨æ€è·¯ç”±åŒ¹é…ï¼‰
# ============================================================================

# æ”¯æŒçš„æ–‡ä»¶ç±»å‹é…ç½®
SUPPORTED_FILE_TYPES = {
    'csv': {
        'mime_types': ['text/csv', 'application/vnd.ms-excel'],
        'max_size_mb': 100,
        'extensions': ['.csv']
    },
    'xlsx': {
        'mime_types': ['application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'],
        'max_size_mb': 100,
        'extensions': ['.xlsx']
    },
    'xls': {
        'mime_types': ['application/vnd.ms-excel'],
        'max_size_mb': 100,
        'extensions': ['.xls']
    },
    'sqlite': {
        'mime_types': ['application/x-sqlite3', 'application/vnd.sqlite3', 'application/octet-stream'],
        'max_size_mb': 500,
        'extensions': ['.db', '.sqlite', '.sqlite3']
    }
}


def _validate_file_type(filename: str, content_type: str, file_size: int) -> Dict[str, Any]:
    """éªŒè¯æ–‡ä»¶ç±»å‹å’Œå¤§å°"""
    ext = os.path.splitext(filename)[1].lower()

    for file_type, config in SUPPORTED_FILE_TYPES.items():
        if ext in config['extensions']:
            max_size_bytes = config['max_size_mb'] * 1024 * 1024
            if file_size > max_size_bytes:
                return {
                    "valid": False,
                    "error": "FILE_TOO_LARGE",
                    "message": f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ï¼Œæœ€å¤§å…è®¸ {config['max_size_mb']}MB"
                }
            return {
                "valid": True,
                "file_type": file_type,
                "extension": ext
            }

    return {
        "valid": False,
        "error": "UNSUPPORTED_FILE_TYPE",
        "message": f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {ext}ã€‚æ”¯æŒçš„ç±»å‹: .csv, .xlsx, .xls, .db, .sqlite, .sqlite3"
    }


@router.post("/upload", summary="ä¸Šä¼ æ•°æ®æ–‡ä»¶åˆ›å»ºæ•°æ®æº", status_code=status.HTTP_201_CREATED)
async def upload_data_source(
    file: UploadFile = File(..., description="æ•°æ®æ–‡ä»¶ (CSV, Excel, SQLite)"),
    name: str = Form(..., description="æ•°æ®æºåç§°"),
    db_type: Optional[str] = Form(None, description="æ•°æ®ç±»å‹"),
    tenant_id: Optional[str] = None,
    request: Request = None,
    db: Session = Depends(get_db)
):
    """
    ä¸Šä¼ æ•°æ®æ–‡ä»¶åˆ›å»ºæ•°æ®æº
    æ”¯æŒ CSVã€Excel (.xls/.xlsx) å’Œ SQLite æ•°æ®åº“ (.db/.sqlite/.sqlite3) æ–‡ä»¶
    """
    # ä»æŸ¥è¯¢å‚æ•°è·å–tenant_id
    if not tenant_id and request:
        tenant_id = request.query_params.get("tenant_id")

    if not tenant_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="tenant_id is required"
        )

    # éªŒè¯æ–‡ä»¶å
    if not file.filename:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æ–‡ä»¶åä¸èƒ½ä¸ºç©º"
        )

    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        file_content = await file.read()
        file_size = len(file_content)

        # éªŒè¯æ–‡ä»¶ç±»å‹å’Œå¤§å°
        validation_result = _validate_file_type(
            file.filename,
            file.content_type or "application/octet-stream",
            file_size
        )

        if not validation_result["valid"]:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=validation_result["message"]
            )

        detected_file_type = validation_result["file_type"]

        # ç”Ÿæˆå”¯ä¸€çš„å­˜å‚¨è·¯å¾„
        file_id = str(uuid.uuid4())
        file_ext = validation_result["extension"]
        storage_path = f"data-sources/{tenant_id}/{file_id}{file_ext}"

        # ğŸš¨ ä¿®å¤ç­–ç•¥ï¼šå¼ºåˆ¶è½åœ°é€»è¾‘ - ç¡®ä¿æ–‡ä»¶ä¸€å®šä¼šä¿å­˜åˆ°æœ¬åœ°ç£ç›˜
        import io
        import os
        
        # å®šä¹‰æœ¬åœ°å­˜å‚¨ç›®å½•ï¼ˆä½¿ç”¨Dockerå·æŒ‚è½½çš„ç›®å½•ï¼‰
        local_upload_dir = "/app/uploads/data-sources"
        tenant_upload_dir = os.path.join(local_upload_dir, tenant_id)
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(tenant_upload_dir, exist_ok=True)
        
        # æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼ˆå®¹å™¨å†…ç»å¯¹è·¯å¾„ï¼‰
        local_file_path = os.path.join(tenant_upload_dir, f"{file_id}{file_ext}")
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ— è®ºMinIOæ˜¯å¦æˆåŠŸï¼Œéƒ½å…ˆä¿å­˜åˆ°æœ¬åœ°ç£ç›˜
        try:
            with open(local_file_path, "wb") as f:
                f.write(file_content)
            logger.info(f"âœ… æ–‡ä»¶å·²å¼ºåˆ¶ä¿å­˜åˆ°æœ¬åœ°: {local_file_path}")
        except Exception as save_error:
            logger.error(f"âŒ ä¿å­˜æ–‡ä»¶åˆ°æœ¬åœ°å¤±è´¥: {save_error}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(save_error)}"
            )
        
        # å°è¯•ä¸Šä¼ åˆ° MinIOï¼ˆå¯é€‰ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰
        minio_upload_success = False
        try:
            upload_success = minio_service.upload_file(
                bucket_name="data-sources",
                object_name=storage_path,
                file_data=io.BytesIO(file_content),
                file_size=file_size,
                content_type=file.content_type or "application/octet-stream"
            )
            if upload_success:
                minio_upload_success = True
                logger.info(f"âœ… æ–‡ä»¶å·²åŒæ—¶ä¸Šä¼ åˆ°MinIO: {storage_path}")
        except Exception as e:
            logger.warning(f"âš ï¸ MinIOä¸Šä¼ å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")

        # åˆ›å»ºæ•°æ®æºè®°å½•
        # ğŸ”§ ä¿®å¤ï¼šç»Ÿä¸€è·¯å¾„æ ¼å¼
        # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼ˆå®¹å™¨å†…ç»å¯¹è·¯å¾„ï¼‰ï¼Œç¡®ä¿Agentä¸€å®šèƒ½æ‰¾åˆ°æ–‡ä»¶
        # æ ¼å¼ï¼š/app/uploads/data-sources/{tenant_id}/{file_id}{ext}
        connection_string = local_file_path  # ç›´æ¥ä½¿ç”¨å®¹å™¨å†…ç»å¯¹è·¯å¾„ï¼Œç¡®ä¿Agentèƒ½æ‰¾åˆ°æ–‡ä»¶

        new_connection = DataSourceConnection(
            tenant_id=tenant_id,
            name=name,
            db_type=db_type or detected_file_type,
            connection_string=connection_string,
            status=DataSourceConnectionStatus.ACTIVE,
            host=None,
            port=None,
            database_name=file.filename
        )

        db.add(new_connection)
        db.commit()
        db.refresh(new_connection)

        logger.info(f"Created file-based data source '{name}' for tenant '{tenant_id}'")

        return {
            "id": str(new_connection.id),
            "tenant_id": new_connection.tenant_id,
            "name": new_connection.name,
            "db_type": new_connection.db_type,
            "status": new_connection.status.value if hasattr(new_connection.status, 'value') else str(new_connection.status),
            "host": new_connection.host,
            "port": new_connection.port,
            "database_name": new_connection.database_name,
            "last_tested_at": new_connection.last_tested_at,
            "test_result": new_connection.test_result,
            "created_at": new_connection.created_at,
            "updated_at": new_connection.updated_at,
            "file_info": {
                "original_name": file.filename,
                "file_type": detected_file_type,
                "file_size": file_size,
                "storage_path": storage_path
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to upload data source: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ä¸Šä¼ æ•°æ®æºå¤±è´¥: {str(e)}"
        )


@router.get("/overview", summary="è·å–æ•°æ®æºæ¦‚è§ˆç»Ÿè®¡")
async def get_data_sources_overview_route(
    tenant_id: str = None,
    user_id: str = None,
    db: Session = Depends(get_db)
):
    """
    è·å–æ•°æ®æºå’Œæ–‡æ¡£çš„æ¦‚è§ˆç»Ÿè®¡ä¿¡æ¯
    ç”¨äºä»ªè¡¨æ¿å±•ç¤ºï¼ŒåŒ…å«å®‰å…¨çš„å­˜å‚¨é…é¢è®¡ç®—å’Œæ•°æ®éš”ç¦»
    """
    if not tenant_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="tenant_id is required"
        )

    if not user_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="user_id is required"
        )

    # å¼ºåŒ–çš„ç§Ÿæˆ·éªŒè¯å’Œæƒé™æ£€æŸ¥
    await _validate_overview_access(tenant_id, user_id, db)

    try:
        # å®‰å…¨åœ°è·å–æ•°æ®åº“è¿æ¥ç»Ÿè®¡
        db_stats = await _get_secure_database_stats(tenant_id, db)
        doc_stats = await _get_secure_document_stats(tenant_id, db)
        storage_stats = await _get_secure_storage_stats(tenant_id, db)
        recent_activity = await _get_secure_recent_activity(tenant_id, db)

        logger.info(f"Overview accessed by user {user_id} for tenant {tenant_id}")

        return {
            "databases": db_stats,
            "documents": doc_stats,
            "storage": storage_stats,
            "recent_activity": recent_activity
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to fetch data sources overview for tenant {tenant_id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to fetch overview statistics"
        )


@router.get("/search", summary="æœç´¢æ•°æ®æº")
async def search_data_sources_route(
    q: str = "",
    type: str = "all",
    status_filter: Optional[str] = None,
    date_from: Optional[str] = None,
    date_to: Optional[str] = None,
    page: int = 1,
    limit: int = 20,
    tenant_id: str = None,
    user_id: str = None,
    db: Session = Depends(get_db)
):
    """æœç´¢æ•°æ®æºå’Œæ–‡æ¡£"""
    if not tenant_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="tenant_id is required"
        )

    if not user_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="user_id is required"
        )

    await _validate_search_parameters(q, type, status_filter, date_from, date_to, page, limit)
    await _validate_tenant_search_access(tenant_id, user_id, db)

    try:
        results = []
        total_count = 0

        if type in ["all", "database"]:
            query = db.query(DataSourceConnection).filter(
                DataSourceConnection.tenant_id == tenant_id,
                DataSourceConnection.status != DataSourceConnectionStatus.INACTIVE
            )

            if q:
                safe_query = _sanitize_search_query(q)
                query = query.filter(
                    DataSourceConnection.name.contains(safe_query) |
                    DataSourceConnection.db_type.contains(safe_query)
                )

            if status_filter:
                valid_statuses = _validate_and_parse_statuses(status_filter)
                if valid_statuses:
                    query = query.filter(DataSourceConnection.status.in_(valid_statuses))

            if date_from or date_to:
                date_range = _validate_and_parse_date_range(date_from, date_to)
                if date_range['from']:
                    query = query.filter(DataSourceConnection.created_at >= date_range['from'])
                if date_range['to']:
                    query = query.filter(DataSourceConnection.created_at <= date_range['to'])

            db_total = query.with_entities(DataSourceConnection.id).count()
            total_count += db_total

            safe_limit = min(limit, 100)
            safe_page = max(1, min(page, 1000))

            db_results = query.offset((safe_page - 1) * safe_limit).limit(safe_limit).all()

            for conn in db_results:
                if conn.tenant_id != tenant_id:
                    continue
                results.append({
                    "id": conn.id,
                    "type": "database",
                    "name": conn.name,
                    "status": conn.status.value if hasattr(conn.status, 'value') else str(conn.status),
                    "created_at": conn.created_at.isoformat(),
                    "updated_at": conn.updated_at.isoformat(),
                    "db_type": conn.db_type,
                    "host": conn.host,
                    "port": conn.port
                })

        total_pages = (total_count + safe_limit - 1) // safe_limit

        return {
            "results": results,
            "total": total_count,
            "page": safe_page,
            "limit": safe_limit,
            "total_pages": total_pages
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to search data sources for tenant {tenant_id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Search operation failed"
        )


class BulkDeleteRequestModel(BaseModel):
    """æ‰¹é‡åˆ é™¤è¯·æ±‚æ¨¡å‹"""
    item_ids: List[str] = Field(..., min_length=1, max_length=50)
    item_type: str = Field(..., pattern=r"^(database|document)$")
    confirmation_token: Optional[str] = None


@router.post("/bulk-delete", summary="æ‰¹é‡åˆ é™¤æ•°æ®æº")
async def bulk_delete_data_sources_route(
    request: BulkDeleteRequestModel,
    tenant_id: str = None,
    user_id: str = None,
    db: Session = Depends(get_db)
):
    """æ‰¹é‡åˆ é™¤æ•°æ®æºæˆ–æ–‡æ¡£"""
    if not tenant_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="tenant_id is required"
        )

    if not user_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="user_id is required"
        )

    if len(request.item_ids) > 50:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Cannot delete more than 50 items at once"
        )

    tenant = db.query(Tenant).filter(
        Tenant.id == tenant_id,
        Tenant.status == TenantStatus.ACTIVE
    ).first()

    if not tenant:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Invalid or inactive tenant"
        )

    success_count = 0
    error_count = 0
    errors = []
    deleted_items = []

    try:
        if request.item_type == "database":
            await _validate_bulk_database_delete_permission(tenant_id, user_id, request.item_ids, db)

            for item_id in request.item_ids:
                try:
                    connection = db.query(DataSourceConnection).filter(
                        DataSourceConnection.id == item_id,
                        DataSourceConnection.tenant_id == tenant_id,
                        DataSourceConnection.status != DataSourceConnectionStatus.INACTIVE
                    ).first()

                    if not connection:
                        error_count += 1
                        errors.append({"item_id": item_id, "error": "Data source not found"})
                        continue

                    if not await _can_delete_data_source(connection, db):
                        error_count += 1
                        errors.append({"item_id": item_id, "error": "Data source cannot be deleted"})
                        continue

                    connection.status = DataSourceConnectionStatus.INACTIVE
                    connection.updated_at = datetime.now()
                    deleted_items.append({"item_id": item_id, "name": connection.name, "type": "database"})
                    success_count += 1

                except Exception as e:
                    error_count += 1
                    errors.append({"item_id": item_id, "error": str(e)})

        elif request.item_type == "document":
            for item_id in request.item_ids:
                error_count += 1
                errors.append({"item_id": item_id, "error": "Document deletion not implemented"})

        db.commit()
        return {
            "success_count": success_count,
            "error_count": error_count,
            "errors": errors,
            "deleted_items": deleted_items
        }

    except HTTPException:
        db.rollback()
        raise
    except Exception as e:
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Bulk delete failed: {str(e)}"
        )


@router.get("/types/supported", summary="è·å–æ”¯æŒçš„æ•°æ®æºç±»å‹")
async def get_supported_data_source_types_route():
    """è·å–æ”¯æŒçš„æ•°æ®æºç±»å‹åˆ—è¡¨"""
    try:
        return connection_test_service.get_supported_database_types()
    except Exception as e:
        logger.error(f"Failed to get supported database types: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get supported database types: {str(e)}"
        )


# ============================================================================
# å›ºå®šè·¯å¾„ POST ç«¯ç‚¹ï¼ˆå¿…é¡»åœ¨åŠ¨æ€è·¯å¾„ç«¯ç‚¹ä¹‹å‰å®šä¹‰ï¼‰
# ============================================================================

@router.post("/", summary="åˆ›å»ºæ•°æ®æºè¿æ¥", status_code=status.HTTP_201_CREATED, response_model=DataSourceResponse)
async def create_data_source(
    request: DataSourceCreateRequest,
    tenant_id: str = None,  # å®é™…åº”è¯¥ä»è®¤è¯ä¸­é—´ä»¶è·å–
    db: Session = Depends(get_db)
):
    """
    åˆ›å»ºæ–°çš„æ•°æ®æºè¿æ¥
    è‡ªåŠ¨åŠ å¯†è¿æ¥å­—ç¬¦ä¸²å¹¶è§£æè¿æ¥ä¿¡æ¯
    """
    logger.info(f"æ”¶åˆ°åˆ›å»ºæ•°æ®æºè¯·æ±‚: tenant_id={tenant_id}")
    logger.info(f"  - name: '{request.name}'")
    logger.info(f"  - db_type: '{request.db_type}'")
    logger.info(f"  - connection_string: '{request.connection_string}'")
    logger.info(f"  - connection_stringé•¿åº¦: {len(request.connection_string) if request.connection_string else 0}")
    logger.info(f"  - requestå¯¹è±¡: {request.model_dump()}")

    if not tenant_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="tenant_id is required"
        )

    try:
        # å…ˆåŠ å¯†è¿æ¥å­—ç¬¦ä¸²
        encrypted_string = data_source_service.encryption_service.encrypt_connection_string(
            request.connection_string
        )

        # åˆ›å»ºæ•°æ®æºè¿æ¥(ç›´æ¥ä½¿ç”¨åŠ å¯†åçš„å­—ç¬¦ä¸²)
        new_connection = DataSourceConnection(
            tenant_id=tenant_id,
            name=request.name,
            db_type=request.db_type,
            _connection_string=encrypted_string,  # ç›´æ¥è®¾ç½®åŠ å¯†åçš„å­—ç¬¦ä¸²åˆ°ç§æœ‰å­—æ®µ
            status=DataSourceConnectionStatus.TESTING
        )

        # è§£æè¿æ¥å­—ç¬¦ä¸²è·å–è¿æ¥ä¿¡æ¯
        parsed_info = data_source_service._parse_connection_string(
            request.connection_string,
            request.db_type
        )
        new_connection.host = parsed_info.get("host")
        new_connection.port = parsed_info.get("port")
        new_connection.database_name = parsed_info.get("database")

        # ä¿å­˜åˆ°æ•°æ®åº“
        db.add(new_connection)
        db.commit()
        db.refresh(new_connection)

        logger.info(f"Created data source '{request.name}' for tenant '{tenant_id}'")

        # è‡ªåŠ¨æµ‹è¯•è¿æ¥å¹¶æ›´æ–°çŠ¶æ€
        try:
            logger.info(f"Auto-testing connection for data source '{request.name}'...")
            test_result = await connection_test_service.test_connection(
                connection_string=request.connection_string,
                db_type=request.db_type
            )

            # æ›´æ–°è¿æ¥çš„æµ‹è¯•ç»“æœå’ŒçŠ¶æ€
            new_connection.update_test_result(test_result.to_dict())
            db.commit()
            db.refresh(new_connection)

            logger.info(f"Connection test completed: {test_result.success}")
        except Exception as e:
            logger.warning(f"Auto-test failed for data source '{request.name}': {e}")
            # å³ä½¿æµ‹è¯•å¤±è´¥,ä¹Ÿè¿”å›åˆ›å»ºçš„æ•°æ®æº(çŠ¶æ€ä¿æŒä¸ºTESTING)

        return DataSourceResponse.from_orm(new_connection)

    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        logger.error(f"Failed to create data source: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to create data source: {str(e)}"
        )


# ============================================================================
# åŠ¨æ€è·¯å¾„ç«¯ç‚¹ï¼ˆå¿…é¡»åœ¨å›ºå®šè·¯å¾„ç«¯ç‚¹ä¹‹åå®šä¹‰ï¼‰
# ============================================================================

@router.get("/{connection_id}", summary="è·å–æ•°æ®æºè¿æ¥è¯¦æƒ…", response_model=DataSourceResponse)
async def get_data_source(
    connection_id: str,
    tenant_id: str = None,  # å®é™…åº”è¯¥ä»è®¤è¯ä¸­é—´ä»¶è·å–
    db: Session = Depends(get_db)
):
    """
    æ ¹æ®IDè·å–æ•°æ®æºè¿æ¥è¯¦æƒ…
    ç¡®ä¿ç§Ÿæˆ·éš”ç¦»
    """
    if not tenant_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="tenant_id is required"
        )

    try:
        connection = await data_source_service.get_data_source_by_id(
            data_source_id=connection_id,
            tenant_id=tenant_id,
            db=db
        )

        if not connection:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Data source connection not found"
            )

        return DataSourceResponse.from_orm(connection)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to fetch data source {connection_id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to fetch data source: {str(e)}"
        )


@router.put("/{connection_id}", summary="æ›´æ–°æ•°æ®æºè¿æ¥", response_model=DataSourceResponse)
async def update_data_source(
    connection_id: str,
    request: DataSourceUpdateRequest,
    tenant_id: str = None,  # å®é™…åº”è¯¥ä»è®¤è¯ä¸­é—´ä»¶è·å–
    db: Session = Depends(get_db)
):
    """
    æ›´æ–°æ•°æ®æºè¿æ¥ä¿¡æ¯
    æ”¯æŒéƒ¨åˆ†æ›´æ–°ï¼Œè‡ªåŠ¨é‡æ–°åŠ å¯†è¿æ¥å­—ç¬¦ä¸²
    """
    if not tenant_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="tenant_id is required"
        )

    try:
        # è·å–ç°æœ‰è¿æ¥
        connection = await data_source_service.get_data_source_by_id(
            data_source_id=connection_id,
            tenant_id=tenant_id,
            db=db
        )

        if not connection:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Data source connection not found"
            )

        # æ›´æ–°å­—æ®µ
        update_data = request.dict(exclude_unset=True)

        if "name" in update_data:
            # æ£€æŸ¥åç§°æ˜¯å¦å·²å­˜åœ¨
            existing = db.query(DataSourceConnection).filter(
                DataSourceConnection.tenant_id == tenant_id,
                DataSourceConnection.name == update_data["name"],
                DataSourceConnection.id != connection_id
            ).first()

            if existing:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="Data source name already exists for this tenant"
                )

            connection.name = update_data["name"]

        if "connection_string" in update_data:
            # åŠ å¯†æ–°çš„è¿æ¥å­—ç¬¦ä¸²
            encrypted_string = data_source_service.encryption_service.encrypt_connection_string(
                update_data["connection_string"]
            )
            connection.connection_string = encrypted_string

            # è§£ææ–°è¿æ¥å­—ç¬¦ä¸²
            parsed_info = data_source_service._parse_connection_string(
                update_data["connection_string"],
                connection.db_type
            )
            connection.host = parsed_info.get("host")
            connection.port = parsed_info.get("port")
            connection.database_name = parsed_info.get("database")

        if "db_type" in update_data:
            connection.db_type = update_data["db_type"]

        if "is_active" in update_data:
            if update_data["is_active"]:
                connection.status = DataSourceConnectionStatus.ACTIVE
            else:
                connection.status = DataSourceConnectionStatus.INACTIVE

        connection.updated_at = datetime.now()

        db.commit()
        db.refresh(connection)

        logger.info(f"Updated data source {connection_id}")
        return DataSourceResponse.from_orm(connection)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to update data source {connection_id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to update data source: {str(e)}"
        )


@router.delete("/{connection_id}", summary="åˆ é™¤æ•°æ®æºè¿æ¥")
async def delete_data_source(
    connection_id: str,
    tenant_id: str = None,  # å®é™…åº”è¯¥ä»è®¤è¯ä¸­é—´ä»¶è·å–
    db: Session = Depends(get_db)
):
    """
    åˆ é™¤æ•°æ®æºè¿æ¥ï¼ˆè½¯åˆ é™¤ï¼‰
    """
    if not tenant_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="tenant_id is required"
        )

    try:
        success = await data_source_service.delete_data_source(
            data_source_id=connection_id,
            tenant_id=tenant_id,
            db=db
        )

        if success:
            logger.info(f"Deleted data source {connection_id}")
            return {
                "message": f"Data source connection {connection_id} has been deactivated",
                "connection_id": connection_id,
                "status": "deactivated"
            }
        else:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Data source connection not found"
            )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to delete data source {connection_id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to delete data source: {str(e)}"
        )


# æ³¨æ„ï¼š/test å¿…é¡»åœ¨ /{connection_id}/test ä¹‹å‰å®šä¹‰
@router.post("/test", summary="æµ‹è¯•è¿æ¥å­—ç¬¦ä¸²")
async def test_connection_string(request: ConnectionTestRequest):
    """
    æµ‹è¯•è¿æ¥å­—ç¬¦ä¸²æ˜¯å¦æœ‰æ•ˆï¼ˆä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
    """
    try:
        test_result = await connection_test_service.test_connection(
            connection_string=request.connection_string,
            db_type=request.db_type
        )

        logger.info(f"Tested connection string for {request.db_type}: {test_result.success}")
        return test_result.to_dict()

    except Exception as e:
        logger.error(f"Failed to test connection string: {e}")
        return {
            "success": False,
            "message": f"Connection test failed: {str(e)}",
            "error_code": "TEST_EXECUTION_ERROR",
            "timestamp": datetime.now().isoformat()
        }


@router.post("/{connection_id}/test", summary="æµ‹è¯•æ•°æ®æºè¿æ¥")
async def test_data_source_connection(
    connection_id: str,
    tenant_id: str = None,  # å®é™…åº”è¯¥ä»è®¤è¯ä¸­é—´ä»¶è·å–
    db: Session = Depends(get_db)
):
    """
    æµ‹è¯•ç°æœ‰æ•°æ®æºè¿æ¥æ˜¯å¦æœ‰æ•ˆ
    è‡ªåŠ¨æ›´æ–°è¿æ¥çŠ¶æ€å’Œæµ‹è¯•ç»“æœ
    """
    if not tenant_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="tenant_id is required"
        )

    try:
        # è·å–æ•°æ®æºè¿æ¥
        connection = await data_source_service.get_data_source_by_id(
            data_source_id=connection_id,
            tenant_id=tenant_id,
            db=db
        )

        if not connection:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Data source connection not found"
            )

        # å¯¹äºæ–‡ä»¶ç±»å‹çš„æ•°æ®æºï¼ˆxlsx, xls, csvï¼‰ï¼Œä¸éœ€è¦æµ‹è¯•æ•°æ®åº“è¿æ¥
        # åªéœ€è¦æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        file_types = ['xlsx', 'xls', 'csv']
        if connection.db_type in file_types:
            # æ–‡ä»¶ç±»å‹çš„æ•°æ®æºï¼Œç›´æ¥æ ‡è®°ä¸ºæˆåŠŸï¼ˆæ–‡ä»¶å·²ä¸Šä¼ ï¼‰
            test_result_dict = {
                "success": True,
                "message": f"æ–‡ä»¶æ•°æ®æºå·²å°±ç»ª ({connection.db_type.upper()})",
                "error_code": None,
                "response_time_ms": 0,
                "details": {
                    "file_type": connection.db_type,
                    "database_name": connection.database_name
                },
                "timestamp": datetime.now().isoformat()
            }
            connection.update_test_result(test_result_dict)
            db.commit()
            logger.info(f"File data source {connection_id} marked as ready")
            return test_result_dict

        # å°è¯•è·å–è§£å¯†åçš„è¿æ¥å­—ç¬¦ä¸²
        try:
            decrypted_connection_string = connection.connection_string
        except RuntimeError as decrypt_error:
            logger.error(f"Failed to decrypt connection string for data source {connection_id}: {decrypt_error}")
            # è¿”å›è§£å¯†å¤±è´¥çš„æµ‹è¯•ç»“æœ
            test_result_dict = {
                "success": False,
                "message": "Failed to decrypt connection string",
                "error_code": "DECRYPTION_ERROR",
                "response_time_ms": 0,
                "details": {
                    "error": "åŠ å¯†å¯†é’¥å¯èƒ½å·²æ›´æ”¹ï¼Œæ— æ³•è§£å¯†è¿æ¥å­—ç¬¦ä¸²ã€‚è¯·åˆ é™¤æ­¤æ•°æ®æºå¹¶é‡æ–°æ·»åŠ ã€‚"
                },
                "timestamp": datetime.now().isoformat()
            }
            connection.update_test_result(test_result_dict)
            db.commit()
            return test_result_dict

        # æµ‹è¯•è¿æ¥å­—ç¬¦ä¸²
        test_result = await connection_test_service.test_connection(
            connection_string=decrypted_connection_string,
            db_type=connection.db_type
        )

        # æ›´æ–°è¿æ¥çš„æµ‹è¯•ç»“æœå’ŒçŠ¶æ€
        connection.update_test_result(test_result.to_dict())
        db.commit()

        logger.info(f"Tested data source {connection_id}: {test_result.success}")
        return test_result.to_dict()

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to test data source {connection_id}: {e}")
        return {
            "success": False,
            "message": f"Connection test failed: {str(e)}",
            "error_code": "TEST_EXECUTION_ERROR",
            "timestamp": datetime.now().isoformat()
        }


# ============================================================================
# è¾…åŠ©å‡½æ•° - è¢«ä¸Šé¢çš„ç«¯ç‚¹ä½¿ç”¨
# ============================================================================

async def _validate_overview_access(tenant_id: str, user_id: str, db: Session):
    """
    éªŒè¯æ¦‚è§ˆè®¿é—®æƒé™
    """
    # éªŒè¯ç§Ÿæˆ·æ˜¯å¦å­˜åœ¨ä¸”æ´»è·ƒ
    tenant = db.query(Tenant).filter(
        Tenant.id == tenant_id,
        Tenant.status == TenantStatus.ACTIVE
    ).first()

    if not tenant:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Invalid or inactive tenant"
        )

    # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šç”¨æˆ·æƒé™éªŒè¯
    # ä¾‹å¦‚ï¼šæ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æŸ¥çœ‹æ¦‚è§ˆçš„æƒé™


async def _get_secure_database_stats(tenant_id: str, db: Session) -> Dict[str, int]:
    """
    å®‰å…¨åœ°è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯ï¼Œå¼ºåŒ–ç§Ÿæˆ·éš”ç¦»
    """
    try:
        # ä½¿ç”¨å¼ºåŒ–çš„ç§Ÿæˆ·éš”ç¦»æŸ¥è¯¢
        db_connections = db.query(DataSourceConnection).filter(
            DataSourceConnection.tenant_id == tenant_id,
            DataSourceConnection.status != DataSourceConnectionStatus.INACTIVE
        ).with_entities(
            DataSourceConnection.id,
            DataSourceConnection.status,
            DataSourceConnection.tenant_id  # é¢å¤–çš„ç§Ÿæˆ·IDç”¨äºéªŒè¯
        ).all()

        # åŒé‡éªŒè¯ï¼šç¡®ä¿æ‰€æœ‰ç»“æœéƒ½å±äºè¯¥ç§Ÿæˆ·
        verified_connections = []
        for conn in db_connections:
            if conn.tenant_id != tenant_id:
                logger.error(f"Security breach: database {conn.id} from tenant {conn.tenant_id} "
                           f"included in stats for tenant {tenant_id}")
                continue
            verified_connections.append(conn)

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        db_total = len(verified_connections)
        db_active = len([conn for conn in verified_connections
                        if conn.status == DataSourceConnectionStatus.ACTIVE])
        db_error = len([conn for conn in verified_connections
                       if conn.status == DataSourceConnectionStatus.ERROR])

        return {
            "total": db_total,
            "active": db_active,
            "error": db_error
        }

    except Exception as e:
        logger.error(f"Failed to get database stats for tenant {tenant_id}: {e}")
        # è¿”å›å®‰å…¨çš„é»˜è®¤å€¼
        return {
            "total": 0,
            "active": 0,
            "error": 0
        }


async def _get_secure_document_stats(tenant_id: str, db: Session) -> Dict[str, int]:
    """
    å®‰å…¨åœ°è·å–æ–‡æ¡£ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        # TODO: å®ç°æ–‡æ¡£ç»Ÿè®¡æŸ¥è¯¢ï¼Œéœ€è¦Documentæ¨¡å‹
        # ç¡®ä¿æŸ¥è¯¢åŒ…å«å¼ºåŒ–çš„ç§Ÿæˆ·éš”ç¦»
        return {
            "total": 0,
            "ready": 0,
            "processing": 0,
            "error": 0
        }

    except Exception as e:
        logger.error(f"Failed to get document stats for tenant {tenant_id}: {e}")
        return {
            "total": 0,
            "ready": 0,
            "processing": 0,
            "error": 0
        }


async def _get_secure_storage_stats(tenant_id: str, db: Session) -> Dict[str, any]:
    """
    å®‰å…¨åœ°è·å–å­˜å‚¨é…é¢å’Œä½¿ç”¨æƒ…å†µç»Ÿè®¡
    """
    try:
        # è·å–ç§Ÿæˆ·çš„å­˜å‚¨é…é¢é…ç½®
        tenant = db.query(Tenant).filter(
            Tenant.id == tenant_id,
            Tenant.status == TenantStatus.ACTIVE
        ).with_entities(
            Tenant.storage_quota_mb
        ).first()

        if not tenant:
            # ç§Ÿæˆ·ä¸å­˜åœ¨ï¼Œè¿”å›å®‰å…¨çš„é»˜è®¤å€¼
            return {
                "used_mb": 0,
                "quota_mb": 1024,  # é»˜è®¤é…é¢
                "usage_percentage": 0.0,
                "quota_exceeded": False
            }

        storage_quota_mb = tenant.storage_quota_mb or 1024  # é»˜è®¤1GB

        # TODO: å®ç°å®é™…å­˜å‚¨ä½¿ç”¨é‡è®¡ç®—
        # è¿™é‡Œåº”è¯¥ä»MinIOè·å–å®é™…çš„å­˜å‚¨ä½¿ç”¨é‡
        storage_used_mb = 0  # å®é™…å®ç°éœ€è¦æŸ¥è¯¢MinIO

        # å®‰å…¨åœ°è®¡ç®—ä½¿ç”¨ç™¾åˆ†æ¯”ï¼Œé˜²æ­¢é™¤é›¶é”™è¯¯
        usage_percentage = 0.0
        if storage_quota_mb > 0:
            usage_percentage = min(100.0, round((storage_used_mb / storage_quota_mb) * 100, 2))

        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é…é¢
        quota_exceeded = storage_used_mb > storage_quota_mb

        # å¦‚æœé…é¢ä½¿ç”¨ç‡è¿‡é«˜ï¼Œè®°å½•è­¦å‘Š
        if usage_percentage > 90:
            logger.warning(f"High storage usage for tenant {tenant_id}: {usage_percentage}%")

        return {
            "used_mb": storage_used_mb,
            "quota_mb": storage_quota_mb,
            "usage_percentage": usage_percentage,
            "quota_exceeded": quota_exceeded
        }

    except Exception as e:
        logger.error(f"Failed to get storage stats for tenant {tenant_id}: {e}")
        # è¿”å›å®‰å…¨çš„é»˜è®¤å€¼
        return {
            "used_mb": 0,
            "quota_mb": 1024,
            "usage_percentage": 0.0,
            "quota_exceeded": False
        }


async def _get_secure_recent_activity(tenant_id: str, db: Session) -> List[Dict[str, any]]:
    """
    å®‰å…¨åœ°è·å–æœ€è¿‘æ´»åŠ¨è®°å½•ï¼ŒåŒ…å«å¼ºåŒ–çš„ç§Ÿæˆ·éš”ç¦»
    """
    try:
        # è·å–æœ€è¿‘çš„æ•°æ®åº“è¿æ¥æ´»åŠ¨
        recent_connections = db.query(DataSourceConnection).filter(
            DataSourceConnection.tenant_id == tenant_id
        ).with_entities(
            DataSourceConnection.id,
            DataSourceConnection.name,
            DataSourceConnection.status,
            DataSourceConnection.created_at,
            DataSourceConnection.updated_at,
            DataSourceConnection.tenant_id  # ç”¨äºéªŒè¯
        ).order_by(DataSourceConnection.updated_at.desc()).limit(5).all()

        recent_activity = []
        for conn in recent_connections:
            # åŒé‡éªŒè¯ï¼šç¡®ä¿æ´»åŠ¨è®°å½•å±äºè¯¥ç§Ÿæˆ·
            if conn.tenant_id != tenant_id:
                logger.error(f"Security breach: activity for database {conn.id} from tenant {conn.tenant_id} "
                           f"included in activity for tenant {tenant_id}")
                continue

            # è¿‡æ»¤æ•æ„Ÿä¿¡æ¯ï¼Œåªè¿”å›å¿…è¦çš„æ´»åŠ¨æ•°æ®
            activity = {
                "id": conn.id,
                "type": "database",
                "action": "updated" if conn.updated_at != conn.created_at else "created",
                "item_name": conn.name,
                "timestamp": conn.updated_at.isoformat() if conn.updated_at else conn.created_at.isoformat(),
                "status": "success" if conn.status == DataSourceConnectionStatus.ACTIVE else "error"
            }
            recent_activity.append(activity)

        return recent_activity

    except Exception as e:
        logger.error(f"Failed to get recent activity for tenant {tenant_id}: {e}")
        return []


async def _validate_search_parameters(
    q: str,
    type: str,
    status: Optional[str],
    date_from: Optional[str],
    date_to: Optional[str],
    page: int,
    limit: int
):
    """
    éªŒè¯æœç´¢å‚æ•°çš„å®‰å…¨æ€§å’Œæœ‰æ•ˆæ€§
    """
    # éªŒè¯æœç´¢æŸ¥è¯¢
    if q:
        if len(q) > 100:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Search query too long (max 100 characters)"
            )
        # æ£€æŸ¥æ½œåœ¨çš„æ³¨å…¥æ”»å‡»æ¨¡å¼
        dangerous_patterns = ["'", '"', ';', '--', '/*', '*/', 'xp_', 'sp_']
        for pattern in dangerous_patterns:
            if pattern in q.lower():
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="Invalid search query pattern"
                )

    # éªŒè¯ç±»å‹å‚æ•°
    if type not in ["all", "database", "document"]:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Invalid type parameter"
        )

    # éªŒè¯åˆ†é¡µå‚æ•°
    if page < 1 or page > 1000:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Invalid page parameter"
        )

    if limit < 1 or limit > 100:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Invalid limit parameter (max 100)"
        )


async def _validate_tenant_search_access(tenant_id: str, user_id: str, db: Session):
    """
    éªŒè¯ç§Ÿæˆ·æœç´¢è®¿é—®æƒé™
    """
    # éªŒè¯ç§Ÿæˆ·æ˜¯å¦å­˜åœ¨ä¸”æ´»è·ƒ
    tenant = db.query(Tenant).filter(
        Tenant.id == tenant_id,
        Tenant.status == TenantStatus.ACTIVE
    ).first()

    if not tenant:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Invalid or inactive tenant"
        )

    # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šç”¨æˆ·æƒé™éªŒè¯
    # ä¾‹å¦‚ï¼šæ£€æŸ¥ç”¨æˆ·æ˜¯å¦å±äºè¯¥ç§Ÿæˆ·


def _sanitize_search_query(query: str) -> str:
    """
    æ¸…ç†æœç´¢æŸ¥è¯¢ï¼Œé˜²æ­¢æ³¨å…¥æ”»å‡»
    """
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
    import re
    sanitized = re.sub(r"[\'\"\\\;\-\-\/\*\*]", "", query)
    return sanitized.strip()


def _validate_and_parse_statuses(status: str) -> List[str]:
    """
    éªŒè¯å’Œè§£æçŠ¶æ€å‚æ•°
    """
    valid_statuses = ["ACTIVE", "INACTIVE", "ERROR", "TESTING"]
    status_list = status.split(',') if ',' in status else [status]

    validated_statuses = []
    for s in status_list:
        s = s.strip().upper()
        if s in valid_statuses:
            validated_statuses.append(s)

    return validated_statuses


def _validate_and_parse_date_range(date_from: Optional[str], date_to: Optional[str]) -> Dict[str, Optional[datetime]]:
    """
    éªŒè¯å’Œè§£ææ—¥æœŸèŒƒå›´
    """
    from datetime import datetime

    result = {"from": None, "to": None}

    try:
        if date_from:
            result["from"] = datetime.fromisoformat(date_from.replace('Z', '+00:00'))
        if date_to:
            result["to"] = datetime.fromisoformat(date_to.replace('Z', '+00:00'))

        # éªŒè¯æ—¥æœŸèŒƒå›´åˆç†æ€§
        if result["from"] and result["to"] and result["from"] > result["to"]:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Invalid date range: start date cannot be after end date"
            )

    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Invalid date format. Use ISO format."
        )

    return result


async def _validate_bulk_database_delete_permission(
    tenant_id: str,
    user_id: str,
    item_ids: List[str],
    db: Session
):
    """
    éªŒè¯æ‰¹é‡åˆ é™¤æ•°æ®åº“è¿æ¥çš„æƒé™

    Args:
        tenant_id: ç§Ÿæˆ·ID
        user_id: ç”¨æˆ·ID
        item_ids: è¦åˆ é™¤çš„æ•°æ®æºIDåˆ—è¡¨
        db: æ•°æ®åº“ä¼šè¯
    """
    # æ£€æŸ¥æ˜¯å¦è¶…è¿‡äº†è¯¥ç§Ÿæˆ·çš„æ•°æ®æºåˆ é™¤é™åˆ¶
    active_connections = db.query(DataSourceConnection).filter(
        DataSourceConnection.tenant_id == tenant_id,
        DataSourceConnection.status != DataSourceConnectionStatus.INACTIVE
    ).count()

    # å¦‚æœåˆ é™¤åä¼šå¯¼è‡´æ•°æ®æºæ•°é‡è¿‡å°‘ï¼Œå¯èƒ½éœ€è¦ç‰¹æ®Šæƒé™
    if active_connections - len(item_ids) < 1:
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ ç‰¹æ®Šæƒé™æ£€æŸ¥
        logger.warning(f"User {user_id} attempting to delete last {len(item_ids)} "
                       f"data sources for tenant {tenant_id}")

    # æ£€æŸ¥æœ€è¿‘åˆ é™¤é¢‘ç‡ï¼Œé˜²æ­¢æ¶æ„æ‰¹é‡åˆ é™¤
    recent_deletions = db.query(DataSourceConnection).filter(
        DataSourceConnection.tenant_id == tenant_id,
        DataSourceConnection.status == DataSourceConnectionStatus.INACTIVE,
        DataSourceConnection.updated_at >= datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
    ).count()

    if recent_deletions > 10:  # åŒä¸€å¤©å†…åˆ é™¤è¶…è¿‡10ä¸ªéœ€è¦é¢å¤–éªŒè¯
        logger.warning(f"High frequency deletion detected for tenant {tenant_id}: "
                       f"{recent_deletions} deletions today")


async def _can_delete_data_source(connection: DataSourceConnection, db: Session) -> bool:
    """
    æ£€æŸ¥æ•°æ®æºæ˜¯å¦å¯ä»¥è¢«åˆ é™¤

    Args:
        connection: æ•°æ®æºè¿æ¥å¯¹è±¡
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        bool: æ˜¯å¦å¯ä»¥åˆ é™¤
    """
    # æ£€æŸ¥æ•°æ®æºçŠ¶æ€
    if connection.status == DataSourceConnectionStatus.ERROR:
        return True  # é”™è¯¯çŠ¶æ€çš„æ•°æ®æºå¯ä»¥åˆ é™¤

    if connection.status == DataSourceConnectionStatus.TESTING:
        return False  # æ­£åœ¨æµ‹è¯•çš„æ•°æ®æºä¸èƒ½åˆ é™¤

    # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šæ£€æŸ¥ï¼Œæ¯”å¦‚ï¼š
    # - æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„æŸ¥è¯¢
    # - æ£€æŸ¥æ˜¯å¦æœ‰å…³è”çš„æ–‡æ¡£
    # - æ£€æŸ¥æ˜¯å¦æœ‰å®šæ—¶ä»»åŠ¡ä¾èµ–

    return True