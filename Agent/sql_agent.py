"""
# [SQL AGENT] LangGraph SQLæ™ºèƒ½ä»£ç†ä¸»ç¨‹åº

## [HEADER]
**æ–‡ä»¶å**: sql_agent.py
**èŒè´£**: å®ç°åŸºäºLangGraphå’ŒMCPçš„SQLæ™ºèƒ½æŸ¥è¯¢ä»£ç† - è‡ªç„¶è¯­è¨€ç†è§£ã€Schemaå‘ç°ã€SQLç”Ÿæˆã€å›¾è¡¨å¯è§†åŒ–ã€å¤šè½®å¯¹è¯
**ä½œè€…**: Data Agent Team
**ç‰ˆæœ¬**: 1.2.0
**å˜æ›´è®°å½•**:
- v1.2.0 (2026-01-06): ç¨³å®šæ€§å¢å¼º - åŠ¨æ€æ—¶é—´ä¸Šä¸‹æ–‡æ³¨å…¥ã€JSONè§£æå®¹é”™å¤„ç†
- v1.1.0 (2026-01-06): å®‰å…¨å¢å¼º - é›†æˆ SQLValidator æ¨¡å—ï¼Œå¢å¼º should_continue é”™è¯¯é‡è¯•é€»è¾‘
- v1.0.1 (2026-01-02): ä¿®å¤MCP echartsæœåŠ¡å™¨URLé…ç½®ï¼ˆæœ¬åœ°å¼€å‘ä½¿ç”¨localhostï¼‰
- v1.0.0 (2026-01-01): åˆå§‹ç‰ˆæœ¬ - LangGraph SQL Agentå®ç°

## [INPUT]
### ä¸»å‡½æ•°å‚æ•°
- **run_agent(question, thread_id, verbose)**:
  - question: str - ç”¨æˆ·é—®é¢˜ï¼ˆè‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼‰
  - thread_id: str - ä¼šè¯IDï¼ˆé»˜è®¤"1"ï¼‰
  - verbose: bool - æ˜¯å¦æ‰“å°è¯¦ç»†è¿‡ç¨‹ï¼ˆé»˜è®¤Trueï¼‰

### é…ç½®ä¾èµ–
- **config** - ä»config.pyå¯¼å…¥ï¼ˆDeepSeek APIé…ç½®ã€æ•°æ®åº“URLï¼‰
- **ENABLE_ECHARTS_MCP** - æ˜¯å¦å¯ç”¨mcp-echartsæœåŠ¡ï¼ˆé»˜è®¤Trueï¼‰

## [OUTPUT]
### ä¸»å‡½æ•°è¿”å›å€¼
- **run_agent()**: VisualizationResponse - ç»“æ„åŒ–çš„å¯è§†åŒ–å“åº”
  - answer: str - AIå›å¤å†…å®¹
  - sql: str - ç”Ÿæˆçš„SQLè¯­å¥
  - data: QueryResult - æŸ¥è¯¢ç»“æœæ•°æ®
  - chart: ChartConfig - å›¾è¡¨é…ç½®
  - success: bool - æ˜¯å¦æˆåŠŸ

### è¾…åŠ©å‡½æ•°è¿”å›å€¼
- **create_llm()**: ChatOpenAI - DeepSeek LLMå®ä¾‹
- **parse_chart_config()**: Optional[Dict[str, Any]] - è§£æå‡ºçš„JSONé…ç½®
- **extract_tool_data()**: tuple[Optional[str], list] - (SQLè¯­å¥, åŸå§‹æ•°æ®åˆ—è¡¨)
- **extract_chart_tool_call()**: Optional[Dict[str, Any]] - å›¾è¡¨å·¥å…·è°ƒç”¨ä¿¡æ¯
- **call_mcp_chart_tool()**: Optional[str] - ä¿å­˜çš„å›¾ç‰‡è·¯å¾„
- **build_visualization_response()**: VisualizationResponse - å¯è§†åŒ–å“åº”å¯¹è±¡
- **_generate_chart_file()**: Optional[str] - ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶è·¯å¾„
- **_get_or_create_agent()**: tuple[agent, mcp_client] - ç¼–è¯‘å¥½çš„agentå’ŒMCPå®¢æˆ·ç«¯
- **interactive_mode()**: None - äº¤äº’æ¨¡å¼å¾ªç¯

## [LINK]
**ä¸Šæ¸¸ä¾èµ–** (å·²è¯»å–æºç ):
- [./config.py](./config.py) - é…ç½®ç®¡ç†ï¼ˆconfigå¯¹è±¡ï¼‰
- [./models.py](./models.py) - æ•°æ®æ¨¡å‹ï¼ˆVisualizationResponse, QueryResult, ChartConfig, ChartTypeï¼‰
- [./sql_validator.py](./sql_validator.py) - SQLå®‰å…¨æ ¡éªŒï¼ˆSQLValidator, SQLValidationErrorï¼‰
- [./terminal_viz.py](./terminal_viz.py) - ç»ˆç«¯å¯è§†åŒ–ï¼ˆrender_responseï¼‰
- [./data_transformer.py](./data_transformer.py) - æ•°æ®è½¬æ¢ï¼ˆsql_result_to_echarts_data, sql_result_to_mcp_echarts_dataï¼‰
- [./chart_service.py](./chart_service.py) - å›¾è¡¨æœåŠ¡ï¼ˆChartRequest, generate_chart_simple, ChartResponseï¼‰
- [backend/src/app/services/agent/tools.py](../../backend/src/app/services/agent/tools.py) - æ–‡ä»¶æ•°æ®æºå·¥å…·ï¼ˆinspect_file, analyze_dataframeï¼‰

**å¤–éƒ¨ä¾èµ–**:
- [langgraph](https://github.com/langchain-ai/langgraph) - LangGraphæ™ºèƒ½ä½“æ¡†æ¶ï¼ˆStateGraph, MessagesState, START, ENDï¼‰
- [langchain-openai](https://github.com/langchain-ai/langchain-openai) - LangChain OpenAIé›†æˆï¼ˆChatOpenAIï¼‰
- [langchain-core](https://github.com/langchain-ai/langchain-core) - LangChainæ ¸å¿ƒï¼ˆHumanMessage, SystemMessage, AIMessage, ToolMessageï¼‰
- [langchain-mcp-adapters](https://github.com/langchain-ai/langchain-mcp-adapters) - MCPé€‚é…å™¨ï¼ˆMultiServerMCPClientï¼‰
- [mcp](https://modelcontextprotocol.io/) - Model Context Protocolï¼ˆClientSession, sse_clientï¼‰

**ä¸‹æ¸¸ä¾èµ–** (å·²è¯»å–æºç ):
- [./run.py](./run.py) - å¯åŠ¨è„šæœ¬ï¼ˆè°ƒç”¨interactive_modeï¼‰
- [backend/src/app/api/v1/endpoints/query.py](../../backend/src/app/api/v1/endpoints/query.py) - æŸ¥è¯¢APIç«¯ç‚¹ï¼ˆè°ƒç”¨run_agentï¼‰

**è°ƒç”¨æ–¹**:
- **run.py**: å¯åŠ¨è„šæœ¬å…¥å£ï¼ˆif __name__ == "__main__"ï¼‰
- **æŸ¥è¯¢API**: é€šè¿‡APIç«¯ç‚¹è°ƒç”¨run_agentå‡½æ•°

## [POS]
**è·¯å¾„**: Agent/sql_agent.py
**æ¨¡å—å±‚çº§**: Level 1ï¼ˆAgentæ ¹ç›®å½•ï¼‰
**ä¾èµ–æ·±åº¦**: ç›´æ¥ä¾èµ– 5 å±‚ï¼ˆconfig.py, models.py, terminal_viz.py, data_transformer.py, chart_service.pyï¼‰
"""
import asyncio
import json
import re
from typing import Annotated, Literal, Optional, Dict, Any

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver
from langchain_mcp_adapters.client import MultiServerMCPClient

from config import config
from models import VisualizationResponse, QueryResult, ChartConfig, ChartType
from terminal_viz import render_response
from data_transformer import sql_result_to_echarts_data, sql_result_to_mcp_echarts_data
from chart_service import ChartRequest, generate_chart_simple, ChartResponse

# ğŸ” é”™è¯¯è¿½è¸ªæ¨¡å—ï¼ˆè´¨é‡ä¿è¯ï¼‰
try:
    from error_tracker import error_tracker, log_agent_error, ErrorCategory
    ERROR_TRACKING_ENABLED = True
except ImportError:
    ERROR_TRACKING_ENABLED = False
    print("âš ï¸  è­¦å‘Š: é”™è¯¯è¿½è¸ªæ¨¡å—æœªå¯ç”¨ï¼ˆerror_tracker.pyä¸å¯ç”¨ï¼‰")

# ğŸ”¥ å¼ºåˆ¶å¯¼å…¥æ–‡ä»¶æ•°æ®æºå·¥å…·ï¼ˆå¤šç§è·¯å¾„å°è¯•ï¼‰
_inspect_file_tool = None
_analyze_dataframe_tool = None

try:
    import sys
    from pathlib import Path
    
    # å°è¯•å¤šç§å¯¼å…¥è·¯å¾„
    import_paths = [
        # è·¯å¾„1: ä»é¡¹ç›®æ ¹ç›®å½•å¯¼å…¥
        (Path(__file__).parent.parent / "backend" / "src", "app.services.agent.tools"),
        # è·¯å¾„2: ä» backend ç›®å½•å¯¼å…¥
        (Path(__file__).parent.parent / "backend" / "src" / "app" / "services" / "agent", "tools"),
        # è·¯å¾„3: ç›´æ¥å¯¼å…¥ï¼ˆå¦‚æœå·²ç»åœ¨è·¯å¾„ä¸­ï¼‰
        (None, "src.app.services.agent.tools"),
    ]
    
    for backend_path, import_module in import_paths:
        try:
            if backend_path and str(backend_path) not in sys.path:
                sys.path.insert(0, str(backend_path))
            
            module = __import__(import_module, fromlist=['inspect_file', 'analyze_dataframe'])
            _inspect_file_tool = getattr(module, 'inspect_file', None)
            _analyze_dataframe_tool = getattr(module, 'analyze_dataframe', None)
            
            if _inspect_file_tool and _analyze_dataframe_tool:
                print(f"[OK] æ–‡ä»¶æ•°æ®æºå·¥å…·å¯¼å…¥æˆåŠŸ (è·¯å¾„: {import_module})")
                print(f"   - inspect_file: {getattr(_inspect_file_tool, 'name', 'unknown')}")
                print(f"   - analyze_dataframe: {getattr(_analyze_dataframe_tool, 'name', 'unknown')}")
                break
        except (ImportError, AttributeError) as e:
            continue
    
    if not _inspect_file_tool or not _analyze_dataframe_tool:
        raise ImportError("æ‰€æœ‰å¯¼å…¥è·¯å¾„éƒ½å¤±è´¥äº†")
        
except Exception as e:
    import os
    print(f"[WARNING] æ–‡ä»¶æ•°æ®æºå·¥å…·å¯¼å…¥å¤±è´¥: {e}")
    print(f"   å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"   è„šæœ¬è·¯å¾„: {Path(__file__).absolute()}")
    print(f"   Python è·¯å¾„: {sys.path[:3]}")
    print("   æç¤º: è¿™äº›å·¥å…·å¯èƒ½åœ¨æŸäº›ç¯å¢ƒä¸‹ä¸å¯ç”¨ï¼Œä½†ä¼šå°è¯•ç»§ç»­è¿è¡Œ")

import base64
import os
from datetime import datetime

# ğŸ”’ å¯¼å…¥ç‹¬ç«‹çš„ SQL å®‰å…¨æ ¡éªŒæ¨¡å—
from sql_validator import SQLValidator, SQLValidationError


# Base system prompt for the SQL Agent (will be dynamically enhanced based on db_type)
BASE_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ PostgreSQL æ•°æ®åº“åŠ©æ‰‹ï¼Œå…·å¤‡æ•°æ®æŸ¥è¯¢å’Œå›¾è¡¨å¯è§†åŒ–èƒ½åŠ›ã€‚

## ğŸš¨ğŸš¨ğŸš¨ã€æœ€é«˜ä¼˜å…ˆçº§å®‰å…¨è§„åˆ™ã€‘ğŸš¨ğŸš¨ğŸš¨

### ğŸ”´ğŸ”´ğŸ”´ ç»å¯¹ç¦æ­¢çš„æ“ä½œï¼ˆè¿åå³å®‰å…¨æ‹¦æˆªï¼‰ğŸ”´ğŸ”´ğŸ”´

ä½ æ˜¯ä¸€ä¸ª**åªè¯»æ•°æ®åˆ†æåŠ©æ‰‹**ï¼Œä¸¥ç¦æ‰§è¡Œä»»ä½•æ•°æ®ä¿®æ”¹æ“ä½œï¼å¦‚æœç”¨æˆ·è¦æ±‚ä»¥ä¸‹æ“ä½œï¼Œå¿…é¡»æ˜ç¡®æ‹’ç»ï¼š

1. **ç¦æ­¢æ•°æ®ä¿®æ”¹**ï¼šUPDATEã€INSERTã€DELETEã€TRUNCATEã€REPLACE
2. **ç¦æ­¢ç»“æ„å˜æ›´**ï¼šCREATEã€ALTERã€DROPã€RENAME è¡¨/æ•°æ®åº“/è§†å›¾
3. **ç¦æ­¢æƒé™æ“ä½œ**ï¼šGRANTã€REVOKE
4. **ç¦æ­¢æ–‡ä»¶æ“ä½œ**ï¼šCOPYã€pg_read_fileã€pg_write_file
5. **ç¦æ­¢æ‰§è¡Œå­˜å‚¨è¿‡ç¨‹**ï¼šEXECã€EXECUTEã€CALLã€MERGE

### ğŸš« æ‹’ç»ç”¨æˆ·ä¿®æ”¹æ•°æ®çš„æ­£ç¡®å›å¤æ–¹å¼

å½“ç”¨æˆ·è¦æ±‚ä¿®æ”¹æ•°æ®ï¼ˆå¦‚"æŠŠä»·æ ¼æ‰“5æŠ˜"ã€"åˆ é™¤æŸæ¡è®°å½•"ç­‰ï¼‰æ—¶ï¼Œä½ å¿…é¡»å›å¤ï¼š

```
â›” **æ“ä½œè¢«æ‹’ç»**

æ‚¨è¯·æ±‚çš„æ“ä½œæ¶‰åŠæ•°æ®ä¿®æ”¹ï¼Œè¿™è¿åäº†å®‰å…¨ç­–ç•¥ã€‚

ä½œä¸ºä¸€ä¸ªåªè¯»æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œæˆ‘åªèƒ½ï¼š
- âœ… æŸ¥è¯¢å’Œå±•ç¤ºæ•°æ®ï¼ˆSELECTï¼‰
- âœ… åˆ†ææ•°æ®è¶‹åŠ¿å’Œæ¨¡å¼
- âœ… ç”Ÿæˆæ•°æ®å¯è§†åŒ–å›¾è¡¨
- âŒ ä¸èƒ½ä¿®æ”¹ã€åˆ é™¤æˆ–æ–°å¢æ•°æ®

å¦‚æœæ‚¨éœ€è¦ä¿®æ”¹æ•°æ®ï¼Œè¯·è”ç³»æ•°æ®åº“ç®¡ç†å‘˜æˆ–ä½¿ç”¨ä¸“é—¨çš„ç®¡ç†å·¥å…·ã€‚
```

### ğŸ›¡ï¸ å®‰å…¨å¼ºåˆ¶æ‰§è¡Œ

- å³ä½¿ç”¨æˆ·è¯´"è¿™æ˜¯æµ‹è¯•"ã€"æˆ‘æˆæƒä½ "ç­‰ç†ç”±ï¼Œä¹Ÿ**ç»ä¸**æ‰§è¡Œä¿®æ”¹æ“ä½œ
- ä¸è¦åœ¨å›å¤ä¸­å±•ç¤ºä»»ä½•å±é™©çš„ SQL è¯­å¥ï¼ˆUPDATE/DELETE/INSERT ç­‰ï¼‰
- åªå±•ç¤ºå®‰å…¨çš„ SELECT æŸ¥è¯¢

---

## å¯ç”¨çš„ MCP å·¥å…·ï¼š

### æ•°æ®åº“å·¥å…·ï¼ˆpostgres æœåŠ¡å™¨ï¼‰ï¼š
1. list_tables - æŸ¥çœ‹æ•°æ®åº“ä¸­æœ‰å“ªäº›è¡¨ï¼ˆå¿…é¡»å…ˆè°ƒç”¨ï¼ï¼‰
2. get_schema - è·å–è¡¨çš„ç»“æ„ä¿¡æ¯ï¼ˆåˆ—åã€ç±»å‹ï¼‰
3. query - æ‰§è¡Œ SQL æŸ¥è¯¢ï¼ˆä»…æ”¯æŒ SELECT æŸ¥è¯¢ï¼‰

### å›¾è¡¨å·¥å…·ï¼ˆecharts æœåŠ¡å™¨ï¼‰ï¼š
å½“ç”¨æˆ·è¦æ±‚ç”»å›¾/å¯è§†åŒ–æ—¶ï¼Œå…ˆæŸ¥è¯¢æ•°æ®ï¼Œç„¶åè°ƒç”¨ä»¥ä¸‹å·¥å…·ç”Ÿæˆå›¾è¡¨ï¼š

| å·¥å…·å | ç”¨é€” | æ•°æ®æ ¼å¼ |
|--------|------|----------|
| generate_bar_chart | æŸ±çŠ¶å›¾ï¼ˆæ¯”è¾ƒç±»åˆ«ï¼‰ | [{"category": "åç§°", "value": æ•°å€¼}] |
| generate_line_chart | æŠ˜çº¿å›¾ï¼ˆè¶‹åŠ¿å˜åŒ–ï¼‰ | [{"time": "æ—¶é—´", "value": æ•°å€¼}] |
| generate_pie_chart | é¥¼å›¾ï¼ˆå æ¯”åˆ†å¸ƒï¼‰ | [{"category": "åç§°", "value": æ•°å€¼}] |
| generate_scatter_chart | æ•£ç‚¹å›¾ï¼ˆç›¸å…³æ€§ï¼‰ | è§å·¥å…·è¯´æ˜ |
| generate_radar_chart | é›·è¾¾å›¾ï¼ˆå¤šç»´å¯¹æ¯”ï¼‰ | è§å·¥å…·è¯´æ˜ |
| generate_funnel_chart | æ¼æ–—å›¾ï¼ˆè½¬åŒ–åˆ†æï¼‰ | è§å·¥å…·è¯´æ˜ |

## ğŸ”´ å›¾è¡¨å·¥å…·è°ƒç”¨æ ¼å¼ï¼ˆé‡è¦ï¼ï¼‰ï¼š

### æŸ±çŠ¶å›¾ç¤ºä¾‹ï¼š
```json
{
  "title": "å„éƒ¨é—¨äººæ•°ç»Ÿè®¡",
  "data": [
    {"category": "æŠ€æœ¯éƒ¨", "value": 45},
    {"category": "é”€å”®éƒ¨", "value": 30},
    {"category": "å¸‚åœºéƒ¨", "value": 25}
  ]
}
```

### æŠ˜çº¿å›¾ç¤ºä¾‹ï¼š
```json
{
  "title": "æœˆåº¦é”€å”®è¶‹åŠ¿",
  "data": [
    {"time": "2024-01", "value": 1000},
    {"time": "2024-02", "value": 1200},
    {"time": "2024-03", "value": 1500}
  ]
}
```

### é¥¼å›¾ç¤ºä¾‹ï¼š
```json
{
  "title": "å¸‚åœºä»½é¢åˆ†å¸ƒ",
  "data": [
    {"category": "äº§å“A", "value": 40},
    {"category": "äº§å“B", "value": 35},
    {"category": "äº§å“C", "value": 25}
  ]
}
```

## å·¥ä½œæµç¨‹ï¼š
1. ä½¿ç”¨ list_tables æŸ¥çœ‹æ•°æ®åº“è¡¨
2. ä½¿ç”¨ get_schema è·å–è¡¨ç»“æ„
3. ä½¿ç”¨ query æ‰§è¡Œ SQL æŸ¥è¯¢è·å–æ•°æ®ï¼ˆä»… SELECTï¼‰
4. **å¦‚æœç”¨æˆ·è¦æ±‚å¯è§†åŒ–**ï¼šå°†æŸ¥è¯¢ç»“æœè½¬æ¢ä¸ºä¸Šè¿°æ ¼å¼ï¼Œè°ƒç”¨å¯¹åº”å›¾è¡¨å·¥å…·

## æ³¨æ„äº‹é¡¹ï¼š
- è¿™æ˜¯ PostgreSQL æ•°æ®åº“ï¼Œä½¿ç”¨ PostgreSQL è¯­æ³•
- ğŸš¨ **åªç”Ÿæˆ SELECT æŸ¥è¯¢ï¼Œä¸æ‰§è¡Œä»»ä½•ä¿®æ”¹æ“ä½œ**
- è°ƒç”¨å›¾è¡¨å·¥å…·æ—¶ï¼Œå¿…é¡»å°† SQL ç»“æœè½¬æ¢ä¸ºæ­£ç¡®çš„ data æ ¼å¼
- ç”¨ä¸­æ–‡å›å¤ç”¨æˆ·

## ğŸ§  æ¨¡ç³ŠæŸ¥è¯¢æ™ºèƒ½æ¨æ–­è§„åˆ™ï¼ˆé‡è¦ï¼ï¼‰

å½“ç”¨æˆ·é—®**æ¨¡ç³Šé—®é¢˜**ï¼ˆå¦‚"æœ€è¿‘ç”Ÿæ„æ€ä¹ˆæ ·"ã€"é”€å”®å¦‚ä½•"ã€"ä¸šç»©å¥½ä¸å¥½"ï¼‰æ—¶ï¼Œä½ å¿…é¡»ï¼š

### 1ï¸âƒ£ é»˜è®¤æ—¶é—´èŒƒå›´
| ç”¨æˆ·è¯´ | åº”ç†è§£ä¸º | SQLæ¡ä»¶ç¤ºä¾‹ |
|--------|----------|-------------|
| "æœ€è¿‘" | æœ€è¿‘30å¤© | `WHERE date_column >= CURRENT_DATE - INTERVAL '30 days'` |
| "æœ€è¿‘ä¸€å‘¨" | æœ€è¿‘7å¤© | `WHERE date_column >= CURRENT_DATE - INTERVAL '7 days'` |
| "æœ€è¿‘ä¸€æœˆ" | æœ€è¿‘30å¤© | `WHERE date_column >= CURRENT_DATE - INTERVAL '30 days'` |
| "æœ¬æœˆ" | å½“æœˆ1æ—¥è‡³ä»Š | `WHERE date_column >= DATE_TRUNC('month', CURRENT_DATE)` |
| "ä¸Šæœˆ" | ä¸Šæœˆæ•´æœˆ | `WHERE date_column >= DATE_TRUNC('month', CURRENT_DATE - INTERVAL '1 month') AND date_column < DATE_TRUNC('month', CURRENT_DATE)` |

### ğŸ”´ğŸ”´ğŸ”´ ç‰¹å®šå¹´æœˆæŸ¥è¯¢ï¼ˆé‡è¦ï¼ï¼‰
å½“ç”¨æˆ·é—®"2024å¹´5æœˆ"ã€"2023å¹´12æœˆè®¢å•"ç­‰**ç‰¹å®šå¹´æœˆ**æŸ¥è¯¢æ—¶ï¼š

| ç”¨æˆ·è¯´ | åº”ç†è§£ä¸º | SQLæ¡ä»¶ç¤ºä¾‹ï¼ˆPostgreSQLï¼‰ | SQLæ¡ä»¶ç¤ºä¾‹ï¼ˆDuckDB/Excelï¼‰ |
|--------|----------|---------------------------|----------------------------|
| "2024å¹´5æœˆ" | 2024å¹´5æœˆæ•´æœˆ | `WHERE TO_CHAR(date_col, 'YYYY-MM') = '2024-05'` | `WHERE strftime(date_col, '%Y-%m') = '2024-05'` |
| "2023å¹´12æœˆ" | 2023å¹´12æœˆæ•´æœˆ | `WHERE date_col >= '2023-12-01'::date AND date_col < '2024-01-01'::date` | `WHERE strftime(date_col, '%Y-%m') = '2023-12'` |
| "2024å¹´çš„è®¢å•" | 2024å¹´å…¨å¹´ | `WHERE EXTRACT(YEAR FROM date_col) = 2024` | `WHERE EXTRACT(YEAR FROM date_col) = 2024` |

**ğŸš¨ğŸš¨ğŸš¨ ç¦æ­¢ä½¿ç”¨ LIKE æŸ¥è¯¢æ—¥æœŸï¼**
- âŒ **é”™è¯¯**: `WHERE order_date LIKE '2024-05%'` ï¼ˆå¯¹æ—¥æœŸç±»å‹æ— æ•ˆï¼ï¼‰
- âœ… **æ­£ç¡®**: `WHERE strftime(order_date, '%Y-%m') = '2024-05'` ï¼ˆDuckDB/Excelï¼‰
- âœ… **æ­£ç¡®**: `WHERE TO_CHAR(order_date, 'YYYY-MM') = '2024-05'` ï¼ˆPostgreSQLï¼‰

### 2ï¸âƒ£ é»˜è®¤ä¸šåŠ¡æŒ‡æ ‡
| ç”¨æˆ·è¯´ | åº”ç†è§£ä¸º | ä¼˜å…ˆæŸ¥è¯¢æŒ‡æ ‡ |
|--------|----------|--------------|
| "ç”Ÿæ„"ã€"é”€å”®"ã€"ä¸šç»©" | è®¢å•é‡å’Œé”€å”®é¢ | COUNT(*) è®¢å•æ•°, SUM(amount) é”€å”®é¢ |
| "å®¢æˆ·"ã€"ç”¨æˆ·" | å®¢æˆ·æ•°é‡ | COUNT(DISTINCT customer_id) å®¢æˆ·æ•° |
| "æ”¶å…¥"ã€"é’±" | é‡‘é¢ | SUM(amount), AVG(amount) |
| "è¶‹åŠ¿"ã€"å˜åŒ–" | æ—¶é—´åºåˆ—æ•°æ® | æŒ‰æ—¥æœŸ/æœˆä»½åˆ†ç»„ç»Ÿè®¡ |

### 3ï¸âƒ£ å¤„ç†æµç¨‹ï¼ˆå¿…é¡»æŒ‰é¡ºåºæ‰§è¡Œï¼‰
```
ç”¨æˆ·é—®"æœ€è¿‘ç”Ÿæ„æ€ä¹ˆæ ·"
â†’ Step 1: list_tablesï¼ˆæ‰¾è¡¨åç±»ä¼¼ orders, sales, transactions çš„è¡¨ï¼‰
â†’ Step 2: get_schemaï¼ˆæ‰¾æ—¥æœŸåˆ—å’Œé‡‘é¢åˆ—ï¼‰
â†’ Step 3: ç”ŸæˆSQLæŸ¥è¯¢æœ€è¿‘30å¤©çš„æ•°æ®ï¼ˆæŒ‰æ—¥æœŸåˆ†ç»„ï¼Œç”¨äºå›¾è¡¨ï¼‰
â†’ Step 4: å°†æŸ¥è¯¢ç»“æœè½¬æ¢ä¸ºå›¾è¡¨æ ¼å¼ï¼Œè°ƒç”¨ generate_line_chart ç”Ÿæˆè¶‹åŠ¿å›¾
â†’ Step 5: ç”¨æ–‡å­—æ€»ç»“æ•°æ®è¦ç‚¹
```

**ğŸ”´ é‡è¦ï¼šæ¨¡ç³ŠæŸ¥è¯¢å¿…é¡»ç”Ÿæˆå›¾è¡¨ï¼**
- æŸ¥è¯¢æ—¶å¿…é¡»**æŒ‰æ—¥æœŸåˆ†ç»„**ï¼ˆå¦‚æŒ‰å¤©æˆ–æŒ‰æœˆï¼‰ï¼Œè¿™æ ·æ‰èƒ½ç”»å‡ºè¶‹åŠ¿å›¾
- ä¸è¦åªæŸ¥æ€»æ•°ï¼Œè¦æŸ¥**æ—¶é—´åºåˆ—æ•°æ®**ç”¨äºå›¾è¡¨
- è°ƒç”¨å›¾è¡¨å·¥å…·ï¼šgenerate_line_chartï¼ˆè¶‹åŠ¿ï¼‰æˆ– generate_bar_chartï¼ˆå¯¹æ¯”ï¼‰

### 4ï¸âƒ£ SQLæŸ¥è¯¢ç¤ºä¾‹ï¼ˆå¿…é¡»æŒ‰æ—¥æœŸåˆ†ç»„ï¼‰
å½“ç”¨æˆ·é—®"æœ€è¿‘ç”Ÿæ„æ€ä¹ˆæ ·"æ—¶ï¼Œ**ä¸è¦åªæŸ¥æ€»æ•°**ï¼Œè¦æŸ¥æ—¶é—´åºåˆ—ï¼š

```sql
-- âœ… æ­£ç¡®ï¼šæŒ‰æ—¥æœŸåˆ†ç»„ï¼Œå¯ç”Ÿæˆè¶‹åŠ¿å›¾
SELECT
    DATE_TRUNC('day', order_date) as date,
    COUNT(*) as orders,
    SUM(amount) as sales
FROM orders
WHERE order_date >= CURRENT_DATE - INTERVAL '30 days'
GROUP BY DATE_TRUNC('day', order_date)
ORDER BY date
-- è¿”å›å¤šè¡Œæ•°æ®ï¼Œæ¯è¡Œæ˜¯ä¸€ä¸ªæ—¥æœŸçš„æ•°æ®

-- âŒ é”™è¯¯ï¼šåªæŸ¥æ€»æ•°ï¼Œæ— æ³•ç”»å›¾
SELECT COUNT(*), SUM(amount) FROM orders WHERE ...
-- åªè¿”å›ä¸€è¡Œï¼Œæ— æ³•ç”Ÿæˆè¶‹åŠ¿å›¾
```

### 5ï¸âƒ£ å›¾è¡¨å·¥å…·è°ƒç”¨ç¤ºä¾‹
æŸ¥è¯¢åˆ°æ—¶é—´åºåˆ—æ•°æ®åï¼Œç«‹å³è°ƒç”¨å›¾è¡¨å·¥å…·ï¼š

```json
{
  "title": "æœ€è¿‘30å¤©ä¸šåŠ¡è¶‹åŠ¿",
  "data": [
    {"time": "2024-12-01", "value": 12000},
    {"time": "2024-12-02", "value": 15000},
    ...
  ]
}
```

### 6ï¸âƒ£ å…³é”®è¦æ±‚
- ğŸ”´ **æ¨¡ç³Šæ—¶é—´å¿…é¡»ä½¿ç”¨é»˜è®¤å€¼**ï¼ˆ"æœ€è¿‘"é»˜è®¤30å¤©ï¼Œä¸è¦é—®ç”¨æˆ·"å¤šä¹…"ï¼‰
- ğŸ”´ **æŸ¥è¯¢å¿…é¡»æŒ‰æ—¥æœŸåˆ†ç»„**ï¼ˆç”Ÿæˆæ—¶é—´åºåˆ—æ•°æ®ç”¨äºç”»å›¾ï¼‰
- ğŸ”´ **å¿…é¡»è°ƒç”¨å›¾è¡¨å·¥å…·**ï¼ˆgenerate_line_chart æˆ– generate_bar_chartï¼‰
- ğŸ”´ **ä¸»åŠ¨æ‰¾è¡¨**ï¼ˆé€šè¿‡list_tablesæ™ºèƒ½æ¨æ–­è¡¨åï¼‰
- ğŸ”´ **æ‰¾ä¸åˆ°åˆé€‚çš„è¡¨/åˆ—æ—¶ï¼Œæ˜ç¡®è¯´æ˜**ï¼ˆä¸è¦ççŒœå­—æ®µåï¼‰

### 7ï¸âƒ£ è¯¦ç»†æŸ¥è¯¢ + åˆ†å¸ƒç»Ÿè®¡ï¼ˆé‡è¦ï¼ï¼‰
å½“ç”¨æˆ·æŸ¥è¯¢ç‰¹å®šæ—¶é—´æ®µçš„æ•°æ®ï¼ˆå¦‚"2024å¹´5æœˆçš„è®¢å•"ã€"ç”µå­äº§å“å“ç‰Œ"ç­‰ï¼‰æ—¶ï¼š

**å¤„ç†æµç¨‹**ï¼š
1. **å…ˆæ‰§è¡Œè¯¦ç»†æŸ¥è¯¢**ï¼šè·å–åŸå§‹æ•°æ®åˆ—è¡¨ï¼ˆç”¨äºè¡¨æ ¼å±•ç¤ºï¼‰
2. **å†æ‰§è¡ŒèšåˆæŸ¥è¯¢**ï¼šç»Ÿè®¡åˆ†å¸ƒæ•°æ®ï¼ˆç”¨äºç”Ÿæˆé¥¼å›¾ï¼‰

**ç¤ºä¾‹**ï¼šç”¨æˆ·é—®"2024å¹´5æœˆçš„è®¢å•æœ‰å“ªäº›ï¼Ÿ"
```sql
-- Step 1: è¯¦ç»†æŸ¥è¯¢ï¼ˆå±•ç¤ºåˆ—è¡¨ï¼‰
SELECT order_id, customer_name, order_date, total_amount, status_cn
FROM è®¢å•è¡¨
WHERE strftime(order_date, '%Y-%m') = '2024-05'
ORDER BY order_date DESC;

-- Step 2: èšåˆæŸ¥è¯¢ - æŒ‰çŠ¶æ€ç»Ÿè®¡ï¼ˆç”Ÿæˆé¥¼å›¾ï¼‰
SELECT status_cn as category, COUNT(*) as value
FROM è®¢å•è¡¨
WHERE strftime(order_date, '%Y-%m') = '2024-05'
GROUP BY status_cn;

-- Step 3: èšåˆæŸ¥è¯¢ - æŒ‰åŸå¸‚ç»Ÿè®¡ï¼ˆç”Ÿæˆé¥¼å›¾ï¼‰
SELECT ship_city as category, COUNT(*) as value
FROM è®¢å•è¡¨
WHERE strftime(order_date, '%Y-%m') = '2024-05'
GROUP BY ship_city;
```

### 8ï¸âƒ£ é¥¼å›¾è§„åˆ™ï¼ˆå®Œæ•´åˆ†å¸ƒï¼ï¼‰
**ğŸ”´ğŸ”´ğŸ”´ é¥¼å›¾å¿…é¡»åŒ…å«æ‰€æœ‰åˆ†ç±»ï¼Œä¸èƒ½æˆªæ–­ï¼**

| åœºæ™¯ | å›¾è¡¨ç±»å‹ | SQLè¦æ±‚ |
|------|----------|---------|
| æŒ‰çŠ¶æ€ç»Ÿè®¡ | é¥¼å›¾ | âŒ ä¸è¦ç”¨ LIMITï¼Œâœ… å¿…é¡»åŒ…å«æ‰€æœ‰çŠ¶æ€ |
| æŒ‰åŸå¸‚ç»Ÿè®¡ | é¥¼å›¾ | âŒ ä¸è¦ç”¨ LIMITï¼Œâœ… å¿…é¡»åŒ…å«æ‰€æœ‰åŸå¸‚ |
| æŒ‰å“ç‰Œç»Ÿè®¡ | é¥¼å›¾ | âŒ ä¸è¦ç”¨ LIMITï¼Œâœ… å¿…é¡»åŒ…å«æ‰€æœ‰å“ç‰Œ |

**æ­£ç¡®ç¤ºä¾‹**ï¼š
```sql
-- âœ… æ­£ç¡®ï¼šåŒ…å«æ‰€æœ‰å“ç‰Œ
SELECT brand as category, COUNT(*) as value
FROM products
WHERE category = 'ç”µå­äº§å“'
GROUP BY brand;

-- âŒ é”™è¯¯ï¼šåªæ˜¾ç¤ºå‰5ä¸ªå“ç‰Œï¼Œé—æ¼å…¶ä»–å“ç‰Œ
SELECT brand as category, COUNT(*) as value
FROM products
WHERE category = 'ç”µå­äº§å“'
GROUP BY brand
LIMIT 5;  -- ä¸è¦åœ¨åˆ†å¸ƒç»Ÿè®¡ä¸­ä½¿ç”¨LIMITï¼
```

**ğŸš¨ ä¾‹å¤–æƒ…å†µ**ï¼šåªæœ‰ç”¨æˆ·æ˜ç¡®è¯´"å‰5å"ã€"Top 10"æ—¶ï¼Œæ‰ä½¿ç”¨ LIMITã€‚

## ğŸ”® æ•°æ®åˆ†æä¸é¢„æµ‹èƒ½åŠ›ï¼š

å½“ç”¨æˆ·é—®"é¢„æµ‹"ã€"é¢„ä¼°"ã€"ä¸‹ä¸ªæœˆ"ç­‰é¢„æµ‹ç±»é—®é¢˜æ—¶ï¼Œä½ éœ€è¦ï¼š

### é¢„æµ‹æ–¹æ³•ï¼ˆç®€å•çº¿æ€§è¶‹åŠ¿ï¼‰ï¼š
1. **æŸ¥è¯¢å†å²æ•°æ®**: è·å–æœ€è¿‘6-12ä¸ªæœˆçš„æœˆåº¦æ•°æ®
2. **è®¡ç®—å¢é•¿ç‡**: å¹³å‡æœˆç¯æ¯”å¢é•¿ç‡ = (æœ€è¿‘æœˆ - æœ€æ—©æœˆ) / æœ€æ—©æœˆ / æœˆä»½æ•°
3. **é¢„æµ‹ä¸‹æœŸå€¼**: é¢„æµ‹å€¼ = æœ€è¿‘ä¸€æœŸå€¼ Ã— (1 + å¹³å‡å¢é•¿ç‡)

### å›ç­”æ ¼å¼ç¤ºä¾‹ï¼š
```
ğŸ“Š **å†å²æ•°æ®åˆ†æ**ï¼š
- 2024å¹´1æœˆ: 100ä¸‡
- 2024å¹´2æœˆ: 110ä¸‡ (ç¯æ¯”+10%)
- 2024å¹´3æœˆ: 125ä¸‡ (ç¯æ¯”+13.6%)

ğŸ“ˆ **è¶‹åŠ¿åˆ†æ**ï¼š
- å¹³å‡æœˆç¯æ¯”å¢é•¿ç‡: 11.8%
- æœ€è¿‘3ä¸ªæœˆå‘ˆä¸Šå‡è¶‹åŠ¿

ğŸ”® **é¢„æµ‹ç»“æœ**ï¼š
- é¢„æµ‹2024å¹´4æœˆé”€å”®é¢: **çº¦139.7ä¸‡**
- è®¡ç®—æ–¹æ³•: 125ä¸‡ Ã— (1 + 11.8%) = 139.75ä¸‡

âš ï¸ **æ³¨æ„**: è¿™æ˜¯åŸºäºå†å²è¶‹åŠ¿çš„ç®€å•çº¿æ€§é¢„æµ‹ï¼Œå®é™…ç»“æœå¯èƒ½å—å­£èŠ‚æ€§ã€å¸‚åœºå˜åŒ–ç­‰å› ç´ å½±å“ã€‚
```

### å…³é”®è¦æ±‚ï¼š
- ğŸ”´ **å¿…é¡»å±•ç¤ºè®¡ç®—è¿‡ç¨‹**ï¼Œä¸èƒ½åªç»™ç»“è®º
- ğŸ”´ **å¿…é¡»ç»™å‡ºå…·ä½“çš„é¢„æµ‹æ•°å€¼**ï¼Œä¸èƒ½åªè¯´"å¯èƒ½å¢é•¿"
- ğŸ”´ **å¿…é¡»å£°æ˜é¢„æµ‹çš„å±€é™æ€§**
"""


def get_system_prompt(db_type: str = "postgresql") -> str:
    """
    æ ¹æ®æ•°æ®åº“ç±»å‹è·å–ç³»ç»Ÿæç¤ºè¯ï¼Œå¹¶æ³¨å…¥åŠ¨æ€æ—¶é—´ä¸Šä¸‹æ–‡

    Args:
        db_type: æ•°æ®åº“ç±»å‹ï¼ˆpostgresql, mysql, sqlite, xlsx, csvç­‰ï¼‰

    Returns:
        str: ç³»ç»Ÿæç¤ºè¯ï¼ˆåŒ…å«å½“å‰æ—¶é—´ä¿¡æ¯ï¼‰
    """
    print(f"ğŸ” [get_system_prompt] è°ƒç”¨å‚æ•° db_type='{db_type}'")

    # ğŸ•’ åŠ¨æ€æ—¶é—´ä¸Šä¸‹æ–‡ï¼ˆå¯¹äº"æ˜¨å¤©"ã€"ä¸Šæœˆ"ç­‰æ—¶é—´æŸ¥è¯¢è‡³å…³é‡è¦ï¼‰
    current_time = datetime.now()
    time_context = f"""

## ğŸ•’ å½“å‰æ—¶é—´ä¸Šä¸‹æ–‡
- **å½“å‰æ—¶é—´**: {current_time.strftime("%Y-%m-%d %H:%M:%S")}
- **å½“å‰å¹´ä»½**: {current_time.year}
- **å½“å‰æœˆä»½**: {current_time.month}æœˆ
- **å½“å‰æ—¥æœŸ**: {current_time.day}æ—¥
- **æ˜ŸæœŸ**: æ˜ŸæœŸ{['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥'][current_time.weekday()]}

åœ¨å¤„ç†æ—¶é—´ç›¸å…³æŸ¥è¯¢æ—¶ï¼ˆå¦‚"æ˜¨å¤©"ã€"ä¸Šå‘¨"ã€"ä¸Šä¸ªæœˆ"ã€"ä»Šå¹´"ç­‰ï¼‰ï¼Œè¯·ä»¥æ­¤æ—¶é—´ä¸ºå‡†è¿›è¡Œè®¡ç®—ã€‚
"""

    try:
        from prompt_generator import generate_database_aware_system_prompt
        result = generate_database_aware_system_prompt(db_type, BASE_SYSTEM_PROMPT)
        # åœ¨æç¤ºè¯æœ«å°¾è¿½åŠ æ—¶é—´ä¸Šä¸‹æ–‡
        result = result + time_context
        print(f"ğŸ” [get_system_prompt] æˆåŠŸç”Ÿæˆæç¤ºè¯ï¼Œé•¿åº¦={len(result)}")
        # æ‰“å°æç¤ºè¯çš„å‰200å­—ç¬¦ï¼ŒéªŒè¯æ˜¯å¦åŒ…å«æ•°æ®åº“ç‰¹å®šä¿¡æ¯
        preview = result[:200].replace('\n', ' ')
        print(f"ğŸ” [get_system_prompt] æç¤ºè¯é¢„è§ˆ: {preview}...")
        return result
    except ImportError as e:
        print(f"âš ï¸ æ— æ³•å¯¼å…¥ prompt_generator: {e}ï¼Œä½¿ç”¨é»˜è®¤PostgreSQLæç¤ºè¯")
        return BASE_SYSTEM_PROMPT + time_context
    except Exception as e:
        print(f"âš ï¸ ç”ŸæˆåŠ¨æ€æç¤ºè¯å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤PostgreSQLæç¤ºè¯")
        return BASE_SYSTEM_PROMPT + time_context


# é»˜è®¤æç¤ºè¯ï¼ˆå‘åå…¼å®¹ï¼‰
SYSTEM_PROMPT = BASE_SYSTEM_PROMPT


def create_llm():
    """Create DeepSeek LLM instance using OpenAI-compatible API"""
    return ChatOpenAI(
        model=config.deepseek_model,
        api_key=config.deepseek_api_key,
        base_url=config.deepseek_base_url,
        temperature=0,
    )


def parse_chart_config(content: str) -> Optional[Dict[str, Any]]:
    """ä»LLMå›å¤ä¸­è§£æJSONå›¾è¡¨é…ç½®ï¼ˆå¢å¼ºç‰ˆï¼Œæ”¯æŒå¤šç§æ ¼å¼å’Œå®¹é”™ï¼‰

    Args:
        content: LLMçš„æ–‡æœ¬å›å¤

    Returns:
        è§£æå‡ºçš„JSONé…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None

    æ”¯æŒçš„æ ¼å¼:
        1. ```json ... ``` ä»£ç å—
        2. ```JSON ... ``` ä»£ç å—ï¼ˆå¤§å†™ï¼‰
        3. ç›´æ¥çš„ JSON å¯¹è±¡ {...}
        4. å¸¦æœ‰ JavaScript æ³¨é‡Šçš„ JSONï¼ˆä¼šå°è¯•æ¸…ç†ï¼‰
    """
    if not content or not content.strip():
        return None

    # ç­–ç•¥1: å°è¯•åŒ¹é… ```json ... ``` ä»£ç å—ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    json_pattern = r'```(?:json|JSON)\s*([\s\S]*?)\s*```'
    match = re.search(json_pattern, content)

    if match:
        json_str = match.group(1).strip()
        result = _try_parse_json(json_str)
        if result is not None:
            return result

    # ç­–ç•¥2: å°è¯•åŒ¹é…ä»»æ„ä»£ç å—ä¸­çš„ JSON
    code_block_pattern = r'```\s*([\s\S]*?)\s*```'
    for match in re.finditer(code_block_pattern, content):
        json_str = match.group(1).strip()
        # æ£€æŸ¥æ˜¯å¦åƒ JSONï¼ˆä»¥ { æˆ– [ å¼€å¤´ï¼‰
        if json_str.startswith('{') or json_str.startswith('['):
            result = _try_parse_json(json_str)
            if result is not None:
                return result

    # ç­–ç•¥3: å°è¯•ç›´æ¥åŒ¹é… JSON å¯¹è±¡ {...}
    # ä½¿ç”¨è´ªå©ªä½†å¹³è¡¡çš„åŒ¹é…ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰
    direct_json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
    for match in re.finditer(direct_json_pattern, content):
        json_str = match.group(0)
        result = _try_parse_json(json_str)
        if result is not None:
            # éªŒè¯æ˜¯å¦æ˜¯å›¾è¡¨é…ç½®ï¼ˆè‡³å°‘åŒ…å«ä¸€äº›é¢„æœŸå­—æ®µï¼‰
            if any(key in result for key in ['chart_type', 'data', 'title', 'type']):
                return result

    return None


def _try_parse_json(json_str: str) -> Optional[Dict[str, Any]]:
    """å°è¯•è§£æ JSON å­—ç¬¦ä¸²ï¼Œæ”¯æŒå®¹é”™å¤„ç†

    Args:
        json_str: JSON å­—ç¬¦ä¸²

    Returns:
        è§£æåçš„å­—å…¸ï¼Œå¤±è´¥è¿”å› None
    """
    if not json_str:
        return None

    # å°è¯•1: ç›´æ¥è§£æ
    try:
        return json.loads(json_str)
    except json.JSONDecodeError:
        pass

    # å°è¯•2: æ¸…ç†å¸¸è§çš„ LLM é”™è¯¯åå†è§£æ
    cleaned = json_str

    # ç§»é™¤ JavaScript é£æ ¼çš„å•è¡Œæ³¨é‡Š
    cleaned = re.sub(r'//.*$', '', cleaned, flags=re.MULTILINE)

    # ç§»é™¤ JavaScript é£æ ¼çš„å¤šè¡Œæ³¨é‡Š
    cleaned = re.sub(r'/\*[\s\S]*?\*/', '', cleaned)

    # ç§»é™¤å°¾éšé€—å·ï¼ˆJSON ä¸å…è®¸ï¼Œä½† JS å…è®¸ï¼‰
    cleaned = re.sub(r',\s*}', '}', cleaned)
    cleaned = re.sub(r',\s*]', ']', cleaned)

    # å°† Python çš„ None/True/False è½¬æ¢ä¸º JSON çš„ null/true/false
    cleaned = re.sub(r'\bNone\b', 'null', cleaned)
    cleaned = re.sub(r'\bTrue\b', 'true', cleaned)
    cleaned = re.sub(r'\bFalse\b', 'false', cleaned)

    # å°†å•å¼•å·è½¬æ¢ä¸ºåŒå¼•å·ï¼ˆJSON è¦æ±‚åŒå¼•å·ï¼‰
    # æ³¨æ„ï¼šè¿™ä¸ªæ›¿æ¢æ¯”è¾ƒå±é™©ï¼Œåªåœ¨å…¶ä»–æ–¹æ³•éƒ½å¤±è´¥æ—¶ä½¿ç”¨
    try:
        return json.loads(cleaned)
    except json.JSONDecodeError:
        pass

    # å°è¯•3: å•å¼•å·è½¬åŒå¼•å·ï¼ˆæœ€åæ‰‹æ®µï¼‰
    try:
        # ç®€å•çš„å•å¼•å·åˆ°åŒå¼•å·è½¬æ¢ï¼ˆä¸å¤„ç†åµŒå¥—å¼•å·ï¼‰
        cleaned_quotes = cleaned.replace("'", '"')
        return json.loads(cleaned_quotes)
    except json.JSONDecodeError:
        pass

    return None


def extract_tool_data(messages: list) -> tuple[Optional[str], list]:
    """ä»æ¶ˆæ¯å†å²ä¸­æå–å·¥å…·è°ƒç”¨çš„SQLå’Œè¿”å›æ•°æ®

    Args:
        messages: æ¶ˆæ¯å†å²åˆ—è¡¨

    Returns:
        (sqlè¯­å¥, åŸå§‹æ•°æ®åˆ—è¡¨)
    """
    sql = None
    raw_data = []

    for msg in messages:
        # æå–SQLï¼ˆä»AIMessageçš„tool_callsä¸­ï¼‰
        if isinstance(msg, AIMessage) and msg.tool_calls:
            for tc in msg.tool_calls:
                if tc.get('name') == 'query':
                    sql = tc.get('args', {}).get('sql')

        # æå–æ•°æ®ï¼ˆä»ToolMessageä¸­ï¼‰
        if isinstance(msg, ToolMessage):
            try:
                data = json.loads(msg.content) if isinstance(msg.content, str) else msg.content
                if isinstance(data, list):
                    raw_data = data
            except (json.JSONDecodeError, TypeError):
                pass

    return sql, raw_data


def extract_chart_tool_call(messages: list) -> Optional[Dict[str, Any]]:
    """ä»æ¶ˆæ¯å†å²ä¸­æå–å›¾è¡¨å·¥å…·è°ƒç”¨ä¿¡æ¯

    Args:
        messages: æ¶ˆæ¯å†å²åˆ—è¡¨

    Returns:
        åŒ…å«å·¥å…·åå’Œå‚æ•°çš„å­—å…¸ï¼Œå¦‚æœæ²¡æœ‰å›¾è¡¨å·¥å…·è°ƒç”¨åˆ™è¿”å› None
    """
    chart_tools = [
        "generate_bar_chart", "generate_line_chart", "generate_pie_chart",
        "generate_scatter_chart", "generate_radar_chart", "generate_funnel_chart",
        "generate_echarts"
    ]

    for msg in messages:
        if isinstance(msg, AIMessage) and msg.tool_calls:
            for tc in msg.tool_calls:
                tool_name = tc.get('name', '')
                if tool_name in chart_tools:
                    return {
                        "tool_name": tool_name,
                        "args": tc.get('args', {})
                    }
    return None


async def call_mcp_chart_tool(tool_name: str, args: Dict[str, Any], output_dir: str = "./charts") -> Optional[str]:
    """ä½¿ç”¨åŸå§‹ MCP å®¢æˆ·ç«¯è°ƒç”¨å›¾è¡¨å·¥å…·ï¼ˆç»•è¿‡ LangChain é€‚é…å™¨çš„é™åˆ¶ï¼‰

    Args:
        tool_name: å·¥å…·åç§°
        args: å·¥å…·å‚æ•°
        output_dir: è¾“å‡ºç›®å½•

    Returns:
        ä¿å­˜çš„å›¾ç‰‡è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
    """
    from mcp import ClientSession
    from mcp.client.sse import sse_client

    url = "http://localhost:3033/sse"

    try:
        async with sse_client(url) as streams:
            async with ClientSession(*streams) as session:
                await session.initialize()

                result = await session.call_tool(tool_name, args)

                if hasattr(result, 'content') and result.content:
                    for item in result.content:
                        if hasattr(item, 'type') and item.type == 'image':
                            if hasattr(item, 'data') and item.data:
                                # ä¿å­˜ Base64 å›¾ç‰‡
                                return _save_base64_image(item.data, output_dir, "png")
                        elif hasattr(item, 'text') and item.text:
                            # å¯èƒ½æ˜¯ URL æˆ–å…¶ä»–æ–‡æœ¬
                            text = item.text
                            if text.startswith("http"):
                                return text

                return None

    except Exception as e:
        print(f"[MCP] Chart tool call failed: {e}")
        return None


def _save_base64_image(base64_data: str, output_dir: str, ext: str = "png") -> str:
    """ä¿å­˜ Base64 ç¼–ç çš„å›¾ç‰‡åˆ°æ–‡ä»¶

    Args:
        base64_data: Base64 ç¼–ç çš„å›¾ç‰‡æ•°æ®
        output_dir: è¾“å‡ºç›®å½•
        ext: æ–‡ä»¶æ‰©å±•å

    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    os.makedirs(output_dir, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"mcp_chart_{timestamp}.{ext}"
    filepath = os.path.join(output_dir, filename)

    # è§£ç å¹¶ä¿å­˜
    image_data = base64.b64decode(base64_data)
    with open(filepath, "wb") as f:
        f.write(image_data)

    print(f"ğŸ“Š å›¾è¡¨å·²ä¿å­˜: {filepath}")
    return filepath


async def build_visualization_response(
    messages: list,
    final_content: str,
    auto_generate_chart: bool = True
) -> VisualizationResponse:
    """æ„å»ºå®Œæ•´çš„å¯è§†åŒ–å“åº”ï¼Œå¹¶å¯é€‰ç”Ÿæˆå›¾è¡¨

    Args:
        messages: å®Œæ•´çš„æ¶ˆæ¯å†å²
        final_content: æœ€ç»ˆçš„AIå›å¤å†…å®¹
        auto_generate_chart: æ˜¯å¦è‡ªåŠ¨ç”Ÿæˆå›¾è¡¨æ–‡ä»¶

    Returns:
        VisualizationResponseå¯¹è±¡
    """
    # æå–SQLå’ŒåŸå§‹æ•°æ®
    sql, raw_data = extract_tool_data(messages)

    # ğŸ†• æ£€æŸ¥æ˜¯å¦æœ‰ mcp-echarts å›¾è¡¨å·¥å…·è°ƒç”¨
    chart_tool_call = extract_chart_tool_call(messages)
    mcp_chart_path = None

    # å¦‚æœ LLM è°ƒç”¨äº†å›¾è¡¨å·¥å…·ï¼Œä½¿ç”¨åŸå§‹ MCP å®¢æˆ·ç«¯é‡æ–°è·å–å›¾ç‰‡
    if chart_tool_call and ENABLE_ECHARTS_MCP:
        print(f"[MCP] Detected chart tool call: {chart_tool_call['tool_name']}")
        mcp_chart_path = await call_mcp_chart_tool(
            chart_tool_call['tool_name'],
            chart_tool_call['args']
        )

    # è§£æå›¾è¡¨é…ç½®
    chart_config_data = parse_chart_config(final_content)

    # æ„å»ºQueryResult
    query_result = QueryResult.from_raw_data(raw_data) if raw_data else QueryResult()

    # æ„å»ºChartConfig
    chart_path = mcp_chart_path  # ä¼˜å…ˆä½¿ç”¨ mcp-echarts çš„å›¾è¡¨

    if chart_config_data:
        chart_type_str = chart_config_data.get('chart_type', 'table')
        try:
            chart_type = ChartType(chart_type_str)
        except ValueError:
            chart_type = ChartType.TABLE

        chart_config = ChartConfig(
            chart_type=chart_type,
            title=chart_config_data.get('chart_title', ''),
            x_field=chart_config_data.get('x_field'),
            y_field=chart_config_data.get('y_field')
        )
        answer = chart_config_data.get('answer', final_content)

        # å¦‚æœæ²¡æœ‰ mcp-echarts å›¾è¡¨ï¼Œå°è¯•ä½¿ç”¨æœ¬åœ°ç”Ÿæˆï¼ˆå›é€€æ–¹æ¡ˆï¼‰
        if not chart_path and auto_generate_chart:
            should_generate = chart_config_data.get('generate_chart', False)
            if should_generate and raw_data:
                chart_path = _generate_chart_file(
                    raw_data=raw_data,
                    chart_type=chart_type_str,
                    title=chart_config.title,
                    x_field=chart_config.x_field,
                    y_field=chart_config.y_field
                )
    else:
        chart_config = ChartConfig()
        answer = final_content

    response = VisualizationResponse(
        answer=answer,
        sql=sql or '',
        data=query_result,
        chart=chart_config,
        success=True
    )

    # å°†å›¾è¡¨è·¯å¾„æ·»åŠ åˆ°å“åº”ä¸­ï¼ˆå¦‚æœç”Ÿæˆäº†ï¼‰
    if chart_path:
        if chart_path.startswith("http"):
            response.answer = f"{answer}\n\nğŸ“Š å›¾è¡¨é“¾æ¥: {chart_path}"
        else:
            response.answer = f"{answer}\n\nğŸ“Š å›¾è¡¨å·²ä¿å­˜: {chart_path}"

    return response


def _generate_chart_file(
    raw_data: list,
    chart_type: str,
    title: str,
    x_field: Optional[str],
    y_field: Optional[str]
) -> Optional[str]:
    """ç”Ÿæˆå›¾è¡¨æ–‡ä»¶

    Args:
        raw_data: SQLæŸ¥è¯¢çš„åŸå§‹æ•°æ®
        chart_type: å›¾è¡¨ç±»å‹
        title: å›¾è¡¨æ ‡é¢˜
        x_field: Xè½´å­—æ®µ
        y_field: Yè½´å­—æ®µ

    Returns:
        ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
    """
    # è·³è¿‡ä¸éœ€è¦å›¾è¡¨çš„ç±»å‹
    if chart_type in ('table', 'none'):
        return None

    try:
        # è½¬æ¢æ•°æ®æ ¼å¼
        echarts_data, actual_x, actual_y = sql_result_to_echarts_data(
            raw_data, x_field, y_field
        )

        if not echarts_data:
            return None

        # åˆ›å»ºå›¾è¡¨è¯·æ±‚
        request = ChartRequest(
            type=chart_type,
            data=echarts_data,
            title=title or "æŸ¥è¯¢ç»“æœ",
            series_name=actual_y or "æ•°å€¼",
            x_axis_name=actual_x,
            y_axis_name=actual_y
        )

        # ç”Ÿæˆå›¾è¡¨ï¼ˆä½¿ç”¨ç®€åŒ–ç‰ˆï¼Œç”ŸæˆHTMLï¼‰
        response: ChartResponse = generate_chart_simple(request, output_dir="./charts")

        if response.success:
            return response.image_path
        else:
            print(f"âš ï¸ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {response.error}")
            return None

    except Exception as e:
        print(f"âš ï¸ å›¾è¡¨ç”Ÿæˆå¼‚å¸¸: {e}")
        return None


# MCP client é…ç½®
# æ˜¯å¦å¯ç”¨ mcp-echartsï¼ˆéœ€è¦å…ˆè¿è¡Œ: mcp-echarts -t sse -p 3033ï¼‰
ENABLE_ECHARTS_MCP = True  # å·²å¯ç”¨ mcp-echarts

# ============================================================
# ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šæŒä¹…åŒ–å•ä¾‹æ¨¡å¼
# ============================================================
# å…¨å±€ç¼“å­˜ï¼Œé¿å…æ¯æ¬¡æŸ¥è¯¢éƒ½é‡æ–°åˆå§‹åŒ–
_cached_agent = None
_cached_mcp_client = None
_cached_tools = None
_cached_checkpointer = None
_cached_db_type = "postgresql"  # ç¼“å­˜å½“å‰æ•°æ®åº“ç±»å‹


def _get_mcp_config():
    """è·å– MCP æœåŠ¡å™¨é…ç½®"""
    import shutil
    import sys
    
    # Check if npx is available
    npx_command = "npx.cmd" if sys.platform == "win32" else "npx"
    npx_path = shutil.which(npx_command)
    
    if not npx_path:
        error_msg = (
            f"âŒ npx å‘½ä»¤ä¸å¯ç”¨ã€‚MCP PostgreSQL æœåŠ¡å™¨éœ€è¦ Node.js/npmã€‚\n"
            f"   è¯·å®‰è£… Node.js æˆ–è®¾ç½® DISABLE_MCP_TOOLS=true ä½¿ç”¨è‡ªå®šä¹‰å·¥å…·ã€‚\n"
            f"   å½“å‰å¹³å°: {sys.platform}, æŸ¥æ‰¾çš„å‘½ä»¤: {npx_command}"
        )
        print(error_msg)
        raise RuntimeError(
            f"npx command not found. Node.js is required for MCP servers. "
            f"Platform: {sys.platform}, Command: {npx_command}. "
            f"Set DISABLE_MCP_TOOLS=true to use custom tools instead."
        )
    
    print(f"âœ… npx å¯ç”¨: {npx_path}")
    
    mcp_config = {
        "postgres": {
            "transport": "stdio",
            "command": npx_command,
            "args": [
                "-y",
                "@modelcontextprotocol/server-postgres",
                config.database_url
            ],
        }
    }

    if ENABLE_ECHARTS_MCP:
        # æœ¬åœ°å¼€å‘ä½¿ç”¨ localhostï¼ŒDockerç¯å¢ƒä½¿ç”¨æœåŠ¡å mcp_echarts
        mcp_config["echarts"] = {
            "transport": "sse",
            "url": "http://localhost:3033/sse",
            "timeout": 30.0,
            "sse_read_timeout": 120.0,
        }

    return mcp_config


async def _get_or_create_agent(db_type: str = "postgresql"):
    """è·å–æˆ–åˆ›å»ºæŒä¹…åŒ–çš„ Agent å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Args:
        db_type: æ•°æ®åº“ç±»å‹ï¼Œç”¨äºç”Ÿæˆç‰¹å®šçš„ç³»ç»Ÿæç¤ºè¯

    Returns:
        tuple: (agent, mcp_client) - ç¼–è¯‘å¥½çš„agentå’ŒMCPå®¢æˆ·ç«¯
    """
    global _cached_agent, _cached_mcp_client, _cached_tools, _cached_checkpointer, _cached_db_type

    # æ£€æŸ¥æ•°æ®åº“ç±»å‹æ˜¯å¦å˜åŒ–ï¼Œå¦‚æœå˜åŒ–åˆ™é‡ç½® Agent
    if _cached_agent is not None and _cached_db_type != db_type:
        print(f"ğŸ”„ æ•°æ®åº“ç±»å‹å˜åŒ–: {_cached_db_type} -> {db_type}ï¼Œé‡ç½® Agent...")
        await reset_agent()
        _cached_db_type = db_type

    # å¦‚æœå·²ç¼“å­˜ï¼Œç›´æ¥è¿”å›
    if _cached_agent is not None and _cached_mcp_client is not None:
        return _cached_agent, _cached_mcp_client

    print(f"ğŸ”„ é¦–æ¬¡åˆå§‹åŒ– Agentï¼ˆæ•°æ®åº“ç±»å‹: {db_type}ï¼Œåç»­æŸ¥è¯¢å°†å¤ç”¨è¿æ¥ï¼‰...")

    # åˆ›å»º MCP å®¢æˆ·ç«¯
    try:
        mcp_config = _get_mcp_config()
        _cached_mcp_client = MultiServerMCPClient(mcp_config)
    except RuntimeError as e:
        print(f"âŒ MCP é…ç½®å¤±è´¥: {e}")
        print("   æç¤º: è®¾ç½® DISABLE_MCP_TOOLS=true å¯ä»¥ç¦ç”¨ MCP å¹¶ä½¿ç”¨è‡ªå®šä¹‰å·¥å…·")
        raise
    except Exception as e:
        print(f"âŒ MCP å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {e}")
        raise

    # è·å–å·¥å…·
    try:
        _cached_tools = await _cached_mcp_client.get_tools()
        print(f"âœ… MCP å·¥å…·åŠ è½½æˆåŠŸï¼Œå…± {len(_cached_tools)} ä¸ªå·¥å…·")
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ å¼ºåˆ¶æ·»åŠ æ–‡ä»¶æ•°æ®æºå·¥å…·ï¼ˆç¡¬ç¼–ç æ–¹å¼ï¼Œä¸ä¾èµ–ä»»ä½•æ¡ä»¶ï¼‰
        tool_names_before = [getattr(t, "name", str(t)) for t in _cached_tools]
        print(f"ğŸ“‹ MCP å·¥å…·åˆ—è¡¨: {', '.join(tool_names_before)}")
        
        # å¼ºåˆ¶æ·»åŠ  inspect_file
        if _inspect_file_tool:
            tool_name = getattr(_inspect_file_tool, "name", "inspect_file")
            if tool_name not in tool_names_before:
                print(f"â• [å¼ºåˆ¶æ·»åŠ ] inspect_file å·¥å…·")
                _cached_tools.append(_inspect_file_tool)
            else:
                print(f"â„¹ï¸ inspect_file å·¥å…·å·²å­˜åœ¨äº MCP å·¥å…·åˆ—è¡¨ä¸­")
        else:
            print(f"âš ï¸ inspect_file å·¥å…·æœªå¯¼å…¥ï¼Œæ— æ³•æ·»åŠ ")
        
        # å¼ºåˆ¶æ·»åŠ  analyze_dataframe
        if _analyze_dataframe_tool:
            tool_name = getattr(_analyze_dataframe_tool, "name", "analyze_dataframe")
            if tool_name not in tool_names_before:
                print(f"â• [å¼ºåˆ¶æ·»åŠ ] analyze_dataframe å·¥å…·")
                _cached_tools.append(_analyze_dataframe_tool)
            else:
                print(f"â„¹ï¸ analyze_dataframe å·¥å…·å·²å­˜åœ¨äº MCP å·¥å…·åˆ—è¡¨ä¸­")
        else:
            print(f"âš ï¸ analyze_dataframe å·¥å…·æœªå¯¼å…¥ï¼Œæ— æ³•æ·»åŠ ")
        
        # æœ€ç»ˆéªŒè¯
        final_tool_count = len(_cached_tools)
        final_tool_names = [getattr(t, "name", str(t)) for t in _cached_tools]
        print(f"\n{'='*60}")
        print(f"âœ… FORCED REGISTRATION: æœ€ç»ˆå·¥å…·åˆ—è¡¨åŒ…å« {final_tool_count} ä¸ªå·¥å…·")
        print(f"   å·¥å…·åç§°: {', '.join(final_tool_names)}")
        print(f"   - inspect_file: {'âœ…' if 'inspect_file' in final_tool_names else 'âŒ'}")
        print(f"   - analyze_dataframe: {'âœ…' if 'analyze_dataframe' in final_tool_names else 'âŒ'}")
        print(f"{'='*60}\n")
        
    except FileNotFoundError as e:
        error_message = str(e)
        print(
            f"âŒ MCP å·¥å…·åˆå§‹åŒ–å¤±è´¥ï¼šå‘½ä»¤æœªæ‰¾åˆ°\n"
            f"   é”™è¯¯ä¿¡æ¯: {error_message}\n"
            f"   å¯èƒ½åŸå› : Node.js/npm æœªå®‰è£…æˆ–ä¸åœ¨ PATH ä¸­\n"
            f"   è§£å†³æ–¹æ¡ˆ: å®‰è£… Node.js æˆ–è®¾ç½® DISABLE_MCP_TOOLS=true"
        )
        raise RuntimeError(
            f"MCP initialization failed: command not found. "
            f"Error: {error_message}. "
            f"Install Node.js or set DISABLE_MCP_TOOLS=true"
        ) from e
    except Exception as e:
        print(f"âŒ MCP å·¥å…·åŠ è½½å¤±è´¥: {e}")
        raise

    # åˆ›å»º LLM
    llm = create_llm()
    llm_with_tools = llm.bind_tools(_cached_tools)

    # è·å–æ•°æ®åº“ç‰¹å®šçš„ç³»ç»Ÿæç¤ºè¯
    system_prompt = get_system_prompt(db_type)

    # å®šä¹‰èŠ‚ç‚¹
    async def call_model(state: MessagesState):
        messages = state["messages"]
        if not any(isinstance(m, SystemMessage) for m in messages):
            messages = [SystemMessage(content=system_prompt)] + messages
        response = await llm_with_tools.ainvoke(messages)
        return {"messages": [response]}

    def should_continue(state: MessagesState) -> Literal["tools", "agent", END]:
        """
        å¢å¼ºçš„è·¯ç”±é€»è¾‘ï¼š
        - æ£€æµ‹å·¥å…·é”™è¯¯å¹¶è·¯ç”±å› Agent è¿›è¡Œè‡ªæˆ‘ä¿®æ­£
        - æ£€æµ‹ SQL å®‰å…¨é—®é¢˜å¹¶é˜»æ­¢æ‰§è¡Œ
        """
        messages = state["messages"]
        last_message = messages[-1]

        # A. æ£€æŸ¥å·¥å…·æ‰§è¡Œç»“æœæ˜¯å¦å‡ºé”™ï¼ˆToolMessage è¿”å›é”™è¯¯æ—¶è·¯ç”±å› Agent ä¿®å¤ï¼‰
        if isinstance(last_message, ToolMessage):
            content_str = str(last_message.content).lower()
            # å¸¸è§çš„ SQL/æ•°æ®åº“é”™è¯¯å…³é”®è¯
            error_indicators = [
                "error", "exception", "failed", "invalid",
                "relation does not exist", "column does not exist",
                "syntax error", "permission denied", "does not exist",
                "no such table", "undefined column", "ambiguous column",
                # DuckDB ç±»å‹ä¸åŒ¹é…é”™è¯¯ (å¦‚ SUBSTRING ç”¨äº TIMESTAMP åˆ—)
                "no function matches", "argument types", "binder error",
                "cannot be applied to", "type mismatch"
            ]
            for indicator in error_indicators:
                if indicator in content_str:
                    print(f"ğŸš¨ æ£€æµ‹åˆ°å·¥å…·æ‰§è¡Œé”™è¯¯ï¼Œè·¯ç”±å› Agent è¿›è¡Œè‡ªæˆ‘ä¿®æ­£...")
                    return "agent"

        # B. æ£€æŸ¥ AI æ˜¯å¦è¦è°ƒç”¨å·¥å…·
        if isinstance(last_message, AIMessage) and last_message.tool_calls:
            # ğŸ”’ SQL å®‰å…¨æ‹¦æˆªï¼šåœ¨å·¥å…·æ‰§è¡Œå‰æ ¡éªŒ SQLï¼ˆä½¿ç”¨ç‹¬ç«‹çš„ SQLValidator æ¨¡å—ï¼‰
            for tc in last_message.tool_calls:
                if tc.get('name') == 'query':
                    sql = tc.get('args', {}).get('sql', '')
                    is_safe, error_msg = SQLValidator.validate(sql)
                    if not is_safe:
                        # è®°å½•è¢«æ‹¦æˆªçš„ SQLï¼ˆæˆªæ–­ä»¥ä¿æŠ¤æ—¥å¿—ï¼‰
                        sanitized_sql = SQLValidator.sanitize_for_logging(sql, 100)
                        print(f"ğŸ›‘ SQL å®‰å…¨æ‹¦æˆª: {error_msg}")
                        print(f"   è¢«æ‹¦æˆªçš„ SQL: {sanitized_sql}")
                        # æ³¨æ„ï¼šè¿™é‡Œè¿”å› "tools" è®© SafeToolNode å¤„ç†ï¼Œå®ƒä¼šè¿”å›é”™è¯¯æ¶ˆæ¯ç»™ Agent
                        # è¿™æ · Agent å¯ä»¥çœ‹åˆ°é”™è¯¯å¹¶å°è¯•ä¿®æ­£
            return "tools"

        return END

    # ğŸ”’ åˆ›å»ºå¸¦å®‰å…¨æ ¡éªŒçš„å·¥å…·èŠ‚ç‚¹ï¼ˆä½¿ç”¨ç‹¬ç«‹çš„ SQLValidator æ¨¡å—ï¼‰
    class SafeToolNode:
        """
        å¸¦ SQL å®‰å…¨æ ¡éªŒçš„å·¥å…·èŠ‚ç‚¹åŒ…è£…å™¨

        å½“ Agent å°è¯•æ‰§è¡Œå±é™© SQL æ—¶ï¼Œä¸ä¼šçœŸæ­£æ‰§è¡Œï¼Œ
        è€Œæ˜¯è¿”å›ä¸€ä¸ªé”™è¯¯æ¶ˆæ¯ï¼Œè®© Agent æœ‰æœºä¼šä¿®æ­£å¹¶é‡è¯•ã€‚
        """
        def __init__(self, tools):
            self._tool_node = ToolNode(tools)

        async def __call__(self, state: MessagesState):
            messages = state["messages"]
            last_message = messages[-1]

            # åœ¨æ‰§è¡Œ query å·¥å…·å‰è¿›è¡Œå®‰å…¨æ ¡éªŒ
            if isinstance(last_message, AIMessage) and last_message.tool_calls:
                for tc in last_message.tool_calls:
                    if tc.get('name') == 'query':
                        sql = tc.get('args', {}).get('sql', '')
                        is_safe, error_msg = SQLValidator.validate(sql)
                        if not is_safe:
                            # è¿”å›ä¸€ä¸ªé”™è¯¯æ¶ˆæ¯ï¼Œè€Œä¸æ˜¯æ‰§è¡Œå±é™©çš„ SQL
                            # è¿™è®© Agent çŸ¥é“è¢«æ‹¦æˆªäº†ï¼Œå¯ä»¥å°è¯•ç”Ÿæˆå®‰å…¨çš„æŸ¥è¯¢
                            return {
                                "messages": [
                                    ToolMessage(
                                        content=f"ğŸš« SQL æ‰§è¡Œè¢«å®‰å…¨ç³»ç»Ÿæ‹¦æˆª: {error_msg}\n\n"
                                                f"è¯·åªç”Ÿæˆ SELECT æŸ¥è¯¢è¯­å¥ï¼Œä¸è¦å°è¯•ä¿®æ”¹æˆ–åˆ é™¤æ•°æ®ã€‚",
                                        tool_call_id=tc.get('id', 'unknown')
                                    )
                                ]
                            }

            # å®‰å…¨æ ¡éªŒé€šè¿‡ï¼Œæ‰§è¡ŒåŸå§‹å·¥å…·
            return await self._tool_node.ainvoke(state)

    tool_node = SafeToolNode(_cached_tools)

    # æ„å»ºå›¾
    builder = StateGraph(MessagesState)
    builder.add_node("agent", call_model)
    builder.add_node("tools", tool_node)
    builder.add_edge(START, "agent")
    builder.add_conditional_edges("agent", should_continue)
    builder.add_edge("tools", "agent")

    # æŒä¹…åŒ– checkpointer
    _cached_checkpointer = MemorySaver()
    _cached_agent = builder.compile(checkpointer=_cached_checkpointer)

    print("âœ… Agent åˆå§‹åŒ–å®Œæˆï¼")

    return _cached_agent, _cached_mcp_client


async def reset_agent():
    """é‡ç½® Agent ç¼“å­˜ï¼ˆç”¨äºé‡æ–°è¿æ¥æˆ–é…ç½®å˜æ›´ï¼‰"""
    global _cached_agent, _cached_mcp_client, _cached_tools, _cached_checkpointer, _cached_db_type
    _cached_agent = None
    _cached_mcp_client = None
    _cached_tools = None
    _cached_checkpointer = None
    _cached_db_type = "postgresql"  # é‡ç½®ä¸ºé»˜è®¤å€¼
    print("ğŸ”„ Agent ç¼“å­˜å·²é‡ç½®")


async def run_agent(question: str, thread_id: str = "1", verbose: bool = True, db_type: str = "postgresql") -> VisualizationResponse:
    """Run the SQL Agent with a question

    Args:
        question: ç”¨æˆ·é—®é¢˜
        thread_id: ä¼šè¯ID
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†è¿‡ç¨‹
        db_type: æ•°æ®åº“ç±»å‹ï¼ˆpostgresql, mysql, sqlite, xlsx, csvç­‰ï¼‰

    Returns:
        VisualizationResponse: ç»“æ„åŒ–çš„å¯è§†åŒ–å“åº”
    """
    # ğŸš€ ä½¿ç”¨æŒä¹…åŒ–çš„ Agentï¼ˆä¼ é€’ db_type å‚æ•°ï¼‰
    agent, mcp_client = await _get_or_create_agent(db_type=db_type)

    # Run the agent
    config_dict = {"configurable": {"thread_id": thread_id}}

    if verbose:
        print(f"\n{'='*60}")
        print(f"é—®é¢˜: {question}")
        print(f"{'='*60}\n")

    step_count = 0
    all_messages = []  # æ”¶é›†æ‰€æœ‰æ¶ˆæ¯
    final_content = ""

    # ä½¿ç”¨ stream_mode="updates" åªè·å–å¢é‡æ›´æ–°
    async for step in agent.astream(
        {"messages": [HumanMessage(content=question)]},
        config_dict,
        stream_mode="updates",
    ):
        step_count += 1

        if verbose:
            print(f"\n{'â”€'*60}")
            print(f"ï¿½ ç¬¬ {step_count} æ­¥")
            print(f"{'â”€'*60}")

        for node_name, node_output in step.items():
            if verbose:
                print(f"\nğŸ”¹ èŠ‚ç‚¹åç§°: {node_name}")

            if "messages" in node_output:
                messages = node_output["messages"]
                all_messages.extend(messages)  # æ”¶é›†æ¶ˆæ¯

                for msg in messages:
                    if verbose:
                        print(f"  ğŸ“¨ æ¶ˆæ¯ç±»å‹: {type(msg).__name__}")

                    # æ ¹æ®æ¶ˆæ¯ç±»å‹å¤„ç†
                    if isinstance(msg, AIMessage):
                        if msg.content:
                            final_content = msg.content  # ä¿å­˜æœ€åçš„AIå›å¤
                            if verbose:
                                preview = msg.content[:200] + ('...' if len(msg.content) > 200 else '')
                                print(f"     ğŸ¤– AI: {preview}")
                        if msg.tool_calls and verbose:
                            for tc in msg.tool_calls:
                                print(f"     ğŸ”§ è°ƒç”¨å·¥å…·: {tc['name']}")

                    elif isinstance(msg, ToolMessage) and verbose:
                        preview = str(msg.content)[:200] + ('...' if len(str(msg.content)) > 200 else '')
                        print(f"     ğŸ“¦ å·¥å…·è¿”å›: {preview}")

    # æ„å»ºå¯è§†åŒ–å“åº”ï¼ˆå¼‚æ­¥ï¼Œæ”¯æŒ mcp-echarts å›¾è¡¨ç”Ÿæˆï¼‰
    viz_response = await build_visualization_response(all_messages, final_content)
    
    if verbose:
        print(f"\n{'='*60}")
        print(f"âœ… å®Œæˆ! å…± {step_count} æ­¥")
        print(f"{'='*60}")
        
        # æ‰“å°ç»“æ„åŒ–æ•°æ®æ‘˜è¦
        print(f"\nğŸ“Š ç»“æ„åŒ–æ•°æ®æ‘˜è¦:")
        print(f"   - SQL: {viz_response.sql[:50]}..." if viz_response.sql else "   - SQL: æ— ")
        print(f"   - æ•°æ®è¡Œæ•°: {viz_response.data.row_count}")
        print(f"   - æ¨èå›¾è¡¨: {viz_response.chart.chart_type.value}")
        print(f"   - å›¾è¡¨æ ‡é¢˜: {viz_response.chart.title or 'æ— '}")
    
    return viz_response


# ===============================================
# ğŸ” å¸¦é”™è¯¯è¿½è¸ªçš„åŒ…è£…å‡½æ•°ï¼ˆè´¨é‡ä¿è¯ï¼‰
# ===============================================

async def run_agent_with_tracking(
    question: str,
    thread_id: str = "1",
    verbose: bool = True,
    db_type: str = "postgresql",
    context: Optional[Dict[str, Any]] = None
) -> VisualizationResponse:
    """
    å¸¦é”™è¯¯è¿½è¸ªçš„run_agentåŒ…è£…å‡½æ•°

    åœ¨åŸæœ‰run_agentåŸºç¡€ä¸Šæ·»åŠ ï¼š
    - æ€§èƒ½ç›‘æ§ï¼ˆæ‰§è¡Œæ—¶é—´ï¼‰
    - é”™è¯¯è‡ªåŠ¨è®°å½•å’Œåˆ†ç±»
    - æˆåŠŸç‡ç»Ÿè®¡
    - å¤±è´¥æ¡ˆä¾‹æ”¶é›†

    Args:
        question: ç”¨æˆ·é—®é¢˜
        thread_id: ä¼šè¯ID
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†è¿‡ç¨‹
        db_type: æ•°æ®åº“ç±»å‹
        context: é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆç”¨æˆ·IDã€ç§Ÿæˆ·IDç­‰ï¼‰

    Returns:
        VisualizationResponse: ä¸run_agentç›¸åŒçš„è¿”å›å€¼
    """
    import time

    if not ERROR_TRACKING_ENABLED:
        # å¦‚æœé”™è¯¯è¿½è¸ªæœªå¯ç”¨ï¼Œç›´æ¥è°ƒç”¨åŸå‡½æ•°
        return await run_agent(question, thread_id, verbose, db_type)

    start_time = time.time()
    response = None

    try:
        # è°ƒç”¨åŸå§‹run_agentå‡½æ•°
        response = await run_agent(question, thread_id, verbose, db_type)

        # è®°å½•æˆåŠŸ
        elapsed = time.time() - start_time
        error_tracker.log_success(
            question=question,
            response=response.answer[:500] if response.answer else "æ— å›å¤",
            context={
                **(context or {}),
                "thread_id": thread_id,
                "db_type": db_type,
                "sql": response.sql[:200] if response.sql else None,
                "chart_type": response.chart.chart_type.value if response.chart else None,
            },
            execution_time=elapsed
        )

        return response

    except Exception as e:
        # è®°å½•é”™è¯¯
        elapsed = time.time() - start_time

        # è‡ªåŠ¨æ¨æ–­é”™è¯¯ç±»åˆ«
        error_category = _categorize_error(e, question)

        log_agent_error(
            question=question,
            error=e,
            category=error_category,
            context={
                **(context or {}),
                "thread_id": thread_id,
                "db_type": db_type,
                "execution_time": elapsed,
            }
        )

        # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼ˆä¿æŒåŸæœ‰è¡Œä¸ºï¼‰
        raise


def _categorize_error(error: Exception, question: str) -> ErrorCategory:
    """
    æ ¹æ®é”™è¯¯ç±»å‹å’Œç”¨æˆ·é—®é¢˜è‡ªåŠ¨åˆ†ç±»é”™è¯¯

    Args:
        error: å¼‚å¸¸å¯¹è±¡
        question: ç”¨æˆ·é—®é¢˜

    Returns:
        ErrorCategory: é”™è¯¯ç±»åˆ«
    """
    error_str = str(error).lower()
    error_type = type(error).__name__

    # å±é™©æ“ä½œæ£€æµ‹
    dangerous_keywords = ["drop", "delete", "update", "insert", "truncate", "alter"]
    if any(kw in question.lower() for kw in dangerous_keywords):
        return ErrorCategory.DANGEROUS_OPERATION

    # SQLæ³¨å…¥å°è¯•
    if "injection" in error_str or "malicious" in error_str:
        return ErrorCategory.SQL_INJECTION_ATTEMPT

    # æ•°æ®åº“è¿æ¥é—®é¢˜
    if "connection" in error_str or "connect" in error_str or "timeout" in error_str:
        return ErrorCategory.DATABASE_CONNECTION

    # LLM APIé”™è¯¯
    if "api" in error_str or "openai" in error_str or "deepseek" in error_str:
        return ErrorCategory.LLM_API_ERROR

    # Schemaä¸å­˜åœ¨
    if "not found" in error_str or "does not exist" in error_str or "unknown" in error_str:
        return ErrorCategory.SCHEMA_NOT_FOUND

    # ç©ºç»“æœ
    if "empty" in error_str or "no data" in error_str or "no result" in error_str:
        return ErrorCategory.EMPTY_RESULT

    # æ•°æ®ç±»å‹ä¸åŒ¹é…
    if error_type in ["ValueError", "TypeError"] or "type" in error_str:
        return ErrorCategory.DATA_TYPE_MISMATCH

    # MCPå·¥å…·å¤±è´¥
    if "mcp" in error_str or "tool" in error_str:
        return ErrorCategory.MCP_TOOL_FAILURE

    # æ¨¡ç³Šé—®é¢˜
    if len(question.strip()) < 5:
        return ErrorCategory.AMBIGUOUS_QUERY

    # é»˜è®¤ä¸ºæœªçŸ¥é”™è¯¯
    return ErrorCategory.UNKNOWN


async def interactive_mode():
    """Run the agent in interactive mode"""
    print("\n" + "="*60)
    print("ğŸ¤– SQL Agent äº¤äº’æ¨¡å¼ï¼ˆå¯è§†åŒ–ç‰ˆï¼‰")
    print("="*60)
    print("å‘½ä»¤:")
    print("  exit/quit - é€€å‡ºç¨‹åº")
    print("  debug     - åˆ‡æ¢è°ƒè¯•æ¨¡å¼")
    print("  reset     - é‡ç½®è¿æ¥ï¼ˆå¦‚é‡è¿æ¥é—®é¢˜ï¼‰")
    print("="*60)
    print("\nğŸ’¡ æç¤º: é¦–æ¬¡æŸ¥è¯¢éœ€è¦åˆå§‹åŒ–è¿æ¥ï¼ˆçº¦5-10ç§’ï¼‰ï¼Œåç»­æŸ¥è¯¢å°†å¾ˆå¿«ï¼\n")

    thread_id = "interactive_session"
    verbose = False  # é»˜è®¤å…³é—­è¯¦ç»†è¾“å‡ºï¼Œåªæ˜¾ç¤ºæ¼‚äº®çš„å¯è§†åŒ–ç»“æœ

    while True:
        try:
            question = input("\nğŸ“ è¯·è¾“å…¥ä½ çš„é—®é¢˜: ").strip()

            if question.lower() in ["exit", "quit", "q"]:
                print("\nğŸ‘‹ å†è§!")
                break

            if question.lower() == "debug":
                verbose = not verbose
                print(f"\nğŸ”§ è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if verbose else 'å…³é—­'}")
                continue

            if question.lower() == "reset":
                await reset_agent()
                continue

            if not question:
                continue

            # è®¡æ—¶
            import time
            start_time = time.time()

            # è¿è¡ŒAgentå¹¶è·å–ç»“æ„åŒ–å“åº”
            viz_response = await run_agent(question, thread_id, verbose=verbose)

            # è®¡ç®—è€—æ—¶
            elapsed = time.time() - start_time

            # ä½¿ç”¨æ¼‚äº®çš„å¯è§†åŒ–æ¸²æŸ“
            if not verbose:  # éè°ƒè¯•æ¨¡å¼ä¸‹æ˜¾ç¤ºæ¼‚äº®è¾“å‡º
                render_response(viz_response)

            print(f"\nâ±ï¸  å“åº”æ—¶é—´: {elapsed:.2f} ç§’")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§!")
            break
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            print("ğŸ’¡ æç¤º: è¾“å…¥ 'reset' å¯é‡ç½®è¿æ¥")


if __name__ == "__main__":
    # Validate configuration
    config.validate_config()

    # Run interactive mode
    asyncio.run(interactive_mode())

