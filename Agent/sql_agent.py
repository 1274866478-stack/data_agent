"""
LangGraph SQL Agent with MCP Integration
Uses DeepSeek as LLM and PostgreSQL MCP Server for database operations
"""
import asyncio
from typing import Annotated, Literal

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver
from langchain_mcp_adapters.client import MultiServerMCPClient

from config import config


# System prompt for the SQL Agent
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„SQLæ•°æ®åº“åŠ©æ‰‹ã€‚ä½ å¯ä»¥å¸®åŠ©ç”¨æˆ·æŸ¥è¯¢PostgreSQLæ•°æ®åº“ã€‚

ä½ çš„å·¥ä½œæµç¨‹ï¼š
1. é¦–å…ˆä½¿ç”¨ list_tables å·¥å…·æŸ¥çœ‹æ•°æ®åº“ä¸­æœ‰å“ªäº›è¡¨
2. ä½¿ç”¨ get_schema å·¥å…·è·å–ç›¸å…³è¡¨çš„ç»“æ„ä¿¡æ¯
3. æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œç”Ÿæˆæ­£ç¡®çš„SQLæŸ¥è¯¢
4. ä½¿ç”¨ query å·¥å…·æ‰§è¡ŒSQLæŸ¥è¯¢
5. å°†æŸ¥è¯¢ç»“æœä»¥å‹å¥½çš„æ–¹å¼å‘ˆç°ç»™ç”¨æˆ·

æ³¨æ„äº‹é¡¹ï¼š
- åªç”ŸæˆSELECTæŸ¥è¯¢ï¼Œä¸è¦æ‰§è¡Œä»»ä½•ä¿®æ”¹æ•°æ®çš„æ“ä½œ
- å¦‚æœä¸ç¡®å®šè¡¨ç»“æ„ï¼Œå…ˆæŸ¥çœ‹schema
- ç”¨ä¸­æ–‡å›å¤ç”¨æˆ·
"""


def create_llm():
    """Create DeepSeek LLM instance using OpenAI-compatible API"""
    return ChatOpenAI(
        model=config.deepseek_model,
        api_key=config.deepseek_api_key,
        base_url=config.deepseek_base_url,
        temperature=0,
    )


# MCP client é…ç½® (æ–°ç‰ˆ API ä¸å†éœ€è¦å•ç‹¬çš„ create å‡½æ•°)


async def run_agent(question: str, thread_id: str = "1"):
    """Run the SQL Agent with a question"""
    # æ–°ç‰ˆ API: ä¸ä½¿ç”¨ async with, ç›´æ¥è°ƒç”¨
    mcp_client = MultiServerMCPClient({
        "postgres": {
            "transport": "stdio",
            "command": "npx",
            "args": [
                "-y",
                "@modelcontextprotocol/server-postgres",
                config.database_url
            ],
        }
    })

    # ç›´æ¥è·å–å·¥å…·
    tools = await mcp_client.get_tools()
    llm = create_llm()
    llm_with_tools = llm.bind_tools(tools)

    # Define nodes
    async def call_model(state: MessagesState):
        messages = state["messages"]
        if not any(isinstance(m, SystemMessage) for m in messages):
            messages = [SystemMessage(content=SYSTEM_PROMPT)] + messages
        response = await llm_with_tools.ainvoke(messages)
        return {"messages": [response]}

    def should_continue(state: MessagesState) -> Literal["tools", END]:
        messages = state["messages"]
        last_message = messages[-1]
        if hasattr(last_message, "tool_calls") and last_message.tool_calls:
            return "tools"
        return END

    tool_node = ToolNode(tools)

    # Build graph
    builder = StateGraph(MessagesState)
    builder.add_node("agent", call_model)
    builder.add_node("tools", tool_node)
    builder.add_edge(START, "agent")
    builder.add_conditional_edges("agent", should_continue)
    builder.add_edge("tools", "agent")

    checkpointer = MemorySaver()
    agent = builder.compile(checkpointer=checkpointer)

    # Run the agent
    config_dict = {"configurable": {"thread_id": thread_id}}

    print(f"\n{'='*60}")
    print(f"é—®é¢˜: {question}")
    print(f"{'='*60}\n")

    step_count = 0

    # ä½¿ç”¨ stream_mode="updates" åªè·å–å¢é‡æ›´æ–°
    async for step in agent.astream(
        {"messages": [HumanMessage(content=question)]},
        config_dict,
        stream_mode="updates",
    ):
        step_count += 1
        print(f"\n{'â”€'*60}")
        print(f"ğŸ“ ç¬¬ {step_count} æ­¥")
        print(f"{'â”€'*60}")

        # æ‰“å°åŸå§‹ step å†…å®¹
        print(f"ğŸ“¦ Step ç±»å‹: {type(step)}")
        print(f"ğŸ“¦ Step keys: {step.keys() if isinstance(step, dict) else 'N/A'}")

        for node_name, node_output in step.items():
            print(f"\nğŸ”¹ èŠ‚ç‚¹åç§°: {node_name}")
            print(f"ğŸ”¹ è¾“å‡ºç±»å‹: {type(node_output)}")

            if "messages" in node_output:
                messages = node_output["messages"]
                print(f"ğŸ”¹ æ¶ˆæ¯æ•°é‡: {len(messages)}")

                for i, msg in enumerate(messages):
                    print(f"\n  ğŸ“¨ æ¶ˆæ¯ {i+1}:")
                    print(f"     ç±»å‹: {type(msg).__name__}")

                    # æ ¹æ®æ¶ˆæ¯ç±»å‹æ‰“å°ä¸åŒå†…å®¹
                    if isinstance(msg, HumanMessage):
                        print(f"     ğŸ‘¤ ç”¨æˆ·è¯´: {msg.content[:100]}...")

                    elif isinstance(msg, AIMessage):
                        print(f"     ğŸ¤– AI æ¶ˆæ¯:")
                        if msg.content:
                            print(f"        å†…å®¹: {msg.content[:200]}{'...' if len(msg.content) > 200 else ''}")
                        if msg.tool_calls:
                            print(f"        ğŸ”§ å·¥å…·è°ƒç”¨: {len(msg.tool_calls)} ä¸ª")
                            for tc in msg.tool_calls:
                                print(f"           - å·¥å…·å: {tc['name']}")
                                print(f"             å‚æ•°: {tc['args']}")

                    elif hasattr(msg, 'content'):
                        # ToolMessage
                        print(f"     ï¿½ å·¥å…·è¿”å›:")
                        content_preview = str(msg.content)[:300]
                        print(f"        {content_preview}{'...' if len(str(msg.content)) > 300 else ''}")
            else:
                print(f"ğŸ”¹ è¾“å‡ºå†…å®¹: {node_output}")

    print(f"\n{'='*60}")
    print(f"âœ… å®Œæˆ! å…± {step_count} æ­¥")
    print(f"{'='*60}")


async def interactive_mode():
    """Run the agent in interactive mode"""
    print("\n" + "="*60)
    print("ğŸ¤– SQL Agent äº¤äº’æ¨¡å¼")
    print("è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º")
    print("="*60 + "\n")

    thread_id = "interactive_session"

    while True:
        try:
            question = input("\nğŸ“ è¯·è¾“å…¥ä½ çš„é—®é¢˜: ").strip()

            if question.lower() in ["exit", "quit", "q"]:
                print("\nğŸ‘‹ å†è§!")
                break

            if not question:
                continue

            await run_agent(question, thread_id)

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§!")
            break
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")


if __name__ == "__main__":
    # Validate configuration
    config.validate_config()

    # Run interactive mode
    asyncio.run(interactive_mode())

