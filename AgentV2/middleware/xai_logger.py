# -*- coding: utf-8 -*-
"""
XAI Logger Middleware - å¯è§£é‡Šæ€§æ—¥å¿—ä¸­é—´ä»¶
===========================================

è®°å½• AI æ¨ç†è¿‡ç¨‹ï¼Œæä¾›å¯è§£é‡Šæ€§ã€‚

æ ¸å¿ƒåŠŸèƒ½:
    - è®°å½•æ¨ç†æ­¥éª¤
    - å·¥å…·è°ƒç”¨è¿½è¸ª
    - å†³ç­–ç‚¹æ—¥å¿—
    - æ€§èƒ½æŒ‡æ ‡æ”¶é›†

ä½œè€…: BMad Master
ç‰ˆæœ¬: 2.0.0
"""

import time
from typing import Any, Dict, List, Optional, Callable, Awaitable
from dataclasses import dataclass, field

# DeepAgents ä¸­é—´ä»¶æ¥å£å¯¼å…¥
from langgraph.prebuilt.tool_node import ToolCallRequest
from langchain_core.messages.tool import ToolMessage
from langgraph.types import Command
from langchain.agents.middleware.types import AgentMiddleware, ModelRequest, ModelResponse, ModelCallResult


# ============================================================================
# æ—¥å¿—æ•°æ®ç»“æ„
# ============================================================================

@dataclass
class ReasoningStep:
    """æ¨ç†æ­¥éª¤è®°å½•"""
    step_number: int
    description: str
    tool_used: Optional[str] = None
    input_data: Optional[Dict[str, Any]] = None
    output_data: Optional[Dict[str, Any]] = None
    timestamp: float = field(default_factory=time.time)
    duration_ms: float = 0


@dataclass
class ToolCall:
    """å·¥å…·è°ƒç”¨è®°å½•"""
    tool_name: str
    input_data: Dict[str, Any]
    output_data: Optional[Dict[str, Any]] = None
    success: bool = True
    error_message: Optional[str] = None
    start_time: float = field(default_factory=time.time)
    end_time: Optional[float] = None
    duration_ms: float = 0


@dataclass
class DecisionPoint:
    """å†³ç­–ç‚¹è®°å½•"""
    decision_id: str
    description: str
    options: List[str]
    selected_option: str
    reasoning: str
    timestamp: float = field(default_factory=time.time)


@dataclass
class XAILog:
    """å®Œæ•´çš„ XAI æ—¥å¿—"""
    session_id: str
    tenant_id: str
    user_query: str

    # æ—¶é—´çº¿
    reasoning_steps: List[ReasoningStep] = field(default_factory=list)
    tool_calls: List[ToolCall] = field(default_factory=list)
    decision_points: List[DecisionPoint] = field(default_factory=list)

    # æ€§èƒ½æŒ‡æ ‡
    total_processing_time_ms: float = 0
    llm_calls: int = 0
    tool_executions: int = 0

    # å…ƒæ•°æ®
    start_time: float = field(default_factory=time.time)
    end_time: Optional[float] = None

    def add_reasoning_step(
        self,
        description: str,
        tool_used: Optional[str] = None,
        input_data: Optional[Dict[str, Any]] = None,
        output_data: Optional[Dict[str, Any]] = None
    ):
        """æ·»åŠ æ¨ç†æ­¥éª¤"""
        step = ReasoningStep(
            step_number=len(self.reasoning_steps) + 1,
            description=description,
            tool_used=tool_used,
            input_data=input_data,
            output_data=output_data
        )
        self.reasoning_steps.append(step)

    def add_tool_call(
        self,
        tool_name: str,
        input_data: Dict[str, Any],
        output_data: Optional[Dict[str, Any]] = None,
        success: bool = True,
        error_message: Optional[str] = None
    ):
        """æ·»åŠ å·¥å…·è°ƒç”¨è®°å½•"""
        call = ToolCall(
            tool_name=tool_name,
            input_data=input_data,
            output_data=output_data,
            success=success,
            error_message=error_message
        )
        if call.end_time:
            call.duration_ms = (call.end_time - call.start_time) * 1000
        self.tool_calls.append(call)
        self.tool_executions += 1

    def add_decision_point(
        self,
        decision_id: str,
        description: str,
        options: List[str],
        selected_option: str,
        reasoning: str
    ):
        """æ·»åŠ å†³ç­–ç‚¹è®°å½•"""
        decision = DecisionPoint(
            decision_id=decision_id,
            description=description,
            options=options,
            selected_option=selected_option,
            reasoning=reasoning
        )
        self.decision_points.append(decision)

    def finalize(self):
        """å®Œæˆæ—¥å¿—è®°å½•"""
        self.end_time = time.time()
        self.total_processing_time_ms = (self.end_time - self.start_time) * 1000


# ============================================================================
# XAILoggerMiddleware
# ============================================================================

class XAILoggerMiddleware(AgentMiddleware):
    """
    å¯è§£é‡Šæ€§æ—¥å¿—ä¸­é—´ä»¶

    è®°å½• AI æ¨ç†è¿‡ç¨‹ï¼Œæä¾›å®Œæ•´çš„å†³ç­–é€æ˜åº¦ã€‚

    ä½¿ç”¨ç¤ºä¾‹:
    ```python
    from AgentV2.middleware import XAILoggerMiddleware

    middleware = XAILoggerMiddleware(
        session_id="session_123",
        tenant_id="tenant_abc"
    )
    ```
    """

    def __init__(
        self,
        session_id: str,
        tenant_id: str,
        enable_detailed_logging: bool = True,
        log_to_file: bool = False,
        log_file_path: Optional[str] = None
    ):
        """
        åˆå§‹åŒ– XAI æ—¥å¿—ä¸­é—´ä»¶

        Args:
            session_id: ä¼šè¯ ID
            tenant_id: ç§Ÿæˆ· ID
            enable_detailed_logging: æ˜¯å¦å¯ç”¨è¯¦ç»†æ—¥å¿—
            log_to_file: æ˜¯å¦è®°å½•åˆ°æ–‡ä»¶
            log_file_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„
        """
        self.session_id = session_id
        self.tenant_id = tenant_id
        self.enable_detailed_logging = enable_detailed_logging
        self.log_to_file = log_to_file
        self.log_file_path = log_file_path

        # å½“å‰æ—¥å¿—
        self._current_log: Optional[XAILog] = None

        # å†å²æ—¥å¿—
        self._log_history: List[XAILog] = []

    def pre_process(self, agent_input: Dict[str, Any]) -> Dict[str, Any]:
        """
        åœ¨ Agent æ‰§è¡Œå‰å¼€å§‹æ—¥å¿—è®°å½•

        Args:
            agent_input: Agent è¾“å…¥æ•°æ®

        Returns:
            å¤„ç†åçš„è¾“å…¥æ•°æ®
        """
        # åˆ›å»ºæ–°çš„æ—¥å¿—ä¼šè¯
        self._current_log = XAILog(
            session_id=self.session_id,
            tenant_id=self.tenant_id,
            user_query=str(agent_input.get("messages", [{}])[-1])
        )

        # è®°å½•åˆå§‹æ­¥éª¤
        self._current_log.add_reasoning_step(
            description="æ¥æ”¶ç”¨æˆ·æŸ¥è¯¢",
            input_data={"query": self._current_log.user_query}
        )

        # åœ¨è¾“å…¥ä¸­æ³¨å…¥æ—¥å¿—è®°å½•å™¨å¼•ç”¨
        agent_input["__xai_logger__"] = self

        return agent_input

    def post_process(self, agent_output: Dict[str, Any]) -> Dict[str, Any]:
        """
        åœ¨ Agent æ‰§è¡Œåå®Œæˆæ—¥å¿—è®°å½•

        Args:
            agent_output: Agent è¾“å‡ºæ•°æ®

        Returns:
            å¤„ç†åçš„è¾“å‡ºæ•°æ®
        """
        if self._current_log:
            # å®Œæˆæ—¥å¿—
            self._current_log.finalize()

            # æ·»åŠ åˆ°è¾“å‡º
            agent_output["__xai_log__"] = self._extract_summary()

            # ä¿å­˜åˆ°å†å²
            self._log_history.append(self._current_log)

            # å¯é€‰ï¼šå†™å…¥æ–‡ä»¶
            if self.log_to_file and self.log_file_path:
                self._write_to_file()

        return agent_output

    def log_tool_call(
        self,
        tool_name: str,
        input_data: Dict[str, Any],
        output_data: Optional[Dict[str, Any]] = None,
        success: bool = True,
        error_message: Optional[str] = None
    ):
        """è®°å½•å·¥å…·è°ƒç”¨"""
        if self._current_log and self.enable_detailed_logging:
            self._current_log.add_tool_call(
                tool_name=tool_name,
                input_data=input_data,
                output_data=output_data,
                success=success,
                error_message=error_message
            )

            # åŒæ—¶è®°å½•æ¨ç†æ­¥éª¤
            self._current_log.add_reasoning_step(
                description=f"è°ƒç”¨å·¥å…·: {tool_name}",
                tool_used=tool_name,
                input_data=input_data,
                output_data=output_data
            )

    def log_reasoning_step(
        self,
        description: str,
        tool_used: Optional[str] = None,
        input_data: Optional[Dict[str, Any]] = None,
        output_data: Optional[Dict[str, Any]] = None
    ):
        """è®°å½•æ¨ç†æ­¥éª¤"""
        if self._current_log and self.enable_detailed_logging:
            self._current_log.add_reasoning_step(
                description=description,
                tool_used=tool_used,
                input_data=input_data,
                output_data=output_data
            )

    def log_decision(
        self,
        decision_id: str,
        description: str,
        options: List[str],
        selected_option: str,
        reasoning: str
    ):
        """è®°å½•å†³ç­–ç‚¹"""
        if self._current_log and self.enable_detailed_logging:
            self._current_log.add_decision_point(
                decision_id=decision_id,
                description=description,
                options=options,
                selected_option=selected_option,
                reasoning=reasoning
            )

    def _extract_summary(self) -> Dict[str, Any]:
        """æå–æ—¥å¿—æ‘˜è¦"""
        if not self._current_log:
            return {}

        return {
            "session_id": self._current_log.session_id,
            "tenant_id": self._current_log.tenant_id,
            "reasoning_steps": len(self._current_log.reasoning_steps),
            "tool_calls": len(self._current_log.tool_calls),
            "decision_points": len(self._current_log.decision_points),
            "total_time_ms": self._current_log.total_processing_time_ms,
            "steps_summary": [step.description for step in self._current_log.reasoning_steps],
            "tools_used": [call.tool_name for call in self._current_log.tool_calls],
            # ğŸ”§ æ–°å¢ï¼šè¿”å›å®Œæ•´çš„æ¨ç†æ­¥éª¤è¯¦æƒ…
            "reasoning_steps_detail": [
                {
                    "step_number": step.step_number,
                    "description": step.description,
                    "tool_used": step.tool_used,
                    "input_data": step.input_data,
                    "output_data": step.output_data,
                    "duration_ms": step.duration_ms,
                }
                for step in self._current_log.reasoning_steps
            ],
            # ğŸ”§ æ–°å¢ï¼šè¿”å›å®Œæ•´çš„å·¥å…·è°ƒç”¨è¯¦æƒ…
            "tool_calls_detail": [
                {
                    "tool_name": call.tool_name,
                    "input_data": call.input_data,
                    "output_data": call.output_data,
                    "success": call.success,
                    "error_message": call.error_message,
                    "duration_ms": call.duration_ms,
                }
                for call in self._current_log.tool_calls
            ],
        }

    def _write_to_file(self):
        """å†™å…¥æ—¥å¿—æ–‡ä»¶"""
        import json
        from pathlib import Path

        if not self.log_file_path:
            return

        try:
            log_file = Path(self.log_file_path)
            log_file.parent.mkdir(parents=True, exist_ok=True)

            with open(log_file, 'a', encoding='utf-8') as f:
                json.dump(self._extract_summary(), f, ensure_ascii=False, indent=2)
                f.write('\n')

        except Exception as e:
            print(f"[WARN] å†™å…¥æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")

    def get_current_log(self) -> Optional[XAILog]:
        """è·å–å½“å‰æ—¥å¿—"""
        return self._current_log

    def get_log_history(self) -> List[XAILog]:
        """è·å–æ—¥å¿—å†å²"""
        return self._log_history.copy()

    def wrap_tool_call(
        self,
        request: ToolCallRequest,
        handler: Callable[[ToolCallRequest], ToolMessage | Command],
    ) -> ToolMessage | Command:
        """
        åŒ…è£…å·¥å…·è°ƒç”¨ä»¥è®°å½• XAI æ—¥å¿—

        è¿™æ˜¯ deepagents ä¸­é—´ä»¶æ¥å£çš„è¦æ±‚ã€‚

        Args:
            request: The tool call request being processed
            handler: The handler function to call with the request

        Returns:
            The raw ToolMessage, or a Command
        """
        # æå–å·¥å…·è°ƒç”¨ä¿¡æ¯
        tool_call = request.tool_call
        tool_name = tool_call.get("name", "unknown")
        tool_input = tool_call.get("args", {})

        # è®°å½•å·¥å…·è°ƒç”¨å¼€å§‹
        if self.enable_detailed_logging:
            self.log_tool_call(
                tool_name=tool_name,
                input_data=tool_input,
                success=True,
                error_message=None
            )

        # æ‰§è¡Œå·¥å…·è°ƒç”¨
        try:
            result = handler(request)

            # è®°å½•æˆåŠŸç»“æœ
            if self.enable_detailed_logging and hasattr(result, 'content'):
                if self._current_log:
                    # æ›´æ–°æœ€åä¸€æ¬¡å·¥å…·è°ƒç”¨çš„è¾“å‡º
                    if self._current_log.tool_calls:
                        self._current_log.tool_calls[-1].output_data = {"result": result.content}
                        self._current_log.tool_calls[-1].success = True

            return result

        except Exception as e:
            # è®°å½•å¤±è´¥ç»“æœ
            if self.enable_detailed_logging:
                if self._current_log and self._current_log.tool_calls:
                    self._current_log.tool_calls[-1].success = False
                    self._current_log.tool_calls[-1].error_message = str(e)

            # é‡æ–°æŠ›å‡ºå¼‚å¸¸
            raise

    async def awrap_tool_call(
        self,
        request: ToolCallRequest,
        handler: Callable[[ToolCallRequest], Awaitable[ToolMessage | Command]],
    ) -> ToolMessage | Command:
        """
        åŒ…è£…å·¥å…·è°ƒç”¨ä»¥è®°å½• XAI æ—¥å¿—ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰

        è¿™æ˜¯ deepagents ä¸­é—´ä»¶æ¥å£çš„å¼‚æ­¥è¦æ±‚ã€‚

        Args:
            request: The tool call request being processed
            handler: The async handler function to call with the request

        Returns:
            The raw ToolMessage, or a Command
        """
        # æå–å·¥å…·è°ƒç”¨ä¿¡æ¯
        tool_call = request.tool_call
        tool_name = tool_call.get("name", "unknown")
        tool_input = tool_call.get("args", {})

        # è®°å½•å·¥å…·è°ƒç”¨å¼€å§‹
        if self.enable_detailed_logging:
            self.log_tool_call(
                tool_name=tool_name,
                input_data=tool_input,
                success=True,
                error_message=None
            )

        # æ‰§è¡Œå¼‚æ­¥å·¥å…·è°ƒç”¨
        try:
            result = await handler(request)

            # è®°å½•æˆåŠŸç»“æœ
            if self.enable_detailed_logging and hasattr(result, 'content'):
                if self._current_log:
                    # æ›´æ–°æœ€åä¸€æ¬¡å·¥å…·è°ƒç”¨çš„è¾“å‡º
                    if self._current_log.tool_calls:
                        self._current_log.tool_calls[-1].output_data = {"result": result.content}
                        self._current_log.tool_calls[-1].success = True

            return result

        except Exception as e:
            # è®°å½•å¤±è´¥ç»“æœ
            if self.enable_detailed_logging:
                if self._current_log and self._current_log.tool_calls:
                    self._current_log.tool_calls[-1].success = False
                    self._current_log.tool_calls[-1].error_message = str(e)

            # é‡æ–°æŠ›å‡ºå¼‚å¸¸
            raise

    def wrap_model_call(self, request, handler) -> Any:
        """
        åŒ…è£…æ¨¡å‹è°ƒç”¨ä»¥è®°å½•æ¨ç†æ­¥éª¤ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰

        è¿™æ˜¯ deepagents ä¸­é—´ä»¶æ¥å£çš„æ‰©å±•æ–¹æ³•ã€‚

        Args:
            request: The model call request
            handler: The handler function to call

        Returns:
            The model output
        """
        # è®°å½•æ¨ç†æ­¥éª¤
        if self.enable_detailed_logging:
            self.log_reasoning_step(
                description="LLM æ¨¡å‹è°ƒç”¨",
                tool_used=None,
                input_data={"request": str(request)[:200]}  # æˆªæ–­ä»¥é¿å…æ—¥å¿—è¿‡å¤§
            )

        # æ‰§è¡Œæ¨¡å‹è°ƒç”¨
        result = handler(request)

        # æ›´æ–° LLM è°ƒç”¨è®¡æ•°
        if self._current_log:
            self._current_log.llm_calls += 1

        return result

    async def awrap_model_call(
        self,
        request: ModelRequest,
        handler: Callable[[ModelRequest], Awaitable[ModelResponse]]
    ) -> ModelCallResult:
        """
        åŒ…è£…æ¨¡å‹è°ƒç”¨ä»¥è®°å½•æ¨ç†æ­¥éª¤ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰

        è¿™æ˜¯ deepagents ä¸­é—´ä»¶æ¥å£çš„å¼‚æ­¥æ‰©å±•æ–¹æ³•ï¼Œç”¨äº astream/ainvoke ç­‰å¼‚æ­¥ä¸Šä¸‹æ–‡ã€‚

        Args:
            request: The model call request
            handler: The async handler function to call

        Returns:
            The model output
        """
        # è®°å½•æ¨ç†æ­¥éª¤
        if self.enable_detailed_logging:
            self.log_reasoning_step(
                description="LLM æ¨¡å‹è°ƒç”¨ (å¼‚æ­¥)",
                tool_used=None,
                input_data={"request": str(request)[:200]}
            )

        # æ‰§è¡Œå¼‚æ­¥æ¨¡å‹è°ƒç”¨
        result = await handler(request)

        # æ›´æ–° LLM è°ƒç”¨è®¡æ•°
        if self._current_log:
            self._current_log.llm_calls += 1

        return result


# ============================================================================
# ä¾¿æ·å‡½æ•°
# ============================================================================

def create_xai_logger(
    session_id: str,
    tenant_id: str,
    enable_detailed_logging: bool = True
) -> XAILoggerMiddleware:
    """
    åˆ›å»º XAI æ—¥å¿—ä¸­é—´ä»¶çš„ä¾¿æ·å‡½æ•°

    Args:
        session_id: ä¼šè¯ ID
        tenant_id: ç§Ÿæˆ· ID
        enable_detailed_logging: æ˜¯å¦å¯ç”¨è¯¦ç»†æ—¥å¿—

    Returns:
        XAILoggerMiddleware å®ä¾‹
    """
    return XAILoggerMiddleware(
        session_id=session_id,
        tenant_id=tenant_id,
        enable_detailed_logging=enable_detailed_logging
    )


# ============================================================================
# æµ‹è¯•ä»£ç 
# ============================================================================

if __name__ == "__main__":
    print("=" * 60)
    print("XAI Logger ä¸­é—´ä»¶æµ‹è¯•")
    print("=" * 60)

    # åˆ›å»ºæ—¥å¿—ä¸­é—´ä»¶
    middleware = create_xai_logger(
        session_id="test_session",
        tenant_id="test_tenant"
    )

    # æ¨¡æ‹Ÿ Agent æ‰§è¡Œ
    agent_input = {"messages": [{"role": "user", "content": "æŸ¥è¯¢æ•°æ®"}]}
    enhanced_input = middleware.pre_process(agent_input)

    print("[INFO] æ—¥å¿—ä¼šè¯å·²åˆ›å»º")

    # æ¨¡æ‹Ÿæ¨ç†è¿‡ç¨‹
    middleware.log_reasoning_step(
        description="è§£æç”¨æˆ·æŸ¥è¯¢æ„å›¾",
        tool_used=None
    )

    middleware.log_tool_call(
        tool_name="get_schema",
        input_data={"table": "users"},
        output_data={"columns": ["id", "name", "email"]}
    )

    middleware.log_decision(
        decision_id="chart_type",
        description="é€‰æ‹©å›¾è¡¨ç±»å‹",
        options=["bar", "line", "pie"],
        selected_option="bar",
        reasoning="æ•°æ®æ˜¯åˆ†ç±»æ¯”è¾ƒï¼ŒæŸ±çŠ¶å›¾æœ€åˆé€‚"
    )

    # æ¨¡æ‹Ÿ Agent è¾“å‡º
    agent_output = {"messages": [{"role": "assistant", "content": "æŸ¥è¯¢å®Œæˆ"}]}
    final_output = middleware.post_process(agent_output)

    # æ˜¾ç¤ºæ—¥å¿—æ‘˜è¦
    if "__xai_log__" in final_output:
        print("[INFO] XAI æ—¥å¿—æ‘˜è¦:")
        summary = final_output["__xai_log__"]
        print(f"  - æ¨ç†æ­¥éª¤: {summary['reasoning_steps']}")
        print(f"  - å·¥å…·è°ƒç”¨: {summary['tool_calls']}")
        print(f"  - å†³ç­–ç‚¹: {summary['decision_points']}")
        print(f"  - æ€»è€—æ—¶: {summary['total_time_ms']:.2f}ms")

    print("\n[PASS] XAI æ—¥å¿—ä¸­é—´ä»¶æµ‹è¯•é€šè¿‡")
