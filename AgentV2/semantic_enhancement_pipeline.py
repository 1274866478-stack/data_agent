# -*- coding: utf-8 -*-
"""
è¯­ä¹‰å±‚å¢å¼ºç®¡é“ - ç»Ÿä¸€çš„ä¸­é—´ä»¶é›†æˆ

è¿™ä¸ªæ¨¡å—å°†æ‰€æœ‰è¯­ä¹‰å±‚å¢å¼ºåŠŸèƒ½é›†æˆåˆ°ä¸€ä¸ªç®¡é“ä¸­ï¼š
1. å‘é‡æ£€ç´¢ Entity Linking
2. ä¸šåŠ¡æœ¯è¯­è¡¨è§£æ
3. Schema Pruning æ™ºèƒ½å‰ªæ
4. Cube Joins æ”¯æŒ

ä½¿ç”¨æ–¹å¼ï¼š
    pipeline = SemanticEnhancementPipeline()
    enhanced_input = pipeline.process_agent_input({
        "query": "P40 çš„é”€å”®é¢æ˜¯å¤šå°‘",
        "tenant_id": "xxx"
    })

ä½œè€…: Data Agent Team
ç‰ˆæœ¬: 2.0.0
"""

import json
import logging
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List, Optional

from .entity_linking import (
    EntityLinkingService,
    EntityLinkingMiddleware,
    EntityType
)
from .context.business_glossary import BusinessGlossary
from .schema_pruning import (
    SchemaPruningService,
    SchemaPruningMiddleware
)
from .cube_joins import (
    CubeJoinsMiddleware,
    CubeJoinsParser
)

logger = logging.getLogger(__name__)


@dataclass
class EnhancementResult:
    """å¢å¼ºç»“æœ

    Attributes:
        original_query: åŸå§‹æŸ¥è¯¢
        normalized_query: è§„èŒƒåŒ–åçš„æŸ¥è¯¢
        linked_entities: é“¾æ¥çš„å®ä½“
        glossary_terms: è¯†åˆ«çš„ä¸šåŠ¡æœ¯è¯­
        pruned_schema: å‰ªæåçš„ schema
        join_suggestions: Join å»ºè®®
        prompt_injection: æ³¨å…¥åˆ° Prompt çš„æ–‡æœ¬
        metadata: é¢å¤–çš„å…ƒæ•°æ®
    """
    original_query: str
    normalized_query: str
    linked_entities: List[Dict[str, Any]] = field(default_factory=list)
    glossary_terms: List[Dict[str, Any]] = field(default_factory=list)
    pruned_schema: Dict[str, Any] = field(default_factory=dict)
    join_suggestions: List[str] = field(default_factory=list)
    prompt_injection: str = ""
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "original_query": self.original_query,
            "normalized_query": self.normalized_query,
            "linked_entities": self.linked_entities,
            "glossary_terms": self.glossary_terms,
            "pruned_schema": self.pruned_schema,
            "join_suggestions": self.join_suggestions,
            "prompt_injection": self.prompt_injection,
            "metadata": self.metadata
        }


class SemanticEnhancementPipeline:
    """è¯­ä¹‰å±‚å¢å¼ºç®¡é“

    é›†æˆæ‰€æœ‰è¯­ä¹‰å±‚å¢å¼ºåŠŸèƒ½çš„ç»Ÿä¸€å…¥å£
    """

    def __init__(
        self,
        enable_entity_linking: bool = True,
        enable_glossary: bool = True,
        enable_schema_pruning: bool = True,
        enable_joins: bool = True,
        embedding_service=None,
        schema_dir: Optional[Path] = None,
        glossary_path: Optional[str] = None
    ):
        """åˆå§‹åŒ–ç®¡é“

        Args:
            enable_entity_linking: æ˜¯å¦å¯ç”¨å®ä½“é“¾æ¥
            enable_glossary: æ˜¯å¦å¯ç”¨ä¸šåŠ¡æœ¯è¯­è¡¨
            enable_schema_pruning: æ˜¯å¦å¯ç”¨ Schema å‰ªæ
            enable_joins: æ˜¯å¦å¯ç”¨ Joins æ”¯æŒ
            embedding_service: å‘é‡åµŒå…¥æœåŠ¡
            schema_dir: Schema ç›®å½•
            glossary_path: æœ¯è¯­è¡¨æ–‡ä»¶è·¯å¾„
        """
        # å®ä½“é“¾æ¥æœåŠ¡
        self.enable_entity_linking = enable_entity_linking
        if enable_entity_linking:
            self.entity_linking_service = EntityLinkingService(
                embedding_service=embedding_service
            )
            self.entity_linking_middleware = EntityLinkingMiddleware(
                linking_service=self.entity_linking_service
            )

        # ä¸šåŠ¡æœ¯è¯­è¡¨
        self.enable_glossary = enable_glossary
        if enable_glossary:
            self.glossary = BusinessGlossary(
                custom_glossary_path=glossary_path,
                enable_hot_reload=True
            )

        # Schema å‰ªæ
        self.enable_schema_pruning = enable_schema_pruning
        if enable_schema_pruning:
            self.schema_pruning_service = SchemaPruningService(
                embedding_service=embedding_service
            )
            self.schema_pruning_middleware = SchemaPruningMiddleware(
                pruning_service=self.schema_pruning_service
            )

        # Joins æ”¯æŒ
        self.enable_joins = enable_joins
        if enable_joins:
            self.joins_middleware = CubeJoinsMiddleware(
                schema_dir=schema_dir
            )

    def process_agent_input(
        self,
        agent_input: Dict[str, Any]
    ) -> Dict[str, Any]:
        """å¤„ç† Agent è¾“å…¥ï¼Œåº”ç”¨æ‰€æœ‰å¢å¼ºåŠŸèƒ½

        Args:
            agent_input: åŸå§‹ Agent è¾“å…¥
                - query: ç”¨æˆ·æŸ¥è¯¢
                - tenant_id: ç§Ÿæˆ·IDï¼ˆå¯é€‰ï¼‰
                - å…¶ä»–å­—æ®µ...

        Returns:
            å¢å¼ºåçš„ Agent è¾“å…¥
        """
        query = agent_input.get("query", "")
        tenant_id = agent_input.get("tenant_id")

        if not query:
            return agent_input

        # åˆ›å»ºå¢å¼ºç»“æœ
        result = EnhancementResult(
            original_query=query,
            normalized_query=query
        )

        # 1. å®ä½“é“¾æ¥
        if self.enable_entity_linking:
            linking_results = self.entity_linking_service.link(
                query,
                tenant_id=tenant_id,
                top_k=3
            )
            result.linked_entities = [r.to_dict() for r in linking_results]

            # è§„èŒƒåŒ–æŸ¥è¯¢ï¼ˆæ›¿æ¢å®ä½“åç§°ï¼‰
            for r in linking_results:
                if r.matched_entity and r.confidence > 0.8:
                    result.normalized_query = result.normalized_query.replace(
                        r.query,
                        r.matched_entity.name
                    )

        # 2. ä¸šåŠ¡æœ¯è¯­è¡¨è§£æ
        if self.enable_glossary:
            # çƒ­æ›´æ–°æ£€æŸ¥
            self.glossary.reload_if_needed()

            # æ³¨å…¥æœ¯è¯­è¡¨
            glossary_injection = self.glossary.inject_glossary_to_prompt(query)
            if glossary_injection:
                agent_input["__glossary_injection__"] = glossary_injection

            # è§„èŒƒåŒ–æŸ¥è¯¢
            normalized = self.glossary.normalize_query(result.normalized_query)
            result.normalized_query = normalized

            # æ”¶é›†è¯†åˆ«çš„æœ¯è¯­
            terms = self._extract_glossary_terms(query)
            result.glossary_terms = terms

        # 3. Schema å‰ªæ
        if self.enable_schema_pruning:
            pruned_schema = self.schema_pruning_service.get_pruned_schema_dict(
                result.normalized_query
            )
            result.pruned_schema = pruned_schema

            agent_input["__pruned_schema__"] = pruned_schema

        # 4. Joins å»ºè®®
        if self.enable_joins:
            suggestions = self._get_join_suggestions(result)
            result.join_suggestions = suggestions

        # 5. ç”Ÿæˆç»Ÿä¸€çš„ Prompt æ³¨å…¥
        result.prompt_injection = self._generate_prompt_injection(result)

        # æ³¨å…¥åˆ° Agent è¾“å…¥
        agent_input["__semantic_enhancement__"] = result.to_dict()
        agent_input["__enhanced_prompt__"] = result.prompt_injection
        agent_input["normalized_query"] = result.normalized_query

        logger.info(
            f"è¯­ä¹‰å±‚å¢å¼ºå®Œæˆ: "
            f"{len(result.linked_entities)} å®ä½“, "
            f"{len(result.glossary_terms)} æœ¯è¯­, "
            f"å‰Šå‡ç‡ {result.pruned_schema.get('summary', {}).get('reduction_rate', '0%')}"
        )

        return agent_input

    def _extract_glossary_terms(self, query: str) -> List[Dict[str, Any]]:
        """ä»æŸ¥è¯¢ä¸­æå–ä¸šåŠ¡æœ¯è¯­"""
        terms = []

        # æ£€æŸ¥åŸå¸‚åˆ«å
        for alias, city in self.glossary.CITY_ALIASES.items():
            if alias in query:
                terms.append({
                    "type": "city_alias",
                    "original": alias,
                    "normalized": city
                })

        # æ£€æŸ¥ä¸šåŠ¡æŒ‡æ ‡
        for acronym, definition in self.glossary.BUSINESS_METRIC_ALIASES.items():
            if acronym in query:
                terms.append({
                    "type": "business_metric",
                    "original": acronym,
                    "normalized": definition["target"],
                    "description": definition.get("description", "")
                })

        # æ£€æŸ¥æ—¶é—´è¡¨è¾¾å¼
        for expr, sql in self.glossary.TIME_EXPRESSIONS.items():
            if expr in query:
                terms.append({
                    "type": "time_expression",
                    "original": expr,
                    "normalized": sql
                })

        return terms

    def _get_join_suggestions(self, result: EnhancementResult) -> List[str]:
        """è·å– Join å»ºè®®"""
        suggestions = []

        # ä» pruned_schema è·å–æ¶‰åŠçš„ Cube
        cubes = result.pruned_schema.get("cubes", {}).keys()
        cubes = list(cubes)

        if len(cubes) > 1:
            # å¤š Cube æŸ¥è¯¢ï¼Œéœ€è¦ Join
            suggestions.append(f"éœ€è¦å…³è”çš„ Cube: {', '.join(cubes)}")

            # éªŒè¯ Join å¯è¡Œæ€§
            if self.enable_joins and len(cubes) >= 2:
                primary = cubes[0]
                for target in cubes[1:]:
                    validation = self.joins_middleware.validate_join_feasibility(
                        primary, target
                    )
                    if validation.get("feasible"):
                        suggestions.append(
                            f"âœ“ {primary} â†’ {target}: å¯é€šè¿‡ {validation['depth']} å±‚ Join è¿æ¥"
                        )
                    else:
                        suggestions.append(
                            f"âœ— {primary} â†’ {target}: {validation.get('error', 'æ— æ³•è¿æ¥')}"
                        )

        return suggestions

    def _generate_prompt_injection(self, result: EnhancementResult) -> str:
        """ç”Ÿæˆæ³¨å…¥åˆ° Prompt çš„æ–‡æœ¬"""
        lines = []

        # æ ‡é¢˜
        lines.append("## è¯­ä¹‰å±‚å¢å¼º")
        lines.append("")

        # å®ä½“é“¾æ¥ç»“æœ
        if result.linked_entities:
            lines.append("### å®ä½“é“¾æ¥")
            for entity_dict in result.linked_entities:
                entity = entity_dict.get("matched_entity")
                if entity:
                    lines.append(
                        f"- **{entity['name']}** (ç½®ä¿¡åº¦: {entity_dict['confidence']:.1%})"
                    )
                    if entity.get("description"):
                        lines.append(f"  - {entity['description']}")
            lines.append("")

        # ä¸šåŠ¡æœ¯è¯­
        if result.glossary_terms:
            lines.append("### æœ¯è¯­è§„èŒƒåŒ–")
            for term in result.glossary_terms:
                lines.append(
                    f"- {term['original']} â†’ {term['normalized']} ({term['type']})"
                )
            lines.append("")

        # Schema å‰ªæç»“æœ
        if result.pruned_schema:
            summary = result.pruned_schema.get("summary", {})
            lines.append(f"### ç›¸å…³ Schemaï¼ˆå·²ä¼˜åŒ– {summary.get('reduction_rate', '0%')}ï¼‰")
            for cube_name, cube_data in result.pruned_schema.get("cubes", {}).items():
                measures = cube_data.get("measures", [])
                dimensions = cube_data.get("dimensions", [])

                line_parts = [f"**{cube_name}**:"]
                if measures:
                    measure_names = [m.get("display_name", m.get("name")) for m in measures]
                    line_parts.append(f"åº¦é‡: {', '.join(measure_names[:5])}")
                if dimensions:
                    dim_names = [d.get("display_name", d.get("name")) for d in dimensions]
                    line_parts.append(f"ç»´åº¦: {', '.join(dim_names[:5])}")

                lines.append(" - ".join(line_parts))
            lines.append("")

        # Join å»ºè®®
        if result.join_suggestions:
            lines.append("### Join å»ºè®®")
            for suggestion in result.join_suggestions:
                lines.append(f"- {suggestion}")
            lines.append("")

        return "\n".join(lines)

    def enhance_system_prompt(
        self,
        base_prompt: str,
        query: str,
        tenant_id: Optional[str] = None
    ) -> str:
        """å¢å¼ºç³»ç»Ÿæç¤ºè¯

        Args:
            base_prompt: åŸºç¡€ç³»ç»Ÿæç¤ºè¯
            query: ç”¨æˆ·æŸ¥è¯¢
            tenant_id: ç§Ÿæˆ·ID

        Returns:
            å¢å¼ºåçš„ç³»ç»Ÿæç¤ºè¯
        """
        # å¤„ç†è¾“å…¥
        agent_input = {"query": query, "tenant_id": tenant_id}
        enhanced = self.process_agent_input(agent_input)

        # è·å–æ³¨å…¥æ–‡æœ¬
        injection = enhanced.get("__enhanced_prompt__", "")

        if not injection:
            return base_prompt

        return f"""{base_prompt}

{injection}

---
ğŸ’¡ æç¤ºï¼šä»¥ä¸Šå†…å®¹å·²æ ¹æ®ç”¨æˆ·æŸ¥è¯¢è¿›è¡Œè¯­ä¹‰å¢å¼ºï¼Œè¯·ä½¿ç”¨æ ‡å‡†åŒ–çš„æœ¯è¯­å’Œ Schema è¿›è¡ŒæŸ¥è¯¢ã€‚
"""

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç®¡é“ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "enabled_features": {
                "entity_linking": self.enable_entity_linking,
                "glossary": self.enable_glossary,
                "schema_pruning": self.enable_schema_pruning,
                "joins": self.enable_joins
            }
        }

        if self.enable_entity_linking:
            stats["entity_count"] = self.entity_linking_service.entity_store.count()

        if self.enable_glossary:
            stats["glossary_summary"] = self.glossary.get_glossary_summary()

        if self.enable_schema_pruning:
            stats["schema_count"] = {
                "measures": len(self.schema_pruning_service.measures),
                "dimensions": len(self.schema_pruning_service.dimensions)
            }

        if self.enable_joins:
            cubes = self.joins_middleware.parser.get_all_cubes()
            stats["cube_count"] = len(cubes)

        return stats


# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

def create_default_pipeline() -> SemanticEnhancementPipeline:
    """åˆ›å»ºé»˜è®¤é…ç½®çš„è¯­ä¹‰å±‚å¢å¼ºç®¡é“"""
    return SemanticEnhancementPipeline(
        enable_entity_linking=True,
        enable_glossary=True,
        enable_schema_pruning=True,
        enable_joins=True
    )


def enhance_query(
    query: str,
    tenant_id: Optional[str] = None
) -> str:
    """å¢å¼ºæŸ¥è¯¢ - ç®€å•è°ƒç”¨æ¥å£

    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        tenant_id: ç§Ÿæˆ·ID

    Returns:
        JSON æ ¼å¼çš„å¢å¼ºç»“æœ
    """
    pipeline = create_default_pipeline()
    agent_input = pipeline.process_agent_input({"query": query, "tenant_id": tenant_id})
    result = agent_input.get("__semantic_enhancement__", {})

    return json.dumps(result, ensure_ascii=False, indent=2)


# ============================================================================
# æµ‹è¯•ä»£ç 
# ============================================================================

if __name__ == "__main__":
    import sys

    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    print("=" * 60)
    print("è¯­ä¹‰å±‚å¢å¼ºç®¡é“æµ‹è¯•")
    print("=" * 60)

    # åˆ›å»ºç®¡é“
    pipeline = create_default_pipeline()

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    stats = pipeline.get_statistics()
    print("\n[ç»Ÿè®¡ä¿¡æ¯]")
    print(json.dumps(stats, ensure_ascii=False, indent=2))

    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "é­”éƒ½çš„ P40 æ‰‹æœºé”€å”®é¢æ˜¯å¤šå°‘",
        "æŒ‰åŸå¸‚ç»Ÿè®¡æœ¬æœˆçš„ GMV",
        "iPhone çš„è®¢å•å®Œæˆç‡æ€ä¹ˆæ ·",
        "åˆ†ææœ€è¿‘ä¸€å‘¨çš„å®¢æˆ·åˆ†å¸ƒè¶‹åŠ¿",
    ]

    for query in test_queries:
        print(f"\n[æµ‹è¯•] æŸ¥è¯¢: {query}")
        print("-" * 40)

        agent_input = pipeline.process_agent_input({"query": query})

        enhancement = agent_input.get("__semantic_enhancement__", {})
        print(f"è§„èŒƒåŒ–æŸ¥è¯¢: {enhancement.get('normalized_query', query)}")
        print(f"å®ä½“é“¾æ¥: {len(enhancement.get('linked_entities', []))} ä¸ª")
        print(f"æœ¯è¯­è¯†åˆ«: {len(enhancement.get('glossary_terms', []))} ä¸ª")

        summary = enhancement.get('pruned_schema', {}).get('summary', {})
        print(f"Schema å‰Šå‡ç‡: {summary.get('reduction_rate', '0%')}")

        print("\nç”Ÿæˆçš„ Prompt æ³¨å…¥:")
        print(agent_input.get("__enhanced_prompt__", ""))

    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 60)
