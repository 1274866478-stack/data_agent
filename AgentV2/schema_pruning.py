# -*- coding: utf-8 -*-
"""
Schema Pruning æœåŠ¡ - åŸºäºå‘é‡ç›¸ä¼¼åº¦çš„æ™ºèƒ½ Schema å‰ªæ

è¿™ä¸ªæ¨¡å—æä¾›åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„ Schema å‰ªæåŠŸèƒ½ï¼š
1. å°† measures å’Œ dimensions å‘é‡åŒ–
2. æ ¹æ®ç”¨æˆ·æŸ¥è¯¢è®¡ç®—ç›¸ä¼¼åº¦
3. åªä¿ç•™é«˜ç›¸å…³çš„ schema å…ƒç´ 
4. å‡å°‘ LLM ä¸Šä¸‹æ–‡å¤§å°ï¼Œæé«˜å“åº”è´¨é‡

æ ¸å¿ƒä¼˜åŠ¿ï¼š
- å‡å°‘ Token æ¶ˆè€—ï¼šåªä¼ é€’ç›¸å…³çš„ schema
- æé«˜ LLM ç†è§£ï¼šå‡å°‘å™ªéŸ³å¹²æ‰°
- åŠ é€Ÿå“åº”æ—¶é—´ï¼šæ›´å°çš„ä¸Šä¸‹æ–‡
- æ”¯æŒå¤§è§„æ¨¡ schemaï¼šæ•°ç™¾ä¸ªæŒ‡æ ‡ä¹Ÿèƒ½é«˜æ•ˆå¤„ç†

ä½œè€…: Data Agent Team
ç‰ˆæœ¬: 2.0.0
"""

import json
import logging
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple
from functools import lru_cache

import numpy as np
import yaml

logger = logging.getLogger(__name__)


# ============================================================================
# æ•°æ®æ¨¡å‹
# ============================================================================

@dataclass
class SchemaElement:
    """Schema å…ƒç´ åŸºç±»

    Attributes:
        cube: æ‰€å± Cube åç§°
        name: å…ƒç´ åç§°
        display_name: æ˜¾ç¤ºåç§°
        description: æè¿°
        element_type: å…ƒç´ ç±»å‹ (measure/dimension)
        metadata: é¢å¤–çš„å…ƒæ•°æ®
        embedding: é¢„è®¡ç®—çš„å‘é‡
        search_text: ç”¨äºæœç´¢çš„æ–‡æœ¬
    """
    cube: str
    name: str
    display_name: str
    description: str
    element_type: str
    metadata: Dict[str, Any] = field(default_factory=dict)
    embedding: Optional[np.ndarray] = None

    def to_dict(self, include_embedding: bool = False) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        result = {
            "cube": self.cube,
            "name": self.name,
            "display_name": self.display_name,
            "description": self.description,
            "element_type": self.element_type,
            "metadata": self.metadata
        }
        if include_embedding and self.embedding is not None:
            result["embedding"] = self.embedding.tolist()
        return result

    def get_search_text(self) -> str:
        """è·å–ç”¨äºå‘é‡æœç´¢çš„æ–‡æœ¬"""
        parts = [self.display_name, self.name]
        if self.description:
            parts.append(self.description)
        # æ·»åŠ å…ƒæ•°æ®ä¸­çš„å…³é”®è¯
        for key, value in self.metadata.items():
            if isinstance(value, str) and value:
                parts.append(value)
        return " ".join(parts)


@dataclass
class MeasureSchema(SchemaElement):
    """åº¦é‡ Schema å®šä¹‰"""
    aggregation_type: str = "sum"  # sum, count, avg, etc.
    sql_template: str = ""

    def __post_init__(self):
        self.element_type = "measure"


@dataclass
class DimensionSchema(SchemaElement):
    """ç»´åº¦ Schema å®šä¹‰"""
    data_type: str = "string"  # string, time, number
    enumerations: List[str] = field(default_factory=list)

    def __post_init__(self):
        self.element_type = "dimension"


@dataclass
class PruningResult:
    """å‰ªæç»“æœ

    Attributes:
        query: åŸå§‹æŸ¥è¯¢
        selected_measures: é€‰ä¸­çš„åº¦é‡
        selected_dimensions: é€‰ä¸­çš„ç»´åº¦
        selected_cubes: é€‰ä¸­çš„ Cube
        excluded_measures: æ’é™¤çš„åº¦é‡
        excluded_dimensions: æ’é™¤çš„ç»´åº¦
        scores: å…ƒç´ å¾—åˆ†
        total_original: åŸå§‹å…ƒç´ æ€»æ•°
        total_selected: é€‰ä¸­å…ƒç´ æ•°é‡
        reduction_rate: å‰Šå‡æ¯”ä¾‹
    """
    query: str
    selected_measures: List[MeasureSchema]
    selected_dimensions: List[DimensionSchema]
    selected_cubes: Set[str]
    excluded_measures: List[MeasureSchema]
    excluded_dimensions: List[DimensionSchema]
    scores: Dict[str, float]
    total_original: int
    total_selected: int
    reduction_rate: float

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "query": self.query,
            "selected_measures": [m.to_dict() for m in self.selected_measures],
            "selected_dimensions": [d.to_dict() for d in self.selected_dimensions],
            "selected_cubes": list(self.selected_cubes),
            "excluded_measures_count": len(self.excluded_measures),
            "excluded_dimensions_count": len(self.excluded_dimensions),
            "total_original": self.total_original,
            "total_selected": self.total_selected,
            "reduction_rate": f"{self.reduction_rate:.1%}"
        }


# ============================================================================
# Schema åŠ è½½å™¨
# ============================================================================

class SchemaLoader:
    """Schema åŠ è½½å™¨

    ä» YAML æ–‡ä»¶æˆ– API åŠ è½½ schema å®šä¹‰
    """

    def __init__(self, schema_dir: Optional[Path] = None):
        """åˆå§‹åŒ–

        Args:
            schema_dir: Schema ç›®å½•è·¯å¾„
        """
        if schema_dir is None:
            self.schema_dir = Path(__file__).parent.parent.parent / "cube_schema"
        else:
            self.schema_dir = Path(schema_dir)

    def load_from_yaml(self) -> Tuple[List[MeasureSchema], List[DimensionSchema]]:
        """ä» YAML æ–‡ä»¶åŠ è½½ Schema

        Returns:
            (åº¦é‡åˆ—è¡¨, ç»´åº¦åˆ—è¡¨)
        """
        measures: List[MeasureSchema] = []
        dimensions: List[DimensionSchema] = []

        if not self.schema_dir.exists():
            logger.warning(f"Schema ç›®å½•ä¸å­˜åœ¨: {self.schema_dir}")
            return measures, dimensions

        for yaml_file in self.schema_dir.glob("*.yaml"):
            try:
                with open(yaml_file, 'r', encoding='utf-8') as f:
                    data = yaml.safe_load(f)

                if not data:
                    continue

                cube_name = data.get('cube', yaml_file.stem)

                # åŠ è½½åº¦é‡
                for measure_data in data.get('measures', []):
                    measure = MeasureSchema(
                        cube=cube_name,
                        name=measure_data.get('name', ''),
                        display_name=measure_data.get('display_name', measure_data.get('name', '')),
                        description=measure_data.get('description', ''),
                        element_type='measure',
                        aggregation_type=measure_data.get('type', 'sum'),
                        sql_template=measure_data.get('sql', ''),
                        metadata=measure_data.get('metadata', {})
                    )
                    measures.append(measure)

                # åŠ è½½ç»´åº¦
                for dim_data in data.get('dimensions', []):
                    dimension = DimensionSchema(
                        cube=cube_name,
                        name=dim_data.get('name', ''),
                        display_name=dim_data.get('display_name', dim_data.get('name', '')),
                        description=dim_data.get('description', ''),
                        element_type='dimension',
                        data_type=dim_data.get('type', 'string'),
                        enumerations=dim_data.get('enumerations', []),
                        metadata=dim_data.get('metadata', {})
                    )
                    dimensions.append(dimension)

            except Exception as e:
                logger.warning(f"åŠ è½½ {yaml_file} å¤±è´¥: {e}")

        logger.info(f"åŠ è½½äº† {len(measures)} ä¸ªåº¦é‡å’Œ {len(dimensions)} ä¸ªç»´åº¦")
        return measures, dimensions

    def load_from_builtin(self) -> Tuple[List[MeasureSchema], List[DimensionSchema]]:
        """åŠ è½½å†…ç½® Schemaï¼ˆä½œä¸ºå›é€€æ–¹æ¡ˆï¼‰"""
        measures = [
            MeasureSchema(
                cube="Orders",
                name="total_revenue",
                display_name="è®¢å•æ€»æ”¶å…¥",
                description="æ‰€æœ‰è®¢å•çš„æ€»é‡‘é¢ï¼ŒåŒ…å«æŠ˜æ‰£ã€ç¨è´¹å’Œè¿è´¹",
                aggregation_type="sum",
                sql_template="SUM(total_amount)"
            ),
            MeasureSchema(
                cube="Orders",
                name="net_revenue",
                display_name="è®¢å•å‡€æ”¶å…¥",
                description="æ’é™¤å–æ¶ˆè®¢å•åçš„æ€»æ”¶å…¥",
                aggregation_type="sum",
                sql_template="SUM(CASE WHEN status != 'cancelled' THEN total_amount ELSE 0 END)"
            ),
            MeasureSchema(
                cube="Orders",
                name="order_count",
                display_name="è®¢å•æ•°é‡",
                description="è®¢å•æ€»æ•°",
                aggregation_type="count",
                sql_template="COUNT(*)"
            ),
            MeasureSchema(
                cube="Orders",
                name="average_order_value",
                display_name="å¹³å‡è®¢å•é‡‘é¢",
                description="æ¯ä¸ªè®¢å•çš„å¹³å‡é‡‘é¢",
                aggregation_type="avg",
                sql_template="AVG(total_amount)"
            ),
            MeasureSchema(
                cube="Customers",
                name="customer_count",
                display_name="å®¢æˆ·æ•°é‡",
                description="å»é‡åçš„å®¢æˆ·æ€»æ•°",
                aggregation_type="count",
                sql_template="COUNT(DISTINCT customer_id)"
            ),
            MeasureSchema(
                cube="Products",
                name="product_count",
                display_name="å•†å“æ•°é‡",
                description="å•†å“æ€»æ•°",
                aggregation_type="count",
                sql_template="COUNT(*)"
            ),
        ]

        dimensions = [
            DimensionSchema(
                cube="Orders",
                name="status",
                display_name="è®¢å•çŠ¶æ€",
                description="è®¢å•çš„å½“å‰çŠ¶æ€",
                data_type="string",
                enumerations=["pending", "processing", "completed", "cancelled", "refunded"]
            ),
            DimensionSchema(
                cube="Orders",
                name="created_at",
                display_name="åˆ›å»ºæ—¶é—´",
                description="è®¢å•åˆ›å»ºçš„æ—¶é—´æˆ³",
                data_type="time"
            ),
            DimensionSchema(
                cube="Orders",
                name="order_date",
                display_name="è®¢å•æ—¥æœŸ",
                description="è®¢å•çš„æ—¥æœŸ",
                data_type="time"
            ),
            DimensionSchema(
                cube="Customers",
                name="city",
                display_name="åŸå¸‚",
                description="å®¢æˆ·æ‰€åœ¨çš„åŸå¸‚",
                data_type="string"
            ),
            DimensionSchema(
                cube="Products",
                name="category",
                display_name="å•†å“ç±»åˆ«",
                description="å•†å“æ‰€å±çš„åˆ†ç±»",
                data_type="string"
            ),
        ]

        return measures, dimensions


# ============================================================================
# åµŒå…¥æœåŠ¡
# ============================================================================

class SimpleEmbeddingService:
    """ç®€å•çš„åµŒå…¥æœåŠ¡ï¼ˆä¸ä¾èµ–å¤–éƒ¨æ¨¡å‹ï¼‰

    ä½œä¸ºå›é€€æ–¹æ¡ˆï¼Œæä¾›åŸºç¡€çš„å‘é‡ç¼–ç 
    """

    def encode(self, texts: List[str]) -> np.ndarray:
        """ç¼–ç æ–‡æœ¬åˆ—è¡¨"""
        embeddings = []
        for text in texts:
            embeddings.append(self._encode_single(text))
        return np.array(embeddings)

    def _encode_single(self, text: str, dim: int = 128) -> np.ndarray:
        """ç®€å•çš„å­—ç¬¦çº§ç¼–ç """
        vector = np.zeros(dim, dtype=np.float32)

        # å­—ç¬¦çº§åˆ«ç‰¹å¾
        for i, char in enumerate(text[:dim]):
            idx = (ord(char) * (i + 1) * 31) % dim
            vector[idx] += 1.0 / (i + 1)

        # è¯å…ƒçº§åˆ«ç‰¹å¾ï¼ˆç®€å•æŒ‰ç©ºæ ¼åˆ†å‰²ï¼‰
        words = text.lower().split()
        for word in words:
            word_hash = hash(word) % dim
            vector[word_hash] += 0.5

        # å½’ä¸€åŒ–
        norm = np.linalg.norm(vector)
        if norm > 0:
            vector = vector / norm

        return vector


# ============================================================================
# Schema Pruning æœåŠ¡
# ============================================================================

class SchemaPruningService:
    """Schema Pruning æœåŠ¡

    æ ¹æ®ç”¨æˆ·æŸ¥è¯¢æ™ºèƒ½å‰ªæ Schemaï¼Œåªä¿ç•™ç›¸å…³çš„å…ƒç´ 
    """

    def __init__(
        self,
        measures: Optional[List[MeasureSchema]] = None,
        dimensions: Optional[List[DimensionSchema]] = None,
        embedding_service=None,
        similarity_threshold: float = 0.3,
        max_measures: int = 10,
        max_dimensions: int = 10,
        enable_caching: bool = True
    ):
        """åˆå§‹åŒ–

        Args:
            measures: åº¦é‡åˆ—è¡¨
            dimensions: ç»´åº¦åˆ—è¡¨
            embedding_service: åµŒå…¥æœåŠ¡
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            max_measures: æœ€å¤šä¿ç•™çš„åº¦é‡æ•°é‡
            max_dimensions: æœ€å¤šä¿ç•™çš„ç»´åº¦æ•°é‡
            enable_caching: æ˜¯å¦å¯ç”¨ç¼“å­˜
        """
        # åŠ è½½ Schema
        loader = SchemaLoader()
        if measures is None:
            self.measures = loader.load_from_yaml()[0]
            if not self.measures:
                self.measures = loader.load_from_builtin()[0]
        else:
            self.measures = measures

        if dimensions is None:
            self.dimensions = loader.load_from_yaml()[1]
            if not self.dimensions:
                self.dimensions = loader.load_from_builtin()[1]
        else:
            self.dimensions = dimensions

        # åµŒå…¥æœåŠ¡
        self.embedding_service = embedding_service or SimpleEmbeddingService()

        # é…ç½®
        self.similarity_threshold = similarity_threshold
        self.max_measures = max_measures
        self.max_dimensions = max_dimensions
        self.enable_caching = enable_caching

        # é¢„è®¡ç®—åµŒå…¥
        self._precompute_embeddings()

    def _precompute_embeddings(self):
        """é¢„è®¡ç®—æ‰€æœ‰å…ƒç´ çš„åµŒå…¥å‘é‡"""
        # åº¦é‡åµŒå…¥
        measure_texts = [m.get_search_text() for m in self.measures]
        if measure_texts:
            self._measure_embeddings = self.embedding_service.encode(measure_texts)
        else:
            self._measure_embeddings = np.array([])

        # ç»´åº¦åµŒå…¥
        dimension_texts = [d.get_search_text() for d in self.dimensions]
        if dimension_texts:
            self._dimension_embeddings = self.embedding_service.encode(dimension_texts)
        else:
            self._dimension_embeddings = np.array([])

        logger.info(
            f"é¢„è®¡ç®—åµŒå…¥å®Œæˆ: {len(self.measures)} ä¸ªåº¦é‡, {len(self.dimensions)} ä¸ªç»´åº¦"
        )

    def prune(
        self,
        query: str,
        include_cube: Optional[str] = None,
        force_measures: Optional[List[str]] = None,
        force_dimensions: Optional[List[str]] = None
    ) -> PruningResult:
        """æ‰§è¡Œ Schema å‰ªæ

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            include_cube: åªåŒ…å«æŒ‡å®š Cube çš„å…ƒç´ 
            force_measures: å¼ºåˆ¶åŒ…å«çš„åº¦é‡åç§°åˆ—è¡¨
            force_dimensions: å¼ºåˆ¶åŒ…å«çš„ç»´åº¦åç§°åˆ—è¡¨

        Returns:
            å‰ªæç»“æœ
        """
        # ç¼–ç æŸ¥è¯¢
        query_embedding = self.embedding_service.encode([query])[0]

        # è®¡ç®—åº¦é‡ç›¸ä¼¼åº¦
        measure_scores = self._compute_similarities(
            query_embedding,
            self._measure_embeddings,
            self.measures,
            include_cube
        )

        # è®¡ç®—ç»´åº¦ç›¸ä¼¼åº¦
        dimension_scores = self._compute_similarities(
            query_embedding,
            self._dimension_embeddings,
            self.dimensions,
            include_cube
        )

        # å¼ºåˆ¶åŒ…å«æŒ‡å®šå…ƒç´ 
        if force_measures:
            for i, m in enumerate(self.measures):
                if m.name in force_measures:
                    measure_scores[i] = 1.0

        if force_dimensions:
            for i, d in enumerate(self.dimensions):
                if d.name in force_dimensions:
                    dimension_scores[i] = 1.0

        # é€‰æ‹©é«˜åˆ†å…ƒç´ 
        selected_measures, excluded_measures = self._select_by_score(
            self.measures,
            measure_scores,
            self.max_measures
        )

        selected_dimensions, excluded_dimensions = self._select_by_score(
            self.dimensions,
            dimension_scores,
            self.max_dimensions
        )

        # æ”¶é›†æ¶‰åŠçš„ Cube
        selected_cubes = set()
        for m in selected_measures:
            selected_cubes.add(m.cube)
        for d in selected_dimensions:
            selected_cubes.add(d.cube)

        # è®¡ç®—å¾—åˆ†å­—å…¸
        scores = {}
        for i, m in enumerate(self.measures):
            scores[f"measure.{m.cube}.{m.name}"] = measure_scores[i]
        for i, d in enumerate(self.dimensions):
            scores[f"dimension.{d.cube}.{d.name}"] = dimension_scores[i]

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_original = len(self.measures) + len(self.dimensions)
        total_selected = len(selected_measures) + len(selected_dimensions)
        reduction_rate = 1.0 - (total_selected / total_original) if total_original > 0 else 0

        return PruningResult(
            query=query,
            selected_measures=selected_measures,
            selected_dimensions=selected_dimensions,
            selected_cubes=selected_cubes,
            excluded_measures=excluded_measures,
            excluded_dimensions=excluded_dimensions,
            scores=scores,
            total_original=total_original,
            total_selected=total_selected,
            reduction_rate=reduction_rate
        )

    def _compute_similarities(
        self,
        query_embedding: np.ndarray,
        element_embeddings: np.ndarray,
        elements: List,
        include_cube: Optional[str]
    ) -> List[float]:
        """è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°"""
        if len(element_embeddings) == 0:
            return []

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = []
        for i, (embedding, element) in enumerate(zip(element_embeddings, elements)):
            # è¿‡æ»¤ Cube
            if include_cube and element.cube != include_cube:
                similarities.append(0.0)
                continue

            # ä½™å¼¦ç›¸ä¼¼åº¦
            similarity = self._cosine_similarity(query_embedding, embedding)
            similarities.append(similarity)

        return similarities

    @staticmethod
    def _cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        dot_product = np.dot(a, b)
        norm_a = np.linalg.norm(a)
        norm_b = np.linalg.norm(b)
        if norm_a == 0 or norm_b == 0:
            return 0.0
        return float(dot_product / (norm_a * norm_b))

    def _select_by_score(
        self,
        elements: List,
        scores: List[float],
        max_count: int
    ) -> Tuple[List, List]:
        """æ ¹æ®åˆ†æ•°é€‰æ‹©å…ƒç´ 

        Returns:
            (é€‰ä¸­åˆ—è¡¨, æ’é™¤åˆ—è¡¨)
        """
        # æŒ‰åˆ†æ•°æ’åº
        indexed_scores = list(enumerate(scores))
        indexed_scores.sort(key=lambda x: x[1], reverse=True)

        # é€‰æ‹©é«˜åˆ†å…ƒç´ 
        selected_indices = set()
        for idx, score in indexed_scores:
            if score >= self.similarity_threshold and len(selected_indices) < max_count:
                selected_indices.add(idx)
            if len(selected_indices) >= max_count:
                break

        selected = [elements[i] for i in selected_indices]
        excluded = [elements[i] for i in range(len(elements)) if i not in selected_indices]

        return selected, excluded

    def get_pruned_schema_dict(
        self,
        query: str,
        include_cube: Optional[str] = None
    ) -> Dict[str, Any]:
        """è·å–å‰ªæåçš„ Schema å­—å…¸ï¼ˆç”¨äºæ³¨å…¥ Promptï¼‰

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            include_cube: åªåŒ…å«æŒ‡å®š Cube

        Returns:
            Schema å­—å…¸ï¼Œå¯åºåˆ—åŒ–ä¸º JSON
        """
        result = self.prune(query, include_cube)

        # æŒ‰ç«‹æ–¹ç»„ç»‡
        schema_dict = {
            "cubes": {}
        }

        for cube in result.selected_cubes:
            cube_measures = [m for m in result.selected_measures if m.cube == cube]
            cube_dimensions = [d for d in result.selected_dimensions if d.cube == cube]

            schema_dict["cubes"][cube] = {
                "measures": [m.to_dict() for m in cube_measures],
                "dimensions": [d.to_dict() for d in cube_dimensions]
            }

        schema_dict["summary"] = {
            "total_measures": len(result.selected_measures),
            "total_dimensions": len(result.selected_dimensions),
            "cubes_count": len(result.selected_cubes),
            "reduction_rate": result.reduction_rate
        }

        return schema_dict

    def get_pruned_prompt_text(
        self,
        query: str,
        include_cube: Optional[str] = None,
        format: str = "compact"
    ) -> str:
        """è·å–å‰ªæåçš„ Prompt æ–‡æœ¬

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            include_cube: åªåŒ…å«æŒ‡å®š Cube
            format: æ ¼å¼ç±»å‹ (compact/detailed)

        Returns:
            å¯æ³¨å…¥åˆ° Prompt çš„æ–‡æœ¬
        """
        result = self.prune(query, include_cube)

        lines = [
            "## ç›¸å…³æ•°æ® Schemaï¼ˆå·²æ ¹æ®æŸ¥è¯¢ä¼˜åŒ–ï¼‰",
            ""
        ]

        if format == "compact":
            # ç´§å‡‘æ ¼å¼
            for cube in sorted(result.selected_cubes):
                lines.append(f"### {cube}")
                measures = [m for m in result.selected_measures if m.cube == cube]
                dimensions = [d for d in result.selected_dimensions if d.cube == cube]

                if measures:
                    measure_list = ", ".join([m.display_name for m in measures])
                    lines.append(f"**åº¦é‡**: {measure_list}")

                if dimensions:
                    dim_list = ", ".join([d.display_name for d in dimensions])
                    lines.append(f"**ç»´åº¦**: {dim_list}")

                lines.append("")
        else:
            # è¯¦ç»†æ ¼å¼
            for cube in sorted(result.selected_cubes):
                lines.append(f"### {cube}")
                lines.append("")

                measures = [m for m in result.selected_measures if m.cube == cube]
                if measures:
                    lines.append("**åº¦é‡**:")
                    for m in measures:
                        lines.append(f"- {m.name} ({m.display_name}): {m.description}")
                    lines.append("")

                dimensions = [d for d in result.selected_dimensions if d.cube == cube]
                if dimensions:
                    lines.append("**ç»´åº¦**:")
                    for d in dimensions:
                        lines.append(f"- {d.name} ({d.display_name}): {d.description}")
                    lines.append("")

        lines.append(f"ğŸ’¡ å·²ä¼˜åŒ–ï¼šä»…æ˜¾ç¤ºä¸æŸ¥è¯¢ç›¸å…³çš„ {result.total_selected} ä¸ªå­—æ®µï¼ˆå…± {result.total_original} ä¸ªï¼Œå‡å°‘ {result.reduction_rate:.0%}ï¼‰")

        return "\n".join(lines)


# ============================================================================
# ä¸­é—´ä»¶é›†æˆ
# ============================================================================

class SchemaPruningMiddleware:
    """Schema Pruning ä¸­é—´ä»¶

    åœ¨ Agent æ‰§è¡Œå‰è‡ªåŠ¨å‰ªæ Schema
    """

    def __init__(
        self,
        pruning_service: Optional[SchemaPruningService] = None,
        enable_auto_prune: bool = True,
        injection_mode: str = "context"  # prompt, context, both
    ):
        """åˆå§‹åŒ–

        Args:
            pruning_service: å‰ªææœåŠ¡
            enable_auto_prune: æ˜¯å¦å¯ç”¨è‡ªåŠ¨å‰ªæ
            injection_mode: æ³¨å…¥æ¨¡å¼
        """
        self.pruning_service = pruning_service or SchemaPruningService()
        self.enable_auto_prune = enable_auto_prune
        self.injection_mode = injection_mode

    def before_agent_execution(
        self,
        agent_input: Dict[str, Any]
    ) -> Dict[str, Any]:
        """åœ¨ Agent æ‰§è¡Œå‰å¤„ç†

        Args:
            agent_input: Agent è¾“å…¥

        Returns:
            å¢å¼ºåçš„ Agent è¾“å…¥
        """
        if not self.enable_auto_prune:
            return agent_input

        query = agent_input.get("query", "")
        if not query:
            return agent_input

        # æ‰§è¡Œå‰ªæ
        schema_dict = self.pruning_service.get_pruned_schema_dict(query)

        # æ³¨å…¥åˆ° Agent è¾“å…¥
        if self.injection_mode in ("prompt", "both"):
            prompt_text = self.pruning_service.get_pruned_prompt_text(query)
            agent_input["__pruned_schema_prompt__"] = prompt_text

        if self.injection_mode in ("context", "both"):
            agent_input["__pruned_schema_context__"] = schema_dict

        agent_input["__schema_pruning_summary__"] = schema_dict.get("summary", {})

        return agent_input

    def enhance_system_prompt(self, base_prompt: str, query: str) -> str:
        """å¢å¼ºç³»ç»Ÿæç¤ºè¯"""
        if not self.enable_auto_prune:
            return base_prompt

        pruned_text = self.pruning_service.get_pruned_prompt_text(query)

        return f"""{base_prompt}

{pruned_text}
"""


# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

def get_relevant_schema(query: str, max_results: int = 10) -> str:
    """è·å–ä¸æŸ¥è¯¢ç›¸å…³çš„ Schema - ä¾› LLM è°ƒç”¨

    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        max_results: æœ€å¤§ç»“æœæ•°é‡

    Returns:
        JSON æ ¼å¼çš„ç›¸å…³ Schema
    """
    service = SchemaPruningService(
        max_measures=max_results,
        max_dimensions=max_results
    )

    result = service.get_pruned_schema_dict(query)

    return json.dumps(result, ensure_ascii=False, indent=2)


# ============================================================================
# æµ‹è¯•ä»£ç 
# ============================================================================

if __name__ == "__main__":
    import sys

    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    print("=" * 60)
    print("Schema Pruning æœåŠ¡æµ‹è¯•")
    print("=" * 60)

    # åˆ›å»ºæœåŠ¡
    service = SchemaPruningService()

    print(f"\n[åˆå§‹åŒ–] åŠ è½½äº† {len(service.measures)} ä¸ªåº¦é‡, {len(service.dimensions)} ä¸ªç»´åº¦")

    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "è®¢å•æ€»æ”¶å…¥æ˜¯å¤šå°‘",
        "æŒ‰åŸå¸‚ç»Ÿè®¡å®¢æˆ·æ•°é‡",
        "åˆ†ææœ€è¿‘ä¸€ä¸ªæœˆçš„é”€å”®è¶‹åŠ¿",
        "iPhone çš„é”€é‡å¦‚ä½•",
        "å„ä¸ªå•†å“ç±»åˆ«çš„å¹³å‡ä»·æ ¼",
    ]

    for query in test_queries:
        print(f"\n[æµ‹è¯•] æŸ¥è¯¢: {query}")
        print("-" * 40)

        result = service.prune(query)

        print(f"é€‰ä¸­äº† {len(result.selected_measures)} ä¸ªåº¦é‡:")
        for m in result.selected_measures:
            score = result.scores.get(f"measure.{m.cube}.{m.name}", 0)
            print(f"  - {m.display_name} ({m.cube}.{m.name}) - ç›¸ä¼¼åº¦: {score:.2f}")

        print(f"é€‰ä¸­äº† {len(result.selected_dimensions)} ä¸ªç»´åº¦:")
        for d in result.selected_dimensions:
            score = result.scores.get(f"dimension.{d.cube}.{d.name}", 0)
            print(f"  - {d.display_name} ({d.cube}.{d.name}) - ç›¸ä¼¼åº¦: {score:.2f}")

        print(f"æ¶‰åŠ Cube: {', '.join(sorted(result.selected_cubes))}")
        print(f"å‰Šå‡ç‡: {result.reduction_rate:.1%}")

    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 60)
