"""
# [SQL AGENT] LangGraph SQLæ™ºèƒ½ä»£ç†ä¸»ç¨‹åº

## [HEADER]
**æ–‡ä»¶å**: sql_agent.py
**èŒè´£**: å®ç°åŸºäºLangGraphå’ŒMCPçš„SQLæ™ºèƒ½æŸ¥è¯¢ä»£ç† - è‡ªç„¶è¯­è¨€ç†è§£ã€Schemaå‘ç°ã€SQLç”Ÿæˆã€å›¾è¡¨å¯è§†åŒ–ã€å¤šè½®å¯¹è¯
**ä½œè€…**: Data Agent Team
**ç‰ˆæœ¬**: 1.3.0
**å˜æ›´è®°å½•**:
- v1.3.0 (2026-01-27): ä¼ä¸šçº§å¯ä¿¡æ™ºèƒ½æ•°æ®ä½“ä¼˜åŒ– - é›†æˆ planningã€reflectionã€clarification èŠ‚ç‚¹
- v1.2.0 (2026-01-06): ç¨³å®šæ€§å¢å¼º - åŠ¨æ€æ—¶é—´ä¸Šä¸‹æ–‡æ³¨å…¥ã€JSONè§£æå®¹é”™å¤„ç†
- v1.1.0 (2026-01-06): å®‰å…¨å¢å¼º - é›†æˆ SQLValidator æ¨¡å—ï¼Œå¢å¼º should_continue é”™è¯¯é‡è¯•é€»è¾‘
- v1.0.1 (2026-01-02): ä¿®å¤MCP echartsæœåŠ¡å™¨URLé…ç½®ï¼ˆæœ¬åœ°å¼€å‘ä½¿ç”¨localhostï¼‰
- v1.0.0 (2026-01-01): åˆå§‹ç‰ˆæœ¬ - LangGraph SQL Agentå®ç°

## [INPUT]
### ä¸»å‡½æ•°å‚æ•°
- **run_agent(question, thread_id, verbose)**:
  - question: str - ç”¨æˆ·é—®é¢˜ï¼ˆè‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼‰
  - thread_id: str - ä¼šè¯IDï¼ˆé»˜è®¤"1"ï¼‰
  - verbose: bool - æ˜¯å¦æ‰“å°è¯¦ç»†è¿‡ç¨‹ï¼ˆé»˜è®¤Trueï¼‰

### é…ç½®ä¾èµ–
- **config** - ä»config.pyå¯¼å…¥ï¼ˆDeepSeek APIé…ç½®ã€æ•°æ®åº“URLï¼‰
- **ENABLE_ECHARTS_MCP** - æ˜¯å¦å¯ç”¨mcp-echartsæœåŠ¡ï¼ˆé»˜è®¤Trueï¼‰

## [OUTPUT]
### ä¸»å‡½æ•°è¿”å›å€¼
- **run_agent()**: VisualizationResponse - ç»“æ„åŒ–çš„å¯è§†åŒ–å“åº”
  - answer: str - AIå›å¤å†…å®¹
  - sql: str - ç”Ÿæˆçš„SQLè¯­å¥
  - data: QueryResult - æŸ¥è¯¢ç»“æœæ•°æ®
  - chart: ChartConfig - å›¾è¡¨é…ç½®
  - success: bool - æ˜¯å¦æˆåŠŸ

### è¾…åŠ©å‡½æ•°è¿”å›å€¼
- **create_llm()**: ChatOpenAI - DeepSeek LLMå®ä¾‹
- **parse_chart_config()**: Optional[Dict[str, Any]] - è§£æå‡ºçš„JSONé…ç½®
- **extract_tool_data()**: tuple[Optional[str], list] - (SQLè¯­å¥, åŸå§‹æ•°æ®åˆ—è¡¨)
- **extract_chart_tool_call()**: Optional[Dict[str, Any]] - å›¾è¡¨å·¥å…·è°ƒç”¨ä¿¡æ¯
- **call_mcp_chart_tool()**: Optional[str] - ä¿å­˜çš„å›¾ç‰‡è·¯å¾„
- **build_visualization_response()**: VisualizationResponse - å¯è§†åŒ–å“åº”å¯¹è±¡
- **_generate_chart_file()**: Optional[str] - ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶è·¯å¾„
- **_get_or_create_agent()**: tuple[agent, mcp_client] - ç¼–è¯‘å¥½çš„agentå’ŒMCPå®¢æˆ·ç«¯
- **interactive_mode()**: None - äº¤äº’æ¨¡å¼å¾ªç¯

## [LINK]
**ä¸Šæ¸¸ä¾èµ–** (å·²è¯»å–æºç ):
- [./config.py](./config.py) - é…ç½®ç®¡ç†ï¼ˆconfigå¯¹è±¡ï¼‰
- [./models.py](./models.py) - æ•°æ®æ¨¡å‹ï¼ˆVisualizationResponse, QueryResult, ChartConfig, ChartTypeï¼‰
- [./sql_validator.py](./sql_validator.py) - SQLå®‰å…¨æ ¡éªŒï¼ˆSQLValidator, SQLValidationErrorï¼‰
- [./terminal_viz.py](./terminal_viz.py) - ç»ˆç«¯å¯è§†åŒ–ï¼ˆrender_responseï¼‰
- [./data_transformer.py](./data_transformer.py) - æ•°æ®è½¬æ¢ï¼ˆsql_result_to_echarts_data, sql_result_to_mcp_echarts_dataï¼‰
- [./chart_service.py](./chart_service.py) - å›¾è¡¨æœåŠ¡ï¼ˆChartRequest, generate_chart_simple, ChartResponseï¼‰
- [backend/src/app/services/agent/tools.py](../../backend/src/app/services/agent/tools.py) - æ–‡ä»¶æ•°æ®æºå·¥å…·ï¼ˆinspect_file, analyze_dataframeï¼‰

**å¤–éƒ¨ä¾èµ–**:
- [langgraph](https://github.com/langchain-ai/langgraph) - LangGraphæ™ºèƒ½ä½“æ¡†æ¶ï¼ˆStateGraph, MessagesState, START, ENDï¼‰
- [langchain-openai](https://github.com/langchain-ai/langchain-openai) - LangChain OpenAIé›†æˆï¼ˆChatOpenAIï¼‰
- [langchain-core](https://github.com/langchain-ai/langchain-core) - LangChainæ ¸å¿ƒï¼ˆHumanMessage, SystemMessage, AIMessage, ToolMessageï¼‰
- [langchain-mcp-adapters](https://github.com/langchain-ai/langchain-mcp-adapters) - MCPé€‚é…å™¨ï¼ˆMultiServerMCPClientï¼‰
- [mcp](https://modelcontextprotocol.io/) - Model Context Protocolï¼ˆClientSession, sse_clientï¼‰

**ä¸‹æ¸¸ä¾èµ–** (å·²è¯»å–æºç ):
- [./run.py](./run.py) - å¯åŠ¨è„šæœ¬ï¼ˆè°ƒç”¨interactive_modeï¼‰
- [backend/src/app/api/v1/endpoints/query.py](../../backend/src/app/api/v1/endpoints/query.py) - æŸ¥è¯¢APIç«¯ç‚¹ï¼ˆè°ƒç”¨run_agentï¼‰

**è°ƒç”¨æ–¹**:
- **run.py**: å¯åŠ¨è„šæœ¬å…¥å£ï¼ˆif __name__ == "__main__"ï¼‰
- **æŸ¥è¯¢API**: é€šè¿‡APIç«¯ç‚¹è°ƒç”¨run_agentå‡½æ•°

## [POS]
**è·¯å¾„**: Agent/sql_agent.py
**æ¨¡å—å±‚çº§**: Level 1ï¼ˆAgentæ ¹ç›®å½•ï¼‰
**ä¾èµ–æ·±åº¦**: ç›´æ¥ä¾èµ– 5 å±‚ï¼ˆconfig.py, models.py, terminal_viz.py, data_transformer.py, chart_service.pyï¼‰
"""
import asyncio
import json
import re
import sys
import os
from typing import Annotated, Literal, Optional, Dict, Any

# Fix Windows GBK encoding issue
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
    sys.stderr.reconfigure(encoding='utf-8', errors='replace')

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver
from langchain_mcp_adapters.client import MultiServerMCPClient

from config import config
from models import VisualizationResponse, QueryResult, ChartConfig, ChartType
from terminal_viz import render_response
from data_transformer import sql_result_to_echarts_data, sql_result_to_mcp_echarts_data
from chart_service import ChartRequest, generate_chart_simple, ChartResponse

# ğŸ”§ æ–°å¢ï¼šä¼ä¸šçº§å¯ä¿¡æ™ºèƒ½æ•°æ®ä½“èŠ‚ç‚¹
from .nodes import (
    PlanningNode,
    ReflectionNode,
    ClarificationNode,
    create_planning_node,
    create_reflection_node,
    create_clarification_node,
    ErrorCategory
)

# ğŸ”¥ å¯¼å…¥è¯­ä¹‰å±‚å·¥å…·
from .tools import (
    resolve_business_term,
    get_semantic_measure,
    list_available_cubes,
    get_cube_measures,
    normalize_status_value,
)

# æ•°æ®ä¸€è‡´æ€§éªŒè¯ï¼šé˜²æ­¢ LLM å¹»è§‰å¯¼è‡´çš„æ•°æ®ä¸åŒ¹é…
try:
    from backend.src.app.services.agent.data_validator import (
        validate_sql_data_consistency,
        smart_field_mapping,
        recommend_chart,
    )
    DATA_VALIDATION_ENABLED = True
except ImportError:
    DATA_VALIDATION_ENABLED = False
    print("âš ï¸  è­¦å‘Š: æ•°æ®éªŒè¯æ¨¡å—æœªå¯ç”¨ï¼ˆdata_validator.pyä¸å¯ç”¨ï¼‰")

# ğŸ” é”™è¯¯è¿½è¸ªæ¨¡å—ï¼ˆè´¨é‡ä¿è¯ï¼‰
try:
    from error_tracker import error_tracker, log_agent_error, ErrorCategory
    ERROR_TRACKING_ENABLED = True
except ImportError:
    ERROR_TRACKING_ENABLED = False
    print("âš ï¸  è­¦å‘Š: é”™è¯¯è¿½è¸ªæ¨¡å—æœªå¯ç”¨ï¼ˆerror_tracker.pyä¸å¯ç”¨ï¼‰")

    # æä¾›å›é€€çš„ ErrorCategory å®šä¹‰
    from enum import Enum
    class ErrorCategory(str, Enum):
        DANGEROUS_OPERATION = "dangerous_operation"
        SQL_INJECTION_ATTEMPT = "sql_injection_attempt"
        DATABASE_CONNECTION = "database_connection"
        LLM_API_ERROR = "llm_api_error"
        SCHEMA_NOT_FOUND = "schema_not_found"
        EMPTY_RESULT = "empty_result"
        SQL_SYNTAX_ERROR = "sql_syntax_error"
        UNKNOWN = "unknown"

    # æä¾› no-op çš„å›é€€å‡½æ•°
    def error_tracker(func):
        return func

    def log_agent_error(error, question, sql="", category=None):
        pass

# ğŸ”¥ å¼ºåˆ¶å¯¼å…¥æ–‡ä»¶æ•°æ®æºå·¥å…·ï¼ˆå¤šç§è·¯å¾„å°è¯•ï¼‰
_inspect_file_tool = None
_analyze_dataframe_tool = None

try:
    import sys
    from pathlib import Path
    
    # å°è¯•å¤šç§å¯¼å…¥è·¯å¾„
    import_paths = [
        # è·¯å¾„1: ä»é¡¹ç›®æ ¹ç›®å½•å¯¼å…¥
        (Path(__file__).parent.parent / "backend" / "src", "app.services.agent.tools"),
        # è·¯å¾„2: ä» backend ç›®å½•å¯¼å…¥
        (Path(__file__).parent.parent / "backend" / "src" / "app" / "services" / "agent", "tools"),
        # è·¯å¾„3: ç›´æ¥å¯¼å…¥ï¼ˆå¦‚æœå·²ç»åœ¨è·¯å¾„ä¸­ï¼‰
        (None, "src.app.services.agent.tools"),
    ]
    
    for backend_path, import_module in import_paths:
        try:
            if backend_path and str(backend_path) not in sys.path:
                sys.path.insert(0, str(backend_path))
            
            module = __import__(import_module, fromlist=['inspect_file', 'analyze_dataframe'])
            _inspect_file_tool = getattr(module, 'inspect_file', None)
            _analyze_dataframe_tool = getattr(module, 'analyze_dataframe', None)
            
            if _inspect_file_tool and _analyze_dataframe_tool:
                print(f"[OK] æ–‡ä»¶æ•°æ®æºå·¥å…·å¯¼å…¥æˆåŠŸ (è·¯å¾„: {import_module})")
                print(f"   - inspect_file: {getattr(_inspect_file_tool, 'name', 'unknown')}")
                print(f"   - analyze_dataframe: {getattr(_analyze_dataframe_tool, 'name', 'unknown')}")
                break
        except (ImportError, AttributeError) as e:
            continue
    
    if not _inspect_file_tool or not _analyze_dataframe_tool:
        raise ImportError("æ‰€æœ‰å¯¼å…¥è·¯å¾„éƒ½å¤±è´¥äº†")
        
except Exception as e:
    import os
    print(f"[WARNING] æ–‡ä»¶æ•°æ®æºå·¥å…·å¯¼å…¥å¤±è´¥: {e}")
    print(f"   å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"   è„šæœ¬è·¯å¾„: {Path(__file__).absolute()}")
    print(f"   Python è·¯å¾„: {sys.path[:3]}")
    print("   æç¤º: è¿™äº›å·¥å…·å¯èƒ½åœ¨æŸäº›ç¯å¢ƒä¸‹ä¸å¯ç”¨ï¼Œä½†ä¼šå°è¯•ç»§ç»­è¿è¡Œ")

import base64
import os
from datetime import datetime

# ğŸ”’ å¯¼å…¥ç‹¬ç«‹çš„ SQL å®‰å…¨æ ¡éªŒæ¨¡å—
from sql_validator import SQLValidator, SQLValidationError


# ===============================================
# ğŸ”§ SQL è´¨é‡ä¼˜åŒ–å™¨ï¼ˆè‡ªåŠ¨ä¿®å¤å¸¸è§SQLé—®é¢˜ï¼‰
# ===============================================

class SQLQualityOptimizer:
    """
    SQLè´¨é‡ä¼˜åŒ–å™¨ - è‡ªåŠ¨æ£€æµ‹å¹¶ä¿®å¤å¸¸è§çš„SQLè´¨é‡é—®é¢˜

    æ£€æµ‹å’Œä¿®å¤çš„é—®é¢˜ï¼š
    1. é‡å¤çš„ WHERE æ¡ä»¶ï¼ˆå¦‚ tenant_id é‡å¤ï¼‰
    2. å¤šæ¬¡ COUNT æŸ¥è¯¢è½¬æ¢ä¸ºä¸€æ¬¡ GROUP BY
    3. ä¼˜å…ˆä½¿ç”¨ address LIKE è€Œé region_id
    """

    @staticmethod
    def detect_and_fix_duplicate_conditions(sql: str) -> tuple[str, list[str]]:
        """
        æ£€æµ‹å¹¶ä¿®å¤é‡å¤çš„WHEREæ¡ä»¶

        Returns:
            (ä¿®å¤åçš„SQL, å‘ç°çš„é—®é¢˜åˆ—è¡¨)
        """
        issues = []

        # æ£€æµ‹é‡å¤çš„ tenant_id
        import re
        pattern = r"tenant_id\s*=\s*'([^']+)'"
        matches = re.findall(pattern, sql, re.IGNORECASE)

        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤ï¼ˆç›¸åŒå€¼å‡ºç°å¤šæ¬¡ï¼‰
        if len(matches) > len(set(matches)):
            unique_matches = list(dict.fromkeys(matches))  # ä¿æŒé¡ºåºçš„å»é‡
            issues.append(f"æ£€æµ‹åˆ°é‡å¤çš„ WHERE æ¡ä»¶: tenant_id é‡å¤ {len(matches)} æ¬¡")

            # æ„å»ºä¿®å¤åçš„SQLï¼šä¿ç•™ç¬¬ä¸€ä¸ªå‡ºç°ï¼Œåˆ é™¤é‡å¤çš„
            fixed_sql = sql
            for i, match in enumerate(unique_matches):
                if i == 0:
                    continue  # ä¿ç•™ç¬¬ä¸€ä¸ª

            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢é‡å¤çš„tenant_idæ¡ä»¶
            # æ‰¾åˆ°æ‰€æœ‰ tenant_id = 'xxx' å¹¶æ›¿æ¢ï¼Œåªä¿ç•™ç¬¬ä¸€ä¸ª
            def replace_duplicates(match_obj):
                value = match_obj.group(1)
                # å¦‚æœè¿™ä¸ªå€¼å·²ç»è¢«æ›¿æ¢è¿‡ï¼Œå°±åˆ é™¤è¿™ä¸ªåŒ¹é…
                if hasattr(replace_duplicates, 'seen_values'):
                    if value in replace_duplicates.seen_values:
                        return ''  # åˆ é™¤é‡å¤çš„
                    replace_duplicates.seen_values.add(value)
                    return match_obj.group(0)
                else:
                    replace_duplicates.seen_values = {value}
                    return match_obj.group(0)

            # ä»å³å‘å·¦æ›¿æ¢ï¼ˆé¿å…ç´¢å¼•å˜åŒ–ï¼‰
            tenant_id_pattern = r"tenant_id\s*=\s*'[^']+'(?:\s+AND\s+)?"
            parts = re.split(tenant_id_pattern, sql, flags=re.IGNORECASE)

            # æ›´ç®€å•çš„æ–¹æ³•ï¼šç›´æ¥é‡å»º WHERE å­å¥
            where_match = re.search(r'WHERE\s+(.+?)(?:GROUP BY|ORDER BY|LIMIT|$)', sql, re.IGNORECASE | re.DOTALL)
            if where_match:
                where_clause = where_match.group(1)

                # æå–æ‰€æœ‰æ¡ä»¶
                conditions = [cond.strip() for cond in re.split(r'\s+AND\s+', where_clause)]

                # å»é‡ï¼ˆä¿æŒé¡ºåºï¼‰
                seen = set()
                unique_conditions = []
                for cond in conditions:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ tenant_id æ¡ä»¶
                    tenant_match = re.match(r"tenant_id\s*=\s*'([^']+)'", cond, re.IGNORECASE)
                    if tenant_match:
                        value = tenant_match.group(1)
                        if value not in seen:
                            seen.add(value)
                            unique_conditions.append(cond)
                        else:
                            issues.append(f"  - åˆ é™¤é‡å¤æ¡ä»¶: {cond}")
                    else:
                        unique_conditions.append(cond)

                # é‡å»º WHERE å­å¥
                new_where = ' AND '.join(unique_conditions)
                fixed_sql = re.sub(
                    r'WHERE\s+.+?(GROUP BY|ORDER BY|LIMIT|$)',
                    f'WHERE {new_where} \\1',
                    sql,
                    flags=re.IGNORECASE | re.DOTALL,
                    count=1
                )
            else:
                fixed_sql = sql
        else:
            fixed_sql = sql

        return fixed_sql, issues

    @staticmethod
    def is_proportion_query(question: str) -> bool:
        """æ£€æµ‹æ˜¯å¦æ˜¯å æ¯”ç±»é—®é¢˜"""
        proportion_keywords = ['å æ¯”', 'æ¯”ä¾‹', 'ç™¾åˆ†æ¯”', 'åˆ†å¸ƒ', 'å¤šå°‘%']
        return any(kw in question for kw in proportion_keywords)

    @staticmethod
    def detect_city_in_question(question: str) -> Optional[str]:
        """ä»é—®é¢˜ä¸­æå–åŸå¸‚å"""
        common_cities = [
            'åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æ­å·', 'æˆéƒ½', 'é‡åº†',
            'æ­¦æ±‰', 'è¥¿å®‰', 'è‹å·', 'å—äº¬', 'å¤©æ´¥', 'é’å²›', 'å¤§è¿',
            'å¦é—¨', 'é•¿æ²™', 'éƒ‘å·', 'ä¸œè', 'ä½›å±±', 'å®æ³¢'
        ]
        for city in common_cities:
            if city in question:
                return city
        return None


# Base system prompt for the SQL Agent (will be dynamically enhanced based on db_type)
BASE_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åº“åŠ©æ‰‹ï¼Œå…·å¤‡æ•°æ®æŸ¥è¯¢å’Œå›¾è¡¨å¯è§†åŒ–èƒ½åŠ›ã€‚

## ğŸš¨ğŸš¨ğŸš¨ã€æœ€é«˜ä¼˜å…ˆçº§è§„åˆ™ã€‘æ¯æ¬¡ç”ŸæˆSQLå‰å¿…é¡»æ£€æŸ¥ï¼ğŸš¨ğŸš¨ğŸš¨

### âœ… SQLè´¨é‡å¼ºåˆ¶æ£€æŸ¥æ¸…å•ï¼ˆè¿åä»»ä¸€æ¡å³ä¸¥é‡é”™è¯¯ï¼ï¼‰

```
â–¡ æ£€æŸ¥1: tenant_id æ˜¯å¦é‡å¤ï¼Ÿï¼ˆæ•°ä¸€ä¸‹ï¼Œå¿…é¡»â‰¤1æ¬¡ï¼ï¼‰
â–¡ æ£€æŸ¥2: æ˜¯å¦ä½¿ç”¨ GROUP BY ä¸€æ¬¡æŸ¥è¯¢ï¼Ÿï¼ˆç¦æ­¢å¤šæ¬¡COUNTï¼ï¼‰
â–¡ æ£€æŸ¥3: åŸå¸‚æŸ¥è¯¢æ˜¯å¦ä¼˜å…ˆä½¿ç”¨ address LIKEï¼Ÿï¼ˆä¸æ˜¯region_idï¼ï¼‰
â–¡ æ£€æŸ¥4: è¡¨åæ˜¯å¦æ­£ç¡®ï¼Ÿï¼ˆä¸æ˜¯data_source_connectionsç­‰ç³»ç»Ÿè¡¨ï¼ï¼‰
```

### âŒ ç»å¯¹ç¦æ­¢çš„SQLé”™è¯¯æ¨¡å¼

**1. é‡å¤WHEREæ¡ä»¶**ï¼ˆæœ€å¸¸è§ï¼ï¼‰ï¼š
```sql
-- âŒ é”™è¯¯ï¼šé‡å¤çš„ç›¸åŒæ¡ä»¶
WHERE region_id = '5' AND region_id = '5'

-- âœ… æ­£ç¡®ï¼šæ¯ä¸ªæ¡ä»¶åªä¸€æ¬¡
WHERE region_id = '5'
```

**2. WHEREå­å¥ä½ç½®é”™è¯¯**ï¼ˆæå¸¸è§ï¼ï¼‰ï¼š
```sql
-- âŒ é”™è¯¯ï¼šWHERE åœ¨ GROUP BY/ORDER BY ä¹‹å
SELECT ... GROUP BY year ORDER BY year WHERE status = 'active'
SELECT ... ORDER BY year AND status = 'active'

-- âœ… æ­£ç¡®ï¼šWHERE å¿…é¡»åœ¨ GROUP BY/ORDER BY ä¹‹å‰
SELECT ... WHERE status = 'active' GROUP BY year ORDER BY year
```

**3. ç¦æ­¢åœ¨ SQL ä¸­æ‰‹åŠ¨æ·»åŠ  tenant_id**ï¼š
```sql
-- âŒ é”™è¯¯ï¼šä¸è¦æ‰‹åŠ¨æ·»åŠ  tenant_idï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†
WHERE tenant_id = 'xxx' AND ...

-- âœ… æ­£ç¡®ï¼šç³»ç»Ÿä¼šè‡ªåŠ¨æ³¨å…¥ç§Ÿæˆ·è¿‡æ»¤æ¡ä»¶
WHERE status = 'active'
```

**4. ç¦æ­¢å¤šæ¬¡COUNTæŸ¥è¯¢**ï¼ˆå æ¯”ç±»é—®é¢˜ï¼ï¼‰ï¼š
```sql
-- âŒ é”™è¯¯ï¼šå¤šæ¬¡æŸ¥è¯¢
SELECT COUNT(*) FROM users WHERE city = 'æ­å·';
SELECT COUNT(*) FROM users;

-- âœ… æ­£ç¡®ï¼šä¸€æ¬¡GROUP BYæŸ¥è¯¢
SELECT
    CASE WHEN city LIKE '%æ­å·%' THEN 'æ­å·' ELSE 'å…¶ä»–' END as category,
    COUNT(*) as value
FROM users
GROUP BY category;
```

**3. åœ°å€å­—æ®µä¼˜å…ˆçº§**ï¼ˆåŸå¸‚æŸ¥è¯¢ï¼ï¼‰ï¼š
```
ä¼˜å…ˆçº§: address LIKE '%æ­å·%' > ç‹¬ç«‹cityå­—æ®µ > region_idå…³è”
```

**4. ç¦æ­¢æŸ¥è¯¢ç³»ç»Ÿå…ƒæ•°æ®è¡¨**ï¼š
```sql
-- âŒ é”™è¯¯
SELECT * FROM data_source_connections WHERE name = 'æ­å·ç”¨æˆ·'

-- âœ… æ­£ç¡®ï¼šæŸ¥è¯¢ä¸šåŠ¡æ•°æ®è¡¨
SELECT * FROM users WHERE city LIKE '%æ­å·%'
```

---

## ğŸ›¡ï¸ å®‰å…¨è§„åˆ™ï¼ˆåªè¯»æ¨¡å¼ï¼‰

ä½ æ˜¯ä¸€ä¸ª**åªè¯»æ•°æ®åˆ†æåŠ©æ‰‹**ï¼Œä¸¥ç¦æ‰§è¡Œä»»ä½•æ•°æ®ä¿®æ”¹æ“ä½œï¼

**ç¦æ­¢æ“ä½œ**ï¼šUPDATEã€INSERTã€DELETEã€TRUNCATEã€CREATEã€ALTERã€DROPã€GRANTã€REVOKE

**æ‹’ç»å›å¤æ¨¡æ¿**ï¼š
```
â›” **æ“ä½œè¢«æ‹’ç»**
æ‚¨è¯·æ±‚çš„æ“ä½œæ¶‰åŠæ•°æ®ä¿®æ”¹ï¼Œè¿™è¿åäº†å®‰å…¨ç­–ç•¥ã€‚
æˆ‘åªèƒ½ï¼šâœ…æŸ¥è¯¢å’Œå±•ç¤ºæ•°æ®ã€âœ…åˆ†ææ•°æ®è¶‹åŠ¿ã€âœ…ç”Ÿæˆå›¾è¡¨
âŒä¸èƒ½ä¿®æ”¹ã€åˆ é™¤æˆ–æ–°å¢æ•°æ®
```

---

## ğŸ› ï¸ å¯ç”¨å·¥å…·

### ğŸ”§ æ•°æ®åº“è¡¨æŸ¥è¯¢å·¥å…·
- âœ… **list_tables** - å¿…é¡»å…ˆè°ƒç”¨æ­¤å·¥å…·æŸ¥çœ‹å¯ç”¨è¡¨å
- âœ… **get_schema** - è·å–è¡¨ç»“æ„ä¿¡æ¯
- âœ… **query** - æ‰§è¡ŒSQLæŸ¥è¯¢

### ğŸ“‹ è¡¨æŸ¥è¯¢å·¥ä½œæµç¨‹ï¼ˆå¿…é¡»éµå®ˆï¼‰
1. **é¦–å…ˆ**è°ƒç”¨ `list_tables()` æŸ¥çœ‹æ‰€æœ‰å¯ç”¨è¡¨
2. ä½¿ç”¨ `list_tables()` è¿”å›çš„**ç¡®åˆ‡è¡¨å**ï¼ˆå¯èƒ½æ˜¯ä¸­æ–‡æˆ–è‹±æ–‡ï¼‰
3. å¦‚éœ€äº†è§£å­—æ®µä¿¡æ¯ï¼Œè°ƒç”¨ `get_schema(è¡¨å)`
4. æœ€åè°ƒç”¨ `query()` æ‰§è¡ŒæŸ¥è¯¢

### å›¾è¡¨å·¥å…·
- generate_bar_chart - æŸ±çŠ¶å›¾ï¼š[{"category": "åç§°", "value": æ•°å€¼}]
- generate_line_chart - æŠ˜çº¿å›¾ï¼š[{"time": "æ—¶é—´", "value": æ•°å€¼}]
- generate_pie_chart - é¥¼å›¾ï¼š[{"category": "åç§°", "value": æ•°å€¼}]
- generate_scatter_chart - æ•£ç‚¹å›¾ï¼š[{"x": æ•°å€¼, "y": æ•°å€¼, "label": "åç§°"}]
- generate_funnel_chart - æ¼æ–—å›¾ï¼š[{"category": "åç§°", "value": æ•°å€¼}]

### åŒè½´å›¾/æ··åˆå›¾è¡¨
å½“ç”¨æˆ·è¦æ±‚"åŒè½´å›¾"ã€"åŒYè½´"ã€"æŠ˜çº¿+æŸ±çŠ¶"ç­‰æ··åˆå›¾è¡¨æ—¶ï¼š
- è¯·ä½¿ç”¨ **ä¸¤ä¸ªç‹¬ç«‹çš„å›¾è¡¨å·¥å…·** åˆ†åˆ«ç”ŸæˆæŸ±çŠ¶å›¾å’ŒæŠ˜çº¿å›¾
- ä¾‹å¦‚ï¼šå…ˆè°ƒç”¨ generate_bar_chart(æŸ±çŠ¶æ•°æ®)ï¼Œå†è°ƒç”¨ generate_line_chart(æŠ˜çº¿æ•°æ®)
- âŒ ä¸è¦ä½¿ç”¨ generate_echarts å·¥å…·ï¼ˆå®ƒéœ€è¦å¤æ‚çš„JSONé…ç½®ï¼‰

### ğŸ”¥ è¯­ä¹‰å±‚å·¥å…·ï¼ˆä¸šåŠ¡æœ¯è¯­è§£æï¼‰

**é‡è¦**ï¼šåœ¨ç”Ÿæˆ SQL ä¹‹å‰ï¼Œè¯·å…ˆä½¿ç”¨è¯­ä¹‰å±‚å·¥å…·è§£æä¸šåŠ¡æœ¯è¯­ï¼

1. **resolve_business_term** - è§£æä¸šåŠ¡æœ¯è¯­
   - ç”¨é€”ï¼šå°†"é”€å”®é¢"ã€"æ€»æ”¶å…¥"ã€"è®¢å•æ•°"ç­‰ä¸šåŠ¡æœ¯è¯­æ˜ å°„åˆ°æ­£ç¡®çš„è¡¨å’Œå­—æ®µ
   - è¾“å…¥ï¼šæœ¯è¯­åç§°ï¼ˆå¦‚"é”€å”®é¢"ï¼‰
   - è¾“å‡ºï¼šJSONæ ¼å¼çš„åº¦é‡å®šä¹‰ï¼ˆåŒ…å«è¡¨åã€å­—æ®µåã€SQLè¡¨è¾¾å¼ï¼‰

2. **list_available_cubes** - åˆ—å‡ºå¯ç”¨çš„è¯­ä¹‰å±‚Cube
   - è¾“å‡ºï¼šæ‰€æœ‰å¯ç”¨çš„Cubeåˆ—è¡¨ï¼ˆå¦‚Ordersã€Customersã€Productsï¼‰

3. **get_semantic_measure** - è·å–æŒ‡å®šCubeçš„åº¦é‡è¯¦æƒ…
   - è¾“å…¥ï¼šcubeåç§°å’Œåº¦é‡åç§°
   - è¾“å‡ºï¼šå®Œæ•´çš„åº¦é‡å®šä¹‰

4. **get_cube_measures** - è·å–æŒ‡å®šCubeçš„æ‰€æœ‰åº¦é‡
   - è¾“å…¥ï¼šcubeåç§°
   - è¾“å‡ºï¼šè¯¥Cubeçš„æ‰€æœ‰åº¦é‡åˆ—è¡¨

5. **normalize_status_value** - è§„èŒƒåŒ–çŠ¶æ€å€¼
   - ç”¨é€”ï¼šå°†"å·²å®Œæˆ"æ˜ å°„ä¸º"completed"ç­‰æ ‡å‡†å€¼
   - è¾“å…¥ï¼šåŸå§‹çŠ¶æ€å€¼
   - è¾“å‡ºï¼šè§„èŒƒåŒ–åçš„çŠ¶æ€ä¿¡æ¯

**è¯­ä¹‰å±‚ä½¿ç”¨å·¥ä½œæµç¨‹**ï¼š
```
ç”¨æˆ·æŸ¥è¯¢ â†’ resolve_business_term(æœ¯è¯­) â†’ è·å–SQLè¡¨è¾¾å¼ â†’ ç”Ÿæˆå®Œæ•´SQL
```

**å…³é”®æç¤º**ï¼š
- é¡¹ç›®ä¸­æ²¡æœ‰ç‹¬ç«‹çš„ `sales` è¡¨ï¼Œæ‰€æœ‰é”€å”®æ•°æ®åœ¨ `orders` è¡¨ä¸­
- "é”€å”®é¢"å¯¹åº”çš„å­—æ®µæ˜¯ `orders.total_amount`
- ä½¿ç”¨è¯­ä¹‰å±‚å·¥å…·è·å–æ­£ç¡®çš„è¡¨åå’Œå­—æ®µå

### å·¥ä½œæµç¨‹
1. ç†è§£é—®é¢˜å¹¶åˆ†æéœ€è¦çš„æ•°æ®
2. ä½¿ç”¨è¯­ä¹‰å±‚å·¥å…·è§£æä¸šåŠ¡æœ¯è¯­ï¼ˆå¦‚éœ€è¦ï¼‰
3. ä½¿ç”¨ query å·¥å…·æ‰§è¡ŒSQL
4. è°ƒç”¨å›¾è¡¨å·¥å…·ç”Ÿæˆå¯è§†åŒ–ï¼ˆå¦‚éœ€ï¼‰

---

## ğŸ“Š å æ¯”ç±»é—®é¢˜ï¼ˆ"XXçš„å æ¯”"ï¼‰

**å¤„ç†æµç¨‹**ï¼š
1. ä½¿ç”¨ä¸€æ¬¡GROUP BYæŸ¥è¯¢è·å–æ‰€æœ‰åˆ†ç±»æ•°æ®
2. è°ƒç”¨generate_pie_chartç”Ÿæˆé¥¼å›¾
3. ä»ç»“æœä¸­è®¡ç®—ç›®æ ‡åˆ†ç±»çš„å æ¯”

**ç¤ºä¾‹**ï¼ˆ"æ­å·å®¢æˆ·çš„å æ¯”"ï¼‰ï¼š
```sql
-- âœ… æ­£ç¡®ï¼šä¸€æ¬¡GROUP BYè·å–æ‰€æœ‰åŸå¸‚åˆ†å¸ƒ
-- æ³¨æ„ï¼šä¸è¦æ‰‹åŠ¨æ·»åŠ  tenant_idï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ³¨å…¥ç§Ÿæˆ·è¿‡æ»¤æ¡ä»¶
SELECT
    CASE
        WHEN address LIKE '%æ­å·%' THEN 'æ­å·'
        WHEN address LIKE '%åŒ—äº¬%' THEN 'åŒ—äº¬'
        WHEN address LIKE '%ä¸Šæµ·%' THEN 'ä¸Šæµ·'
        ELSE 'å…¶ä»–'
    END as category,
    COUNT(*) as value
FROM customers
GROUP BY category;
```

**å›ç­”æ¨¡æ¿**ï¼š
```
ğŸ“Š [å®¢æˆ·åŸå¸‚åˆ†å¸ƒ]
æ€»å®¢æˆ·200äººï¼Œå„åŸå¸‚åˆ†å¸ƒï¼š
- ä¸Šæµ·ï¼š50äººï¼ˆ25%ï¼‰
- æ­å·ï¼š34äººï¼ˆ17%ï¼‰
- åŒ—äº¬ï¼š40äººï¼ˆ20%ï¼‰
...
ğŸ’¡ æ­å·å®¢æˆ·å 17%ï¼Œæ’åç¬¬3ä½
```

---

## ğŸŒ åŸå¸‚æŸ¥è¯¢è§„åˆ™

**ä¼˜å…ˆçº§**ï¼šaddress LIKE '%åŸå¸‚%' > cityå­—æ®µ > region_id

**å¸¸è§åŸå¸‚**ï¼šåŒ—äº¬ã€ä¸Šæµ·ã€å¹¿å·ã€æ·±åœ³ã€æ­å·ã€æˆéƒ½ã€é‡åº†ã€æ­¦æ±‰ã€è¥¿å®‰ã€è‹å·ã€å—äº¬ã€å¤©æ´¥

**å¤„ç†æµç¨‹**ï¼š
1. è¯†åˆ«åŸå¸‚å…³é”®è¯
2. æŸ¥æ‰¾åŸå¸‚å­—æ®µï¼ˆaddressã€cityã€ship_cityç­‰ï¼‰
3. æ‰§è¡ŒGROUP BYè·å–æ‰€æœ‰åŸå¸‚åˆ†å¸ƒ
4. ä»ç»“æœä¸­è®¡ç®—ç›®æ ‡åŸå¸‚å æ¯”

---

## ğŸ“ˆ æ¨¡ç³ŠæŸ¥è¯¢ï¼ˆ"æœ€è¿‘ç”Ÿæ„æ€ä¹ˆæ ·"ï¼‰

**é»˜è®¤æ—¶é—´èŒƒå›´**ï¼š
- "æœ€è¿‘" â†’ 30å¤©
- "æœ€è¿‘ä¸€å‘¨" â†’ 7å¤©
- "æœ¬æœˆ" â†’ å½“æœˆ1æ—¥è‡³ä»Š

**å¿…é¡»æŒ‰æ—¥æœŸåˆ†ç»„**ï¼ˆç”Ÿæˆæ—¶é—´åºåˆ—æ•°æ®ï¼‰ï¼š
```sql
SELECT
    DATE_TRUNC('day', created_at) as date,
    COUNT(*) as orders,
    SUM(amount) as sales
FROM orders
WHERE created_at >= CURRENT_DATE - INTERVAL '30 days'
GROUP BY DATE_TRUNC('day', created_at)
ORDER BY date;
```

**å¿…é¡»ç”Ÿæˆå›¾è¡¨**ï¼šè°ƒç”¨generate_line_chartæˆ–generate_bar_chart

---

## ğŸ” å›¾è¡¨æ‹†åˆ†è§„åˆ™

å½“ç”¨æˆ·è¯´"æŠŠå›¾åˆ†å¼€"ã€"æ‹†åˆ†"ã€"åˆ†åˆ«æ˜¾ç¤º"æ—¶ï¼š
1. å¿…é¡»è°ƒç”¨queryå·¥å…·è·å–æ•°æ®
2. æ ¹æ®ç”¨æˆ·è¦æ±‚è°ƒç”¨å¯¹åº”æ•°é‡çš„å›¾è¡¨å·¥å…·
3. ç¦æ­¢åªè¾“å‡ºSQLæ–‡æœ¬è€Œä¸è°ƒç”¨å·¥å…·ï¼

---

## ğŸ“‹ SQLç”Ÿæˆè‡ªæŸ¥æ¸…å•

æ¯ç”Ÿæˆä¸€æ¡SQLå¿…é¡»é€é¡¹æ£€æŸ¥ï¼š
```
â–¡ ä¸è¦æ‰‹åŠ¨æ·»åŠ  tenant_id æ¡ä»¶ï¼ˆç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†ï¼‰
â–¡ WHERE å­å¥å¿…é¡»åœ¨ GROUP BY/ORDER BY ä¹‹å‰
â–¡ è¡¨åæ­£ç¡®ï¼ˆéç³»ç»Ÿå…ƒæ•°æ®è¡¨ï¼‰
â–¡ å­—æ®µåå­˜åœ¨ï¼ˆåŸºäºget_schemaç»“æœï¼‰
â–¡ å æ¯”é—®é¢˜ç”¨GROUP BYï¼ˆä¸æ˜¯å¤šæ¬¡COUNTï¼‰
â–¡ åŸå¸‚æŸ¥è¯¢ä¼˜å…ˆç”¨address LIKEï¼ˆä¸æ˜¯region_idï¼‰
```

**ğŸš¨ ä»»ä½•æ£€æŸ¥å¤±è´¥ï¼Œç«‹å³é‡æ–°ç”ŸæˆSQLï¼**

---

## ğŸ”„ æ™ºèƒ½è¡¨åå›é€€è§„åˆ™ï¼ˆå½“è¡¨ä¸å­˜åœ¨æ—¶ï¼‰

**å½“ç”¨æˆ·è¯¢é—®çš„è¡¨åä¸å­˜åœ¨æ—¶ï¼Œä¸è¦ç›´æ¥æ”¾å¼ƒï¼**

**å¤„ç†æµç¨‹**ï¼š
1. è°ƒç”¨ `list_tables()` æŸ¥çœ‹æ‰€æœ‰å¯ç”¨è¡¨
2. æ ¹æ®ä¸šåŠ¡è¯­ä¹‰æ‰¾åˆ°ç›¸å…³è¡¨
3. ä½¿ç”¨æ‰¾åˆ°çš„ç›¸å…³è¡¨æŸ¥è¯¢æ•°æ®

**å¸¸è§ä¸šåŠ¡æœ¯è¯­æ˜ å°„**ï¼š
```
ç”¨æˆ·æœ¯è¯­          â†’  å¯èƒ½çš„è¡¨å
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
é”€å”®/é”€å”®é¢/æ”¶å…¥    â†’ è®¢å•è¡¨ã€è®¢å•æ˜ç»†ã€æœˆåº¦é”€å”®æ±‡æ€»ã€ğŸ“Šæœˆåº¦é”€å”®æ±‡æ€»ã€orders
å®¢æˆ·/ç”¨æˆ·         â†’ ç”¨æˆ·è¡¨ã€å®¢æˆ·è¡¨ã€å®¢æˆ·æ¶ˆè´¹æ’è¡Œã€usersã€customers
äº§å“/å•†å“         â†’ äº§å“è¡¨ã€å•†å“è¡¨ã€products
è®¢å•             â†’ è®¢å•è¡¨ã€è®¢å•æ˜ç»†ã€orders
åº“å­˜             â†’ åº“å­˜è¡¨ã€å•†å“è¡¨ã€inventory
```

**æ­£ç¡®ç¤ºä¾‹**ï¼š
```
âŒ é”™è¯¯ï¼šè¡¨ä¸å­˜åœ¨å°±ç›´æ¥æ”¾å¼ƒ
ç”¨æˆ·ï¼šæŸ¥è¯¢2023å¹´é”€å”®è¶‹åŠ¿
AIï¼šå¾ˆæŠ±æ­‰ï¼Œsalesè¡¨ä¸å­˜åœ¨...

âœ… æ­£ç¡®ï¼šæŸ¥æ‰¾ç›¸å…³è¡¨å¹¶ä½¿ç”¨
ç”¨æˆ·ï¼šæŸ¥è¯¢2023å¹´é”€å”®è¶‹åŠ¿
AIï¼š
1. è°ƒç”¨ list_tables() â†’ è¿”å› ["äº§å“è¡¨", "è®¢å•è¡¨", "è®¢å•æ˜ç»†", "ğŸ“Šæœˆåº¦é”€å”®æ±‡æ€»", ...]
2. è¯†åˆ«ç›¸å…³è¡¨ï¼šè®¢å•è¡¨ã€ğŸ“Šæœˆåº¦é”€å”®æ±‡æ€»
3. æ‰§è¡ŒæŸ¥è¯¢ï¼šSELECT * FROM è®¢å•è¡¨ WHERE YEAR(è®¢å•æ—¥æœŸ) = 2023
```

---

## ğŸ“Š å›¾è¡¨ç”Ÿæˆå†³ç­–è§„åˆ™ï¼ˆğŸ”´ å¼ºåˆ¶æ‰§è¡Œï¼‰

**âš ï¸ æ‰§è¡ŒæŸ¥è¯¢åï¼Œå¿…é¡»æ ¹æ®æ•°æ®ç‰¹å¾å’Œç”¨æˆ·é—®é¢˜ç±»å‹åˆ¤æ–­æ˜¯å¦ç”Ÿæˆå›¾è¡¨ï¼**

### å¿…é¡»ç”Ÿæˆå›¾è¡¨çš„åœºæ™¯

| ç”¨æˆ·é—®é¢˜ç±»å‹ | æ•°æ®ç‰¹å¾ | å¿…é¡»è°ƒç”¨çš„å›¾è¡¨å·¥å…· |
|-------------|----------|-------------------|
| è¶‹åŠ¿/å˜åŒ–/å¢é•¿ | å«æ—¶é—´/æ—¥æœŸå­—æ®µ | `generate_line_chart` |
| å¯¹æ¯”/æ’å/Top N | å«åˆ†ç±»å­—æ®µ + æ•°å€¼å­—æ®µ | `generate_bar_chart` |
| å æ¯”/åˆ†å¸ƒ | å«åˆ†ç»„ + è®¡æ•°/ç™¾åˆ†æ¯” | `generate_pie_chart` |
| é”€å”®è¶‹åŠ¿/è®¢å•è¶‹åŠ¿ | æ—¶é—´ + æ•°å€¼ | `generate_line_chart` |
| XXçš„æ’å/XXæ’è¡Œ | åˆ†ç»„ + æ•°å€¼æ’åº | `generate_bar_chart` |
| æ¯æœˆ/æ¯å¹´/æ¯æ—¥ | æ—¶é—´åºåˆ— | `generate_line_chart` |

### åˆ¤æ–­æµç¨‹
```
æŸ¥è¯¢è¿”å›æ•°æ® â†’ åˆ†ææ•°æ®ç‰¹å¾ â†’ åŒ¹é…ä¸Šè¡¨åœºæ™¯ â†’ è°ƒç”¨å¯¹åº”å›¾è¡¨å·¥å…· â†’ ç”Ÿæˆæ–‡å­—åˆ†æ
```

### ç¤ºä¾‹
```
âŒ é”™è¯¯ï¼šåªè¾“å‡ºæ–‡å­—ï¼Œä¸ç”Ÿæˆå›¾è¡¨
ç”¨æˆ·ï¼šæŸ¥è¯¢2023å¹´é”€å”®è¶‹åŠ¿
AIï¼š2023å¹´é”€å”®é¢ä¸ºXXX...ï¼ˆæ²¡æœ‰ä»»ä½•å›¾è¡¨ï¼‰

âœ… æ­£ç¡®ï¼šå…ˆè°ƒç”¨å›¾è¡¨å·¥å…·ï¼Œå†åˆ†æ
ç”¨æˆ·ï¼šæŸ¥è¯¢2023å¹´é”€å”®è¶‹åŠ¿
AIï¼š
1. è°ƒç”¨ query() è·å–æ•°æ®
2. è°ƒç”¨ generate_line_chart() ç”Ÿæˆè¶‹åŠ¿å›¾
3. è¾“å‡ºæ–‡å­—åˆ†æï¼šğŸ“Š 2023å¹´é”€å”®è¶‹åŠ¿åˆ†æ...
```

### å›¾è¡¨æ•°æ®æ ¼å¼
```json
// æŠ˜çº¿å›¾/æŸ±çŠ¶å›¾
[{"time": "2023-01", "value": 1000}, {"time": "2023-02", "value": 1200}]
// æˆ– [{"category": "äº§å“A", "value": 100}, {"category": "äº§å“B", "value": 200}]

// é¥¼å›¾
[{"category": "åŒ—äº¬", "value": 30}, {"category": "ä¸Šæµ·", "value": 50}]
```

---

## ğŸ’¡ æ•°æ®åˆ†æè¾“å‡ºè¦æ±‚ï¼ˆğŸ”´ å¼ºåˆ¶æ‰§è¡Œï¼Œä¸å¯è·³è¿‡ï¼‰

âš ï¸ **æ¯æ¬¡æŸ¥è¯¢åï¼Œä½ å¿…é¡»ç”Ÿæˆè¯¦ç»†çš„æ•°æ®åˆ†ææ–‡æœ¬ï¼è¿™ä¸æ˜¯å¯é€‰é¡¹ï¼Œæ˜¯å¿…é€‰é¡¹ï¼**

åˆ†æå†…å®¹å¿…é¡»åŒ…å«ä»¥ä¸‹å››ä¸ªéƒ¨åˆ†ï¼š

### 1. æ•°æ®æ¦‚è¦ï¼ˆå¿…å¡«ï¼‰
- æŸ¥è¯¢è¿”å›äº†å¤šå°‘æ¡è®°å½•
- æ¶‰åŠçš„æ—¶é—´èŒƒå›´ï¼ˆå¦‚æœ‰ï¼‰
- ä¸»è¦çš„æ•°æ®ç»´åº¦

### 2. å…³é”®å‘ç°ï¼ˆå¿…å¡«ï¼‰
- æ•°æ®ä¸­çš„é‡è¦è¶‹åŠ¿ï¼ˆä¸Šå‡/ä¸‹é™/æ³¢åŠ¨ï¼‰
- å¼‚å¸¸å€¼è¯†åˆ«ï¼ˆæœ€é«˜/æœ€ä½/å¼‚å¸¸ç‚¹ï¼‰
- æ•°æ®åˆ†å¸ƒç‰¹å¾

### 3. æ•°å€¼è§£è¯»ï¼ˆå¿…å¡«ï¼‰
- å…·ä½“æ•°å­—çš„å«ä¹‰ï¼ˆå¦‚"é”€å”®é¢å¢é•¿äº†20%"ï¼‰
- å…³é”®æŒ‡æ ‡çš„è®¡ç®—ç»“æœ
- æ•°æ®ä¹‹é—´çš„å…³è”å…³ç³»

### 4. ä¸šåŠ¡æ´å¯Ÿï¼ˆå¿…å¡«ï¼‰
- æ•°æ®å¯¹ä¸šåŠ¡çš„å¯ç¤º
- å»ºè®®çš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨
- æ½œåœ¨çš„é£é™©æˆ–æœºä¼š

**âŒ ç¦æ­¢è¡Œä¸º**ï¼š
- åªè¾“å‡ºSQLæˆ–å›¾è¡¨ï¼Œä¸ç”Ÿæˆæ–‡å­—åˆ†æ
- åªè¯´"æŸ¥è¯¢å®Œæˆ"ã€"å·²ç”Ÿæˆå›¾è¡¨"ç­‰æ— æ„ä¹‰å›å¤
- è·³è¿‡ä¸Šè¿°ä»»ä½•ä¸€ä¸ªåˆ†æéƒ¨åˆ†

**âœ… æ­£ç¡®ç¤ºä¾‹**ï¼š
```
ğŸ“Š [æ•°æ®åˆ†æç»“æœ]

æ ¹æ®æŸ¥è¯¢ç»“æœï¼Œå…±æ‰¾åˆ° 15 æ¡è®¢å•è®°å½•ï¼š

ğŸ” **å…³é”®å‘ç°**ï¼š
â€¢ å°ç±³å“ç‰Œçš„æ€»é”€å”®é¢ä¸º Â¥125,000ï¼Œå æ€»é”€å”®é¢çš„ 32%
â€¢ å¹³å‡è®¢å•é‡‘é¢ä¸º Â¥8,333ï¼Œæœ€é«˜å•ç¬”è®¢å•ä¸º Â¥15,000ï¼ˆ2024-05-15ï¼‰
â€¢ é”€å”®é¢å‘ˆç°ä¸Šå‡è¶‹åŠ¿ï¼Œ5æœˆä»½æ¯”4æœˆä»½å¢é•¿äº† 25%

ğŸ’¡ **ä¸šåŠ¡æ´å¯Ÿ**ï¼š
å°ç±³å“ç‰Œè¡¨ç°è‰¯å¥½ï¼Œé”€å”®é¢å æ¯”è¶…è¿‡ä¸‰æˆï¼Œæ˜¯æ ¸å¿ƒå“ç‰Œä¹‹ä¸€ã€‚å»ºè®®ç»§ç»­å…³æ³¨è¯¥å“ç‰Œçš„åº“å­˜å’Œä¿ƒé”€æ´»åŠ¨ï¼ŒåŒæ—¶åˆ†æå¢é•¿é©±åŠ¨å› ç´ ä»¥å¤åˆ¶æˆåŠŸç»éªŒã€‚
```
"""

def get_system_prompt(db_type: str = "postgresql") -> str:
    """
    æ ¹æ®æ•°æ®åº“ç±»å‹è·å–ç³»ç»Ÿæç¤ºè¯ï¼Œå¹¶æ³¨å…¥åŠ¨æ€æ—¶é—´ä¸Šä¸‹æ–‡

    Args:
        db_type: æ•°æ®åº“ç±»å‹ï¼ˆpostgresql, mysql, sqlite, xlsx, csvç­‰ï¼‰

    Returns:
        str: ç³»ç»Ÿæç¤ºè¯ï¼ˆåŒ…å«å½“å‰æ—¶é—´ä¿¡æ¯ï¼‰
    """
    print(f"ğŸ” [get_system_prompt] è°ƒç”¨å‚æ•° db_type='{db_type}'")

    # ğŸ•’ åŠ¨æ€æ—¶é—´ä¸Šä¸‹æ–‡ï¼ˆå¯¹äº"æ˜¨å¤©"ã€"ä¸Šæœˆ"ç­‰æ—¶é—´æŸ¥è¯¢è‡³å…³é‡è¦ï¼‰
    current_time = datetime.now()
    time_context = f"""

## ğŸ•’ å½“å‰æ—¶é—´ä¸Šä¸‹æ–‡
- **å½“å‰æ—¶é—´**: {current_time.strftime("%Y-%m-%d %H:%M:%S")}
- **å½“å‰å¹´ä»½**: {current_time.year}
- **å½“å‰æœˆä»½**: {current_time.month}æœˆ
- **å½“å‰æ—¥æœŸ**: {current_time.day}æ—¥
- **æ˜ŸæœŸ**: æ˜ŸæœŸ{['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥'][current_time.weekday()]}

åœ¨å¤„ç†æ—¶é—´ç›¸å…³æŸ¥è¯¢æ—¶ï¼ˆå¦‚"æ˜¨å¤©"ã€"ä¸Šå‘¨"ã€"ä¸Šä¸ªæœˆ"ã€"ä»Šå¹´"ç­‰ï¼‰ï¼Œè¯·ä»¥æ­¤æ—¶é—´ä¸ºå‡†è¿›è¡Œè®¡ç®—ã€‚
"""

    # ğŸ”¥ğŸ”¥ğŸ”¥ ã€å…³é”®ã€‘æ•°æ®åˆ†æè¾“å‡ºå¼ºåˆ¶è¦æ±‚ï¼ˆç¡®ä¿ answer å­—æ®µå§‹ç»ˆæœ‰å†…å®¹ï¼‰
    data_analysis_output_requirement = """

## ğŸ”´ğŸ”´ğŸ”´ ã€å¼ºåˆ¶è¦æ±‚ã€‘å¿…é¡»ç”Ÿæˆæ•°æ®åˆ†ææ–‡æœ¬ï¼

**âš ï¸ è°ƒç”¨å·¥å…·åï¼Œå¿…é¡»ç”¨æ–‡å­—æ€»ç»“æŸ¥è¯¢ç»“æœï¼**

æ¯æ¬¡æŸ¥è¯¢åï¼Œä½ å¿…é¡»åœ¨æ–‡æœ¬å›å¤ä¸­åŒ…å«ï¼š
1. **æ•°æ®æ¦‚è¦**ï¼šæŸ¥è¯¢è¿”å›äº†å¤šå°‘æ¡è®°å½•
2. **å…³é”®å‘ç°**ï¼šæ•°æ®ä¸­çš„é‡è¦è¶‹åŠ¿æˆ–å¼‚å¸¸å€¼
3. **æ•°å€¼è§£è¯»**ï¼šå…·ä½“æ•°å­—çš„å«ä¹‰ï¼ˆå¦‚"é”€å”®é¢å¢é•¿äº†20%"ï¼‰
4. **ä¸šåŠ¡æ´å¯Ÿ**ï¼šæ•°æ®å¯¹ä¸šåŠ¡çš„å¯ç¤º

**æ­£ç¡®æ ¼å¼ç¤ºä¾‹**ï¼š
```
ğŸ“Š [æ•°æ®åˆ†æç»“æœ]

æ ¹æ®æŸ¥è¯¢ç»“æœï¼Œå…±æ‰¾åˆ° 15 æ¡è®¢å•è®°å½•ï¼š

ğŸ” **å…³é”®å‘ç°**ï¼š
â€¢ å°ç±³å“ç‰Œçš„æ€»é”€å”®é¢ä¸º Â¥125,000ï¼Œå æ€»é”€å”®é¢çš„ 32%
â€¢ å¹³å‡è®¢å•é‡‘é¢ä¸º Â¥8,333
â€¢ æœ€é«˜å•ç¬”è®¢å•ä¸º Â¥15,000ï¼ˆ2024-05-15ï¼‰

ğŸ’¡ **ä¸šåŠ¡æ´å¯Ÿ**ï¼š
å°ç±³å“ç‰Œè¡¨ç°è‰¯å¥½ï¼Œé”€å”®é¢å æ¯”è¶…è¿‡ä¸‰æˆï¼Œæ˜¯æ ¸å¿ƒå“ç‰Œä¹‹ä¸€ã€‚å»ºè®®ç»§ç»­å…³æ³¨è¯¥å“ç‰Œçš„åº“å­˜å’Œä¿ƒé”€æ´»åŠ¨ã€‚
```

**âŒ ç¦æ­¢åšæ³•**ï¼š
- åªè°ƒç”¨å·¥å…·ï¼Œä¸ç”Ÿæˆæ–‡æœ¬æ€»ç»“
- åªè¾“å‡º"æŸ¥è¯¢å®Œæˆ"ã€"å·²ç”Ÿæˆå›¾è¡¨"ç­‰æ— æ„ä¹‰å›å¤
- åªå±•ç¤ºSQLè¯­å¥è€Œä¸è§£é‡Šç»“æœ

**âœ… æ­£ç¡®åšæ³•**ï¼š
- è°ƒç”¨ query å·¥å…·è·å–æ•°æ®
- è°ƒç”¨å›¾è¡¨å·¥å…·ç”Ÿæˆå¯è§†åŒ–ï¼ˆå¦‚éœ€è¦ï¼‰
- **ç”¨æ–‡å­—è¯¦ç»†åˆ†ææ•°æ®ç»“æœ**
"""

    try:
        from prompt_generator import generate_database_aware_system_prompt
        result = generate_database_aware_system_prompt(db_type, BASE_SYSTEM_PROMPT)

        # ğŸ”§ æ£€æµ‹æ˜¯å¦ä¸ºæµ‹è¯•æ•°æ®åº“ï¼Œæ³¨å…¥æ­£ç¡®çš„è¡¨ç»“æ„ä¿¡æ¯
        if 'ecommerce_test_db' in config.database_url:
            test_db_schema = """

## ğŸ§ª æµ‹è¯•æ•°æ®åº“è¡¨ç»“æ„ï¼ˆé‡è¦ï¼ä½¿ç”¨ä»¥ä¸‹è¡¨åå’Œå­—æ®µï¼‰

**æ ¸å¿ƒä¸šåŠ¡è¡¨**ï¼š
1. **users** - ç”¨æˆ·è¡¨ï¼ˆä¸æ˜¯customersï¼ï¼‰
   - id: ç”¨æˆ·ID
   - username: ç”¨æˆ·å
   - vip_level: VIPç­‰çº§ï¼ˆ0=æ™®é€š, 1=é“¶å¡, 2=é‡‘å¡, 3=é’»çŸ³ï¼‰
   - total_spent: ç´¯è®¡æ¶ˆè´¹é‡‘é¢
   - gender: æ€§åˆ«
   - registration_date: æ³¨å†Œæ—¶é—´

2. **orders** - è®¢å•è¡¨
   - id: è®¢å•ID
   - user_id: ç”¨æˆ·IDï¼ˆå…³è”users.idï¼Œä¸æ˜¯customer_idï¼ï¼‰
   - total_amount: è®¢å•æ€»é‡‘é¢
   - final_amount: å®ä»˜é‡‘é¢
   - status: è®¢å•çŠ¶æ€ï¼ˆpending/completed/cancelledï¼‰
   - order_date: è®¢å•æ—¥æœŸï¼ˆdateç±»å‹ï¼‰
   - created_at: åˆ›å»ºæ—¶é—´

3. **products** - å•†å“è¡¨
   - id: å•†å“ID
   - name: å•†å“åç§°
   - category_id: ç±»åˆ«IDï¼ˆå…³è”categories.idï¼‰
   - brand: å“ç‰Œ
   - price: ä»·æ ¼
   - sales_count: é”€é‡
   - rating: å¹³å‡è¯„åˆ†
   - review_count: è¯„ä»·æ•°

4. **reviews** - è¯„ä»·è¡¨
   - id: è¯„ä»·ID
   - product_id: å•†å“ID
   - user_id: ç”¨æˆ·IDï¼ˆå…³è”users.idï¼‰
   - rating: è¯„åˆ†ï¼ˆ1-5ï¼‰
   - content: è¯„ä»·å†…å®¹
   - created_at: åˆ›å»ºæ—¶é—´

5. **categories** - å•†å“ç±»åˆ«è¡¨
   - id: ç±»åˆ«ID
   - name: ç±»åˆ«åç§°
   - parent_id: çˆ¶ç±»åˆ«ID

6. **order_items** - è®¢å•æ˜ç»†è¡¨
   - order_id: è®¢å•ID
   - product_id: å•†å“ID
   - quantity: æ•°é‡
   - price: å•ä»·
   - subtotal: å°è®¡

7. **addresses** - åœ°å€è¡¨
   - user_id: ç”¨æˆ·IDï¼ˆå…³è”users.idï¼‰
   - city: åŸå¸‚
   - province: çœä»½

## âš ï¸âš ï¸âš ï¸ é‡è¦ï¼šæŸ¥è¯¢ç”¨æˆ·å’Œè®¢å•å…³è”æ—¶ä½¿ç”¨ user_id
- âŒ é”™è¯¯ï¼šcustomer_id, cid
- âœ… æ­£ç¡®ï¼šuser_id, u.user_id
- å…³è”æ–¹å¼ï¼šFROM orders o JOIN users u ON o.user_id = u.id

## ğŸ“‹ ç”¨æˆ·å¤è´­åˆ†æä¸“ç”¨SQLæ¨¡æ¿
```sql
-- ç»Ÿè®¡æ¯ä¸ªç”¨æˆ·çš„ä¸‹å•æ¬¡æ•°
SELECT user_id, COUNT(*) as order_count
FROM orders
GROUP BY user_id
ORDER BY order_count DESC;

-- åˆ†æå¤è´­ç”¨æˆ·å æ¯”
SELECT
    CASE WHEN order_count >= 2 THEN 'å¤è´­ç”¨æˆ·' ELSE 'å•æ¬¡è´­ä¹°ç”¨æˆ·' END as user_type,
    COUNT(*) as user_count,
    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as percentage
FROM (SELECT user_id, COUNT(*) as order_count FROM orders GROUP BY user_id) sub
GROUP BY user_type;

-- ç”¨æˆ·è®¢å•æ•°é‡åˆ†å¸ƒï¼ˆç›´æ–¹å›¾ï¼‰
SELECT order_count, COUNT(*) as user_count
FROM (SELECT user_id, COUNT(*) as order_count FROM orders GROUP BY user_id) sub
GROUP BY order_count
ORDER BY order_count;
```
   - user_id: ç”¨æˆ·ID
   - city: åŸå¸‚
   - province: çœä»½
"""
            result = result + test_db_schema

        # åœ¨æç¤ºè¯æœ«å°¾è¿½åŠ æ•°æ®åˆ†æè¾“å‡ºè¦æ±‚å’Œæ—¶é—´ä¸Šä¸‹æ–‡
        result = result + data_analysis_output_requirement + time_context
        print(f"ğŸ” [get_system_prompt] æˆåŠŸç”Ÿæˆæç¤ºè¯ï¼Œé•¿åº¦={len(result)}")
        # æ‰“å°æç¤ºè¯çš„å‰200å­—ç¬¦ï¼ŒéªŒè¯æ˜¯å¦åŒ…å«æ•°æ®åº“ç‰¹å®šä¿¡æ¯
        preview = result[:200].replace('\n', ' ')
        print(f"ğŸ” [get_system_prompt] æç¤ºè¯é¢„è§ˆ: {preview}...")
        return result
    except ImportError as e:
        print(f"âš ï¸ æ— æ³•å¯¼å…¥ prompt_generator: {e}ï¼Œä½¿ç”¨é»˜è®¤PostgreSQLæç¤ºè¯")
        return BASE_SYSTEM_PROMPT + data_analysis_output_requirement + time_context
    except Exception as e:
        print(f"âš ï¸ ç”ŸæˆåŠ¨æ€æç¤ºè¯å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤PostgreSQLæç¤ºè¯")
        return BASE_SYSTEM_PROMPT + data_analysis_output_requirement + time_context


# é»˜è®¤æç¤ºè¯ï¼ˆå‘åå…¼å®¹ï¼‰
SYSTEM_PROMPT = BASE_SYSTEM_PROMPT


def create_llm():
    """Create DeepSeek LLM instance using OpenAI-compatible API"""
    return ChatOpenAI(
        model=config.deepseek_model,
        api_key=config.deepseek_api_key,
        base_url=config.deepseek_base_url,
        temperature=0,
    )


def parse_chart_config(content: str) -> Optional[Dict[str, Any]]:
    """ä»LLMå›å¤ä¸­è§£æJSONå›¾è¡¨é…ç½®ï¼ˆå¢å¼ºç‰ˆï¼Œæ”¯æŒå¤šç§æ ¼å¼å’Œå®¹é”™ï¼‰

    Args:
        content: LLMçš„æ–‡æœ¬å›å¤

    Returns:
        è§£æå‡ºçš„JSONé…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None

    æ”¯æŒçš„æ ¼å¼:
        1. ```json ... ``` ä»£ç å—
        2. ```JSON ... ``` ä»£ç å—ï¼ˆå¤§å†™ï¼‰
        3. ç›´æ¥çš„ JSON å¯¹è±¡ {...}
        4. å¸¦æœ‰ JavaScript æ³¨é‡Šçš„ JSONï¼ˆä¼šå°è¯•æ¸…ç†ï¼‰
    """
    if not content or not content.strip():
        return None

    # ç­–ç•¥1: å°è¯•åŒ¹é… ```json ... ``` ä»£ç å—ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    json_pattern = r'```(?:json|JSON)\s*([\s\S]*?)\s*```'
    match = re.search(json_pattern, content)

    if match:
        json_str = match.group(1).strip()
        result = _try_parse_json(json_str)
        if result is not None:
            return result

    # ç­–ç•¥2: å°è¯•åŒ¹é…ä»»æ„ä»£ç å—ä¸­çš„ JSON
    code_block_pattern = r'```\s*([\s\S]*?)\s*```'
    for match in re.finditer(code_block_pattern, content):
        json_str = match.group(1).strip()
        # æ£€æŸ¥æ˜¯å¦åƒ JSONï¼ˆä»¥ { æˆ– [ å¼€å¤´ï¼‰
        if json_str.startswith('{') or json_str.startswith('['):
            result = _try_parse_json(json_str)
            if result is not None:
                return result

    # ç­–ç•¥3: å°è¯•ç›´æ¥åŒ¹é… JSON å¯¹è±¡ {...}
    # ä½¿ç”¨è´ªå©ªä½†å¹³è¡¡çš„åŒ¹é…ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰
    direct_json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
    for match in re.finditer(direct_json_pattern, content):
        json_str = match.group(0)
        result = _try_parse_json(json_str)
        if result is not None:
            # éªŒè¯æ˜¯å¦æ˜¯å›¾è¡¨é…ç½®ï¼ˆè‡³å°‘åŒ…å«ä¸€äº›é¢„æœŸå­—æ®µï¼‰
            if any(key in result for key in ['chart_type', 'data', 'title', 'type']):
                return result

    return None


def _try_parse_json(json_str: str) -> Optional[Dict[str, Any]]:
    """å°è¯•è§£æ JSON å­—ç¬¦ä¸²ï¼Œæ”¯æŒå®¹é”™å¤„ç†

    Args:
        json_str: JSON å­—ç¬¦ä¸²

    Returns:
        è§£æåçš„å­—å…¸ï¼Œå¤±è´¥è¿”å› None
    """
    if not json_str:
        return None

    # å°è¯•1: ç›´æ¥è§£æ
    try:
        return json.loads(json_str)
    except json.JSONDecodeError:
        pass

    # å°è¯•2: æ¸…ç†å¸¸è§çš„ LLM é”™è¯¯åå†è§£æ
    cleaned = json_str

    # ç§»é™¤ JavaScript é£æ ¼çš„å•è¡Œæ³¨é‡Š
    cleaned = re.sub(r'//.*$', '', cleaned, flags=re.MULTILINE)

    # ç§»é™¤ JavaScript é£æ ¼çš„å¤šè¡Œæ³¨é‡Š
    cleaned = re.sub(r'/\*[\s\S]*?\*/', '', cleaned)

    # ç§»é™¤å°¾éšé€—å·ï¼ˆJSON ä¸å…è®¸ï¼Œä½† JS å…è®¸ï¼‰
    cleaned = re.sub(r',\s*}', '}', cleaned)
    cleaned = re.sub(r',\s*]', ']', cleaned)

    # å°† Python çš„ None/True/False è½¬æ¢ä¸º JSON çš„ null/true/false
    cleaned = re.sub(r'\bNone\b', 'null', cleaned)
    cleaned = re.sub(r'\bTrue\b', 'true', cleaned)
    cleaned = re.sub(r'\bFalse\b', 'false', cleaned)

    # å°†å•å¼•å·è½¬æ¢ä¸ºåŒå¼•å·ï¼ˆJSON è¦æ±‚åŒå¼•å·ï¼‰
    # æ³¨æ„ï¼šè¿™ä¸ªæ›¿æ¢æ¯”è¾ƒå±é™©ï¼Œåªåœ¨å…¶ä»–æ–¹æ³•éƒ½å¤±è´¥æ—¶ä½¿ç”¨
    try:
        return json.loads(cleaned)
    except json.JSONDecodeError:
        pass

    # å°è¯•3: å•å¼•å·è½¬åŒå¼•å·ï¼ˆæœ€åæ‰‹æ®µï¼‰
    try:
        # ç®€å•çš„å•å¼•å·åˆ°åŒå¼•å·è½¬æ¢ï¼ˆä¸å¤„ç†åµŒå¥—å¼•å·ï¼‰
        cleaned_quotes = cleaned.replace("'", '"')
        return json.loads(cleaned_quotes)
    except json.JSONDecodeError:
        pass

    return None


def extract_tool_data(messages: list) -> tuple[Optional[str], list]:
    """ä»æ¶ˆæ¯å†å²ä¸­æå–å·¥å…·è°ƒç”¨çš„SQLå’Œè¿”å›æ•°æ®

    Args:
        messages: æ¶ˆæ¯å†å²åˆ—è¡¨

    Returns:
        (sqlè¯­å¥, åŸå§‹æ•°æ®åˆ—è¡¨)
    """
    sql = None
    raw_data = []

    for msg in messages:
        # æå–SQLï¼ˆä»AIMessageçš„tool_callsä¸­ï¼‰
        if isinstance(msg, AIMessage) and msg.tool_calls:
            for tc in msg.tool_calls:
                if tc.get('name') == 'query':
                    sql = tc.get('args', {}).get('sql')

        # æå–æ•°æ®ï¼ˆä»ToolMessageä¸­ï¼‰
        if isinstance(msg, ToolMessage):
            try:
                data = json.loads(msg.content) if isinstance(msg.content, str) else msg.content
                if isinstance(data, list):
                    raw_data = data
            except (json.JSONDecodeError, TypeError):
                pass

    return sql, raw_data


def extract_chart_tool_call(messages: list) -> Optional[Dict[str, Any]]:
    """ä»æ¶ˆæ¯å†å²ä¸­æå–å›¾è¡¨å·¥å…·è°ƒç”¨ä¿¡æ¯

    Args:
        messages: æ¶ˆæ¯å†å²åˆ—è¡¨

    Returns:
        åŒ…å«å·¥å…·åå’Œå‚æ•°çš„å­—å…¸ï¼Œå¦‚æœæ²¡æœ‰å›¾è¡¨å·¥å…·è°ƒç”¨åˆ™è¿”å› None
    """
    chart_tools = [
        "generate_bar_chart", "generate_line_chart", "generate_pie_chart",
        "generate_scatter_chart", "generate_radar_chart", "generate_funnel_chart",
        "generate_echarts"
    ]

    for msg in messages:
        if isinstance(msg, AIMessage) and msg.tool_calls:
            for tc in msg.tool_calls:
                tool_name = tc.get('name', '')
                if tool_name in chart_tools:
                    return {
                        "tool_name": tool_name,
                        "args": tc.get('args', {})
                    }
    return None


async def call_mcp_chart_tool(tool_name: str, args: Dict[str, Any], output_dir: str = "./charts") -> Optional[str]:
    """ä½¿ç”¨åŸå§‹ MCP å®¢æˆ·ç«¯è°ƒç”¨å›¾è¡¨å·¥å…·ï¼ˆç»•è¿‡ LangChain é€‚é…å™¨çš„é™åˆ¶ï¼‰

    Args:
        tool_name: å·¥å…·åç§°
        args: å·¥å…·å‚æ•°
        output_dir: è¾“å‡ºç›®å½•

    Returns:
        ä¿å­˜çš„å›¾ç‰‡è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
    """
    from mcp import ClientSession
    from mcp.client.sse import sse_client

    url = "http://localhost:3033/sse"

    try:
        async with sse_client(url) as streams:
            async with ClientSession(*streams) as session:
                await session.initialize()

                result = await session.call_tool(tool_name, args)

                if hasattr(result, 'content') and result.content:
                    for item in result.content:
                        if hasattr(item, 'type') and item.type == 'image':
                            if hasattr(item, 'data') and item.data:
                                # ä¿å­˜ Base64 å›¾ç‰‡
                                return _save_base64_image(item.data, output_dir, "png")
                        elif hasattr(item, 'text') and item.text:
                            # å¯èƒ½æ˜¯ URL æˆ–å…¶ä»–æ–‡æœ¬
                            text = item.text
                            if text.startswith("http"):
                                return text

                return None

    except Exception as e:
        print(f"[MCP] Chart tool call failed: {e}")
        return None


def _save_base64_image(base64_data: str, output_dir: str, ext: str = "png") -> str:
    """ä¿å­˜ Base64 ç¼–ç çš„å›¾ç‰‡åˆ°æ–‡ä»¶

    Args:
        base64_data: Base64 ç¼–ç çš„å›¾ç‰‡æ•°æ®
        output_dir: è¾“å‡ºç›®å½•
        ext: æ–‡ä»¶æ‰©å±•å

    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    os.makedirs(output_dir, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"mcp_chart_{timestamp}.{ext}"
    filepath = os.path.join(output_dir, filename)

    # è§£ç å¹¶ä¿å­˜
    image_data = base64.b64decode(base64_data)
    with open(filepath, "wb") as f:
        f.write(image_data)

    print(f"ğŸ“Š å›¾è¡¨å·²ä¿å­˜: {filepath}")
    return filepath


async def _generate_default_answer(query_result: QueryResult, sql: str, chart_config: ChartConfig) -> str:
    """
    ç”Ÿæˆé»˜è®¤çš„æ•°æ®åˆ†ææ–‡æœ¬ï¼ˆå½“ LLM æ²¡æœ‰ç”Ÿæˆåˆ†ææ—¶ä½¿ç”¨ï¼‰

    Args:
        query_result: æŸ¥è¯¢ç»“æœ
        sql: SQL è¯­å¥
        chart_config: å›¾è¡¨é…ç½®

    Returns:
        str: é»˜è®¤åˆ†ææ–‡æœ¬
    """
    if query_result.row_count == 0:
        return "ğŸ“Š [æŸ¥è¯¢ç»“æœ]\n\næœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®è®°å½•ã€‚"

    rows = query_result.rows
    columns = query_result.columns
    row_count = query_result.row_count

    # æ„å»ºåˆ†ææ–‡æœ¬
    answer_parts = [
        "ğŸ“Š [æ•°æ®åˆ†æç»“æœ]",
        f"\næ ¹æ®æŸ¥è¯¢ç»“æœï¼Œå…±æ‰¾åˆ° {row_count} æ¡è®°å½•ï¼š\n"
    ]

    # æ·»åŠ å‰å‡ æ¡æ•°æ®é¢„è§ˆ
    preview_count = min(5, row_count)
    answer_parts.append("ğŸ” **æ•°æ®é¢„è§ˆ**ï¼ˆå‰{}æ¡ï¼‰ï¼š".format(preview_count))

    for i in range(preview_count):
        row_data = []
        for j, col in enumerate(columns):
            if j < len(rows[i]):
                row_data.append(f"{col}: {rows[i][j]}")
        answer_parts.append(f"â€¢ {', '.join(row_data)}")

    if row_count > 5:
        answer_parts.append(f"\n... è¿˜æœ‰ {row_count - 5} æ¡è®°å½•")

    # å°è¯•è¿›è¡Œæ•°å€¼åˆ†æ
    numeric_analysis = _analyze_numeric_data(rows, columns)
    if numeric_analysis:
        answer_parts.append("\nğŸ” **æ•°å€¼ç»Ÿè®¡**ï¼š")
        answer_parts.append(numeric_analysis)

    # æ·»åŠ å›¾è¡¨è¯´æ˜
    if chart_config and chart_config.title:
        chart_type = chart_config.chart_type.value if hasattr(chart_config.chart_type, 'value') else str(chart_config.chart_type)
        answer_parts.append(f"\nğŸ“Š å·²ç”Ÿæˆ {chart_type} å›¾è¡¨ï¼š{chart_config.title}")

    return "\n".join(answer_parts)


def _analyze_numeric_data(rows: list, columns: list) -> str:
    """
    åˆ†ææ•°å€¼æ•°æ®ï¼Œç”Ÿæˆç»Ÿè®¡æ‘˜è¦

    Args:
        rows: æ•°æ®è¡Œ
        columns: åˆ—å

    Returns:
        str: æ•°å€¼åˆ†ææ‘˜è¦
    """
    if not rows or not columns:
        return ""

    analysis_parts = []

    # å¯»æ‰¾æ•°å€¼åˆ—
    for col_idx, col_name in enumerate(columns):
        if col_idx >= len(rows[0]):
            continue

        # æ£€æŸ¥è¯¥åˆ—æ˜¯å¦ä¸ºæ•°å€¼ç±»å‹
        is_numeric = True
        numeric_values = []

        for row in rows:
            if col_idx < len(row):
                val = row[col_idx]
                if isinstance(val, (int, float)):
                    numeric_values.append(float(val))
                elif isinstance(val, str) and val.replace('.', '').replace('-', '').replace('+', '').isdigit():
                    try:
                        numeric_values.append(float(val))
                    except ValueError:
                        is_numeric = False
                        break
                else:
                    is_numeric = False
                    break

        if is_numeric and numeric_values:
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            count = len(numeric_values)
            total = sum(numeric_values)
            avg = total / count if count > 0 else 0
            max_val = max(numeric_values)
            min_val = min(numeric_values)

            analysis_parts.append(
                f"â€¢ {col_name}: æ€»è®¡={total:.2f}, å¹³å‡={avg:.2f}, æœ€å¤§={max_val}, æœ€å°={min_val}"
            )

    return "\n".join(analysis_parts) if analysis_parts else ""


async def build_visualization_response(
    messages: list,
    final_content: str,
    auto_generate_chart: bool = True
) -> VisualizationResponse:
    """æ„å»ºå®Œæ•´çš„å¯è§†åŒ–å“åº”ï¼Œå¹¶å¯é€‰ç”Ÿæˆå›¾è¡¨

    Args:
        messages: å®Œæ•´çš„æ¶ˆæ¯å†å²
        final_content: æœ€ç»ˆçš„AIå›å¤å†…å®¹
        auto_generate_chart: æ˜¯å¦è‡ªåŠ¨ç”Ÿæˆå›¾è¡¨æ–‡ä»¶

    Returns:
        VisualizationResponseå¯¹è±¡
    """
    # æå–SQLå’ŒåŸå§‹æ•°æ®
    sql, raw_data = extract_tool_data(messages)

    # ğŸ†• æ£€æŸ¥æ˜¯å¦æœ‰ mcp-echarts å›¾è¡¨å·¥å…·è°ƒç”¨
    chart_tool_call = extract_chart_tool_call(messages)
    mcp_chart_path = None

    # å¦‚æœ LLM è°ƒç”¨äº†å›¾è¡¨å·¥å…·ï¼Œä½¿ç”¨åŸå§‹ MCP å®¢æˆ·ç«¯é‡æ–°è·å–å›¾ç‰‡
    if chart_tool_call and ENABLE_ECHARTS_MCP:
        print(f"[MCP] Detected chart tool call: {chart_tool_call['tool_name']}")
        try:
            mcp_chart_path = await call_mcp_chart_tool(
                chart_tool_call['tool_name'],
                chart_tool_call['args']
            )
        except Exception as e:
            print(f"[MCP] Failed to call chart tool: {e}")

    # è§£æå›¾è¡¨é…ç½®
    chart_config_data = parse_chart_config(final_content)

    # æ„å»ºQueryResult
    query_result = QueryResult.from_raw_data(raw_data) if raw_data else QueryResult()

    # ========================================================================
    # ğŸ”¥ æ•°æ®ä¸€è‡´æ€§éªŒè¯ï¼šé˜²æ­¢ LLM å¹»è§‰å¯¼è‡´çš„æ•°æ®ä¸åŒ¹é…é—®é¢˜
    # ========================================================================
    # éªŒè¯ LLM ç”Ÿæˆçš„å­—æ®µæ˜¯å¦çœŸå®å­˜åœ¨äºæŸ¥è¯¢ç»“æœä¸­
    llm_x_field = chart_config_data.get('x_field') if chart_config_data else None
    llm_y_field = chart_config_data.get('y_field') if chart_config_data else None

    actual_columns = []
    if raw_data and len(raw_data) > 0:
        actual_columns = list(raw_data[0].keys())

    # æ£€æµ‹å¹»è§‰å­—æ®µ
    hallucinated_fields = []
    if llm_x_field and llm_x_field not in actual_columns:
        hallucinated_fields.append(f"x_field: {llm_x_field}")
    if llm_y_field and llm_y_field not in actual_columns:
        hallucinated_fields.append(f"y_field: {llm_y_field}")

    if hallucinated_fields:
        print(f"âš ï¸ [æ•°æ®éªŒè¯] æ£€æµ‹åˆ° LLM å¹»è§‰å­—æ®µ: {hallucinated_fields}")
        print(f"   å®é™…å­—æ®µ: {actual_columns}ï¼Œå°†ä½¿ç”¨æ™ºèƒ½å­—æ®µæ˜ å°„")
        # æ¸…é™¤å¹»è§‰é…ç½®ï¼Œå¼ºåˆ¶ä½¿ç”¨æ™ºèƒ½æ˜ å°„
        chart_config_data = None

    # ä½¿ç”¨æ™ºèƒ½å­—æ®µæ˜ å°„ï¼ˆå¦‚æœæœ‰æ•°æ®ï¼‰
    if raw_data and DATA_VALIDATION_ENABLED:
        field_mapping = smart_field_mapping(raw_data, sql)
        chart_rec = recommend_chart(raw_data, sql, final_content[:200] if final_content else "")

        # è¦†ç›– LLM æä¾›çš„å­—æ®µï¼Œä½¿ç”¨çœŸå®æ•°æ®æ˜ å°„
        if not chart_config_data:
            chart_config_data = {
                'chart_type': chart_rec.chart_type,
                'chart_title': chart_rec.title,
                'x_field': field_mapping.x_field,
                'y_field': field_mapping.y_field,
            }
            print(f"ğŸ“Š [æ™ºèƒ½æ˜ å°„] X={field_mapping.x_field}, Y={field_mapping.y_field}, ç±»å‹={chart_rec.chart_type}")
        else:
            # éªŒè¯ LLM é…ç½®çš„å­—æ®µï¼Œå¦‚æœæ— æ•ˆåˆ™ä½¿ç”¨æ™ºèƒ½æ˜ å°„
            if llm_x_field and llm_x_field not in actual_columns:
                chart_config_data['x_field'] = field_mapping.x_field
            if llm_y_field and llm_y_field not in actual_columns:
                chart_config_data['y_field'] = field_mapping.y_field

    # æ„å»ºChartConfig
    chart_path = mcp_chart_path  # ä¼˜å…ˆä½¿ç”¨ mcp-echarts çš„å›¾è¡¨

    if chart_config_data:
        chart_type_str = chart_config_data.get('chart_type', 'table')
        try:
            chart_type = ChartType(chart_type_str)
        except ValueError:
            chart_type = ChartType.TABLE

        chart_config = ChartConfig(
            chart_type=chart_type,
            title=chart_config_data.get('chart_title', ''),
            x_field=chart_config_data.get('x_field'),
            y_field=chart_config_data.get('y_field')
        )
        answer = chart_config_data.get('answer', final_content)

        # å¦‚æœæ²¡æœ‰ mcp-echarts å›¾è¡¨ï¼Œå°è¯•ä½¿ç”¨æœ¬åœ°ç”Ÿæˆï¼ˆå›é€€æ–¹æ¡ˆï¼‰
        if not chart_path and auto_generate_chart:
            should_generate = chart_config_data.get('generate_chart', False)
            if should_generate and raw_data:
                chart_path = _generate_chart_file(
                    raw_data=raw_data,
                    chart_type=chart_type_str,
                    title=chart_config.title,
                    x_field=chart_config.x_field,
                    y_field=chart_config.y_field
                )
    else:
        chart_config = ChartConfig()
        answer = final_content

    # ğŸ”¥ğŸ”¥ğŸ”¥ ã€å…³é”®ä¿®å¤ã€‘ç¡®ä¿ answer å­—æ®µå§‹ç»ˆæœ‰å†…å®¹
    # å¦‚æœ LLM æ²¡æœ‰ç”Ÿæˆåˆ†ææ–‡æœ¬ï¼ŒåŸºäºæŸ¥è¯¢ç»“æœç”Ÿæˆé»˜è®¤åˆ†æ
    if not answer or not answer.strip():
        answer = _generate_default_answer(query_result, sql or '', chart_config)
        print("[Agent] LLMæœªç”Ÿæˆåˆ†ææ–‡æœ¬ï¼Œå·²ç”Ÿæˆé»˜è®¤æ•°æ®åˆ†æ")

    response = VisualizationResponse(
        answer=answer,
        sql=sql or '',
        data=query_result,
        chart=chart_config,
        success=True
    )

    # å°†å›¾è¡¨è·¯å¾„æ·»åŠ åˆ°å“åº”ä¸­ï¼ˆå¦‚æœç”Ÿæˆäº†ï¼‰
    if chart_path:
        if chart_path.startswith("http"):
            response.answer = f"{answer}\n\nğŸ“Š å›¾è¡¨é“¾æ¥: {chart_path}"
        else:
            response.answer = f"{answer}\n\nğŸ“Š å›¾è¡¨å·²ä¿å­˜: {chart_path}"

    return response


def _generate_chart_file(
    raw_data: list,
    chart_type: str,
    title: str,
    x_field: Optional[str],
    y_field: Optional[str]
) -> Optional[str]:
    """ç”Ÿæˆå›¾è¡¨æ–‡ä»¶

    Args:
        raw_data: SQLæŸ¥è¯¢çš„åŸå§‹æ•°æ®
        chart_type: å›¾è¡¨ç±»å‹
        title: å›¾è¡¨æ ‡é¢˜
        x_field: Xè½´å­—æ®µ
        y_field: Yè½´å­—æ®µ

    Returns:
        ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
    """
    # è·³è¿‡ä¸éœ€è¦å›¾è¡¨çš„ç±»å‹
    if chart_type in ('table', 'none'):
        return None

    try:
        # è½¬æ¢æ•°æ®æ ¼å¼
        echarts_data, actual_x, actual_y = sql_result_to_echarts_data(
            raw_data, x_field, y_field
        )

        if not echarts_data:
            return None

        # åˆ›å»ºå›¾è¡¨è¯·æ±‚
        request = ChartRequest(
            type=chart_type,
            data=echarts_data,
            title=title or "æŸ¥è¯¢ç»“æœ",
            series_name=actual_y or "æ•°å€¼",
            x_axis_name=actual_x,
            y_axis_name=actual_y
        )

        # ç”Ÿæˆå›¾è¡¨ï¼ˆä½¿ç”¨ç®€åŒ–ç‰ˆï¼Œç”ŸæˆHTMLï¼‰
        response: ChartResponse = generate_chart_simple(request, output_dir="./charts")

        if response.success:
            return response.image_path
        else:
            print(f"âš ï¸ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {response.error}")
            return None

    except Exception as e:
        print(f"âš ï¸ å›¾è¡¨ç”Ÿæˆå¼‚å¸¸: {e}")
        return None


# MCP client é…ç½®
# æ˜¯å¦å¯ç”¨ mcp-echartsï¼ˆéœ€è¦å…ˆè¿è¡Œ: mcp-echarts -t sse -p 3033ï¼‰
ENABLE_ECHARTS_MCP = True  # å·²å¯ç”¨ mcp-echarts

# ============================================================
# ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šæŒä¹…åŒ–å•ä¾‹æ¨¡å¼
# ============================================================
# å…¨å±€ç¼“å­˜ï¼Œé¿å…æ¯æ¬¡æŸ¥è¯¢éƒ½é‡æ–°åˆå§‹åŒ–
_cached_agent = None
_cached_mcp_client = None
_cached_tools = None
_cached_checkpointer = None
_cached_db_type = "postgresql"  # ç¼“å­˜å½“å‰æ•°æ®åº“ç±»å‹


def _get_mcp_config():
    """è·å– MCP æœåŠ¡å™¨é…ç½®"""
    import shutil
    import sys
    
    # Check if npx is available
    npx_command = "npx.cmd" if sys.platform == "win32" else "npx"
    npx_path = shutil.which(npx_command)
    
    if not npx_path:
        error_msg = (
            f"âŒ npx å‘½ä»¤ä¸å¯ç”¨ã€‚MCP PostgreSQL æœåŠ¡å™¨éœ€è¦ Node.js/npmã€‚\n"
            f"   è¯·å®‰è£… Node.js æˆ–è®¾ç½® DISABLE_MCP_TOOLS=true ä½¿ç”¨è‡ªå®šä¹‰å·¥å…·ã€‚\n"
            f"   å½“å‰å¹³å°: {sys.platform}, æŸ¥æ‰¾çš„å‘½ä»¤: {npx_command}"
        )
        print(error_msg)
        raise RuntimeError(
            f"npx command not found. Node.js is required for MCP servers. "
            f"Platform: {sys.platform}, Command: {npx_command}. "
            f"Set DISABLE_MCP_TOOLS=true to use custom tools instead."
        )
    
    print(f"âœ… npx å¯ç”¨: {npx_path}")

    # ç¡®ä¿DATABASE_URLåŒ…å«SSLå‚æ•°
    db_url = config.database_url
    if "sslmode" not in db_url.lower():
        if "?" in db_url:
            db_url += "&sslmode=require"
        else:
            db_url += "?sslmode=require"
        print(f"ğŸ”’ æ·»åŠ SSLå‚æ•°åˆ°æ•°æ®åº“è¿æ¥")

    mcp_config = {
        "postgres": {
            "transport": "stdio",
            "command": npx_command,
            "args": [
                "-y",
                "@modelcontextprotocol/server-postgres",
                db_url
            ],
        }
    }

    if ENABLE_ECHARTS_MCP:
        # æœ¬åœ°å¼€å‘ä½¿ç”¨ localhostï¼ŒDockerç¯å¢ƒä½¿ç”¨æœåŠ¡å mcp_echarts
        mcp_config["echarts"] = {
            "transport": "sse",
            "url": "http://localhost:3033/sse",
            "timeout": 30.0,
            "sse_read_timeout": 120.0,
        }

    return mcp_config


async def _get_or_create_agent(db_type: str = "postgresql"):
    """è·å–æˆ–åˆ›å»ºæŒä¹…åŒ–çš„ Agent å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Args:
        db_type: æ•°æ®åº“ç±»å‹ï¼Œç”¨äºç”Ÿæˆç‰¹å®šçš„ç³»ç»Ÿæç¤ºè¯

    Returns:
        tuple: (agent, mcp_client) - ç¼–è¯‘å¥½çš„agentå’ŒMCPå®¢æˆ·ç«¯
    """
    global _cached_agent, _cached_mcp_client, _cached_tools, _cached_checkpointer, _cached_db_type

    # æ£€æŸ¥æ•°æ®åº“ç±»å‹æ˜¯å¦å˜åŒ–ï¼Œå¦‚æœå˜åŒ–åˆ™é‡ç½® Agent
    if _cached_agent is not None and _cached_db_type != db_type:
        print(f"ğŸ”„ æ•°æ®åº“ç±»å‹å˜åŒ–: {_cached_db_type} -> {db_type}ï¼Œé‡ç½® Agent...")
        await reset_agent()
        _cached_db_type = db_type

    # å¦‚æœå·²ç¼“å­˜ï¼Œç›´æ¥è¿”å›
    if _cached_agent is not None and _cached_mcp_client is not None:
        return _cached_agent, _cached_mcp_client

    print(f"ğŸ”„ é¦–æ¬¡åˆå§‹åŒ– Agentï¼ˆæ•°æ®åº“ç±»å‹: {db_type}ï¼Œåç»­æŸ¥è¯¢å°†å¤ç”¨è¿æ¥ï¼‰...")

    # åˆ›å»º MCP å®¢æˆ·ç«¯
    try:
        mcp_config = _get_mcp_config()
        _cached_mcp_client = MultiServerMCPClient(mcp_config)
    except RuntimeError as e:
        print(f"âŒ MCP é…ç½®å¤±è´¥: {e}")
        print("   æç¤º: è®¾ç½® DISABLE_MCP_TOOLS=true å¯ä»¥ç¦ç”¨ MCP å¹¶ä½¿ç”¨è‡ªå®šä¹‰å·¥å…·")
        raise
    except Exception as e:
        print(f"âŒ MCP å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {e}")
        raise

    # è·å–å·¥å…·
    try:
        _cached_tools = await _cached_mcp_client.get_tools()
        print(f"âœ… MCP å·¥å…·åŠ è½½æˆåŠŸï¼Œå…± {len(_cached_tools)} ä¸ªå·¥å…·")
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ å¼ºåˆ¶æ·»åŠ æ–‡ä»¶æ•°æ®æºå·¥å…·ï¼ˆç¡¬ç¼–ç æ–¹å¼ï¼Œä¸ä¾èµ–ä»»ä½•æ¡ä»¶ï¼‰
        tool_names_before = [getattr(t, "name", str(t)) for t in _cached_tools]
        print(f"ğŸ“‹ MCP å·¥å…·åˆ—è¡¨: {', '.join(tool_names_before)}")
        
        # å¼ºåˆ¶æ·»åŠ  inspect_file
        if _inspect_file_tool:
            tool_name = getattr(_inspect_file_tool, "name", "inspect_file")
            if tool_name not in tool_names_before:
                print(f"â• [å¼ºåˆ¶æ·»åŠ ] inspect_file å·¥å…·")
                _cached_tools.append(_inspect_file_tool)
            else:
                print(f"â„¹ï¸ inspect_file å·¥å…·å·²å­˜åœ¨äº MCP å·¥å…·åˆ—è¡¨ä¸­")
        else:
            print(f"âš ï¸ inspect_file å·¥å…·æœªå¯¼å…¥ï¼Œæ— æ³•æ·»åŠ ")
        
        # å¼ºåˆ¶æ·»åŠ  analyze_dataframe
        if _analyze_dataframe_tool:
            tool_name = getattr(_analyze_dataframe_tool, "name", "analyze_dataframe")
            if tool_name not in tool_names_before:
                print(f"â• [å¼ºåˆ¶æ·»åŠ ] analyze_dataframe å·¥å…·")
                _cached_tools.append(_analyze_dataframe_tool)
            else:
                print(f"â„¹ï¸ analyze_dataframe å·¥å…·å·²å­˜åœ¨äº MCP å·¥å…·åˆ—è¡¨ä¸­")
        else:
            print(f"âš ï¸ analyze_dataframe å·¥å…·æœªå¯¼å…¥ï¼Œæ— æ³•æ·»åŠ ")
        
        # ğŸ”¥ æ·»åŠ è¯­ä¹‰å±‚å·¥å…·
        from langchain_core.tools import StructuredTool

        semantic_tools = [
            StructuredTool.from_function(
                func=resolve_business_term,
                name="resolve_business_term",
                description="è§£æä¸šåŠ¡æœ¯è¯­ï¼ˆå¦‚'æ€»æ”¶å…¥'ã€'é”€å”®é¢'ï¼‰ï¼Œè¿”å›è¯­ä¹‰å±‚å®šä¹‰ã€‚è¾“å…¥: æœ¯è¯­åç§°ï¼Œè¾“å‡º: JSONæ ¼å¼çš„åº¦é‡å®šä¹‰",
            ),
            StructuredTool.from_function(
                func=get_semantic_measure,
                name="get_semantic_measure",
                description="è·å–æŒ‡å®š Cube çš„åº¦é‡è¯¦æƒ…ã€‚è¾“å…¥: cubeåç§°å’Œåº¦é‡åç§°ï¼Œè¾“å‡º: å®Œæ•´åº¦é‡å®šä¹‰",
            ),
            StructuredTool.from_function(
                func=list_available_cubes,
                name="list_available_cubes",
                description="åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è¯­ä¹‰å±‚ Cubeï¼ˆå¦‚ Ordersã€Customersã€Productsï¼‰",
            ),
            StructuredTool.from_function(
                func=get_cube_measures,
                name="get_cube_measures",
                description="è·å–æŒ‡å®š Cube çš„æ‰€æœ‰åº¦é‡ã€‚è¾“å…¥: cubeåç§°ï¼Œè¾“å‡º: åº¦é‡åˆ—è¡¨",
            ),
            StructuredTool.from_function(
                func=normalize_status_value,
                name="normalize_status_value",
                description="è§„èŒƒåŒ–çŠ¶æ€å€¼ï¼ˆå¦‚'å·²å®Œæˆ'â†’'completed'ï¼‰",
            ),
        ]

        # å°†è¯­ä¹‰å±‚å·¥å…·æ·»åŠ åˆ°å·¥å…·åˆ—è¡¨
        _cached_tools.extend(semantic_tools)
        print(f"âœ… å·²æ·»åŠ  {len(semantic_tools)} ä¸ªè¯­ä¹‰å±‚å·¥å…·")

        # æœ€ç»ˆéªŒè¯
        final_tool_count = len(_cached_tools)
        final_tool_names = [getattr(t, "name", str(t)) for t in _cached_tools]
        semantic_tool_names = [getattr(t, "name", str(t)) for t in semantic_tools]
        print(f"\n{'='*60}")
        print(f"âœ… FORCED REGISTRATION: æœ€ç»ˆå·¥å…·åˆ—è¡¨åŒ…å« {final_tool_count} ä¸ªå·¥å…·")
        print(f"   å·¥å…·åç§°: {', '.join(final_tool_names)}")
        print(f"   - inspect_file: {'âœ…' if 'inspect_file' in final_tool_names else 'âŒ'}")
        print(f"   - analyze_dataframe: {'âœ…' if 'analyze_dataframe' in final_tool_names else 'âŒ'}")
        print(f"   - è¯­ä¹‰å±‚å·¥å…·: {', '.join(semantic_tool_names)}")
        print(f"{'='*60}\n")

    except FileNotFoundError as e:
        error_message = str(e)
        print(
            f"âŒ MCP å·¥å…·åˆå§‹åŒ–å¤±è´¥ï¼šå‘½ä»¤æœªæ‰¾åˆ°\n"
            f"   é”™è¯¯ä¿¡æ¯: {error_message}\n"
            f"   å¯èƒ½åŸå› : Node.js/npm æœªå®‰è£…æˆ–ä¸åœ¨ PATH ä¸­\n"
            f"   è§£å†³æ–¹æ¡ˆ: å®‰è£… Node.js æˆ–è®¾ç½® DISABLE_MCP_TOOLS=true"
        )
        raise RuntimeError(
            f"MCP initialization failed: command not found. "
            f"Error: {error_message}. "
            f"Install Node.js or set DISABLE_MCP_TOOLS=true"
        ) from e
    except Exception as e:
        print(f"âŒ MCP å·¥å…·åŠ è½½å¤±è´¥: {e}")
        raise

    # åˆ›å»º LLM
    llm = create_llm()
    llm_with_tools = llm.bind_tools(_cached_tools)

    # è·å–æ•°æ®åº“ç‰¹å®šçš„ç³»ç»Ÿæç¤ºè¯
    system_prompt = get_system_prompt(db_type)

    # ğŸ”´ğŸ”´ğŸ”´ å›¾è¡¨æ‹†åˆ†å…³é”®è¯æ£€æµ‹ï¼ˆç”¨äºå¼ºåˆ¶å·¥å…·è°ƒç”¨ï¼‰
    CHART_SPLIT_KEYWORDS = ["åˆ†å¼€", "æ‹†åˆ†", "åˆ†åˆ«æ˜¾ç¤º", "å•ç‹¬å±•ç¤º", "å•ç‹¬æ˜¾ç¤º", "å„è‡ªæ˜¾ç¤º", "æ‹†æˆ"]

    # ğŸ”´ğŸ”´ğŸ”´ å›¾è¡¨åˆå¹¶å…³é”®è¯æ£€æµ‹ï¼ˆç”¨äºå¼ºåˆ¶å·¥å…·è°ƒç”¨ï¼‰
    CHART_MERGE_KEYWORDS = ["åˆå¹¶", "åˆåœ¨ä¸€èµ·", "æ”¾åˆ°ä¸€èµ·", "åˆå¹¶åœ¨ä¸€å¼ å›¾", "åˆå¹¶åˆ°ä¸€èµ·", "åˆå¹¶æ˜¾ç¤º", "ç»„åˆ"]

    # å®šä¹‰èŠ‚ç‚¹
    async def call_model(state: MessagesState):
        messages = state["messages"]

        # ğŸ”§ æ£€æµ‹æ˜¯å¦æ˜¯å›¾è¡¨æ‹†åˆ†æˆ–åˆå¹¶è¯·æ±‚
        last_human_message = None
        for msg in reversed(messages):
            if isinstance(msg, HumanMessage):
                last_human_message = msg.content
                break

        is_split_request = False
        is_merge_request = False
        if last_human_message:
            is_split_request = any(keyword in str(last_human_message) for keyword in CHART_SPLIT_KEYWORDS)
            is_merge_request = any(keyword in str(last_human_message) for keyword in CHART_MERGE_KEYWORDS)

        # å¦‚æœæ˜¯æ‹†åˆ†æˆ–åˆå¹¶è¯·æ±‚ï¼Œå¢å¼ºç³»ç»Ÿæç¤ºè¯
        enhanced_system_prompt = system_prompt
        chart_count = None  # ğŸ”´ å¿…é¡»åœ¨å¤–å±‚åˆå§‹åŒ–ï¼Œå¦åˆ™åç»­ä»£ç æ— æ³•è®¿é—®
        if is_split_request:
            # ğŸ”´ æ£€æµ‹ç”¨æˆ·æ˜¯å¦æŒ‡å®šäº†å›¾è¡¨æ•°é‡
            import re
            if last_human_message:
                # åŒ¹é…å„ç§å›¾è¡¨æ•°é‡è¡¨è¾¾æ–¹å¼
                # æ³¨æ„ï¼šæ¨¡å¼é¡ºåºå¾ˆé‡è¦ï¼Œæ›´å…·ä½“çš„æ¨¡å¼åº”è¯¥åœ¨å‰é¢
                number_patterns = [
                    # ç›´æ¥ "æ‹†Xä¸ª" æˆ– "æ‹†æˆXä¸ª" æˆ– "æ‹†åˆ†æˆXä¸ª"
                    r'æ‹†(?:åˆ†)?(?:æˆ)?([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+)ä¸ª',
                    # "åˆ†æˆXä¸ª"
                    r'åˆ†æˆ([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+)ä¸ª',
                    # "åˆ†[åˆ«æˆ]Xä¸ª" - åŸæœ‰æ¨¡å¼ä¿ç•™
                    r'åˆ†[åˆ«æˆ]([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+)ä¸ª',
                    # "åˆ†åˆ«æ˜¾ç¤ºXä¸ª"
                    r'åˆ†åˆ«æ˜¾ç¤º([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+)ä¸ª',
                    # "å•ç‹¬å±•ç¤ºXä¸ª"
                    r'å•ç‹¬å±•ç¤º([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+)ä¸ª',
                ]
                for pattern in number_patterns:
                    match = re.search(pattern, str(last_human_message))
                    if match:
                        num_str = match.group(1)
                        # ä¸­æ–‡æ•°å­—è½¬é˜¿æ‹‰ä¼¯æ•°å­—
                        cn_nums = {'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5,
                                  'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'å': 10,
                                  '1': 1, '2': 2, '3': 3, '4': 4, '5': 5,
                                  '6': 6, '7': 7, '8': 8, '9': 9, '10': 10}
                        chart_count = cn_nums.get(num_str, int(num_str) if num_str.isdigit() else None)
                        if chart_count:
                            print(f"ğŸ” [åŒ¹é…æˆåŠŸ] æ­£åˆ™æ¨¡å¼: {pattern}, åŒ¹é…å€¼: {num_str}, è½¬æ¢ç»“æœ: {chart_count}")
                            break

            chart_count_instruction = ""
            if chart_count:
                chart_count_instruction = f"""

ğŸ”´ğŸ”´ğŸ”´ **ç”¨æˆ·æ˜ç¡®è¦æ±‚ç”Ÿæˆ {chart_count} ä¸ªå›¾è¡¨ï¼ä½ å¿…é¡»ç”Ÿæˆæ­£å¥½ {chart_count} ä¸ªå›¾è¡¨ï¼**

**å¦‚ä½•ç”Ÿæˆ {chart_count} ä¸ªå›¾è¡¨ï¼š**
- å¦‚æœæœ‰2ä¸ªæŒ‡æ ‡ï¼ˆå¦‚è®¢å•æ•°é‡ã€é”€å”®é¢ï¼‰ï¼Œæ¯ä¸ªæŒ‡æ ‡ç”¨2ç§å›¾è¡¨ç±»å‹ï¼ˆæŠ˜çº¿å›¾+æŸ±çŠ¶å›¾ï¼‰= 4ä¸ªå›¾è¡¨
- å¦‚æœæœ‰1ä¸ªæŒ‡æ ‡ï¼Œç”¨{chart_count}ç§ä¸åŒå›¾è¡¨ç±»å‹ï¼ˆæŠ˜çº¿å›¾ã€æŸ±çŠ¶å›¾ã€é¥¼å›¾ã€æ•£ç‚¹å›¾ç­‰ï¼‰
- **å…³é”®**ï¼šåŒä¸€ä¸ªæ•°æ®å¯ä»¥ç”¨ä¸åŒå›¾è¡¨ç±»å‹å±•ç¤ºï¼Œè¿™æ˜¯å…è®¸çš„ï¼
"""
                print(f"ğŸ”´ğŸ“Š [æ‹†åˆ†è¯·æ±‚] æ£€æµ‹åˆ°ç”¨æˆ·è¦æ±‚ {chart_count} ä¸ªå›¾è¡¨ï¼åŸå§‹æ¶ˆæ¯: {last_human_message}")
            else:
                print(f"ğŸ“Š [æ‹†åˆ†è¯·æ±‚] æœªæ£€æµ‹åˆ°å…·ä½“å›¾è¡¨æ•°é‡ã€‚åŸå§‹æ¶ˆæ¯: {last_human_message}")

            enhanced_system_prompt = f"""{system_prompt}

## ğŸš¨ğŸš¨ğŸš´ã€å½“å‰è¯·æ±‚ç‰¹æ®ŠæŒ‡ä»¤ - å¿…é¡»æ‰§è¡Œã€‘ğŸš¨ğŸš¨ğŸš¨

ç”¨æˆ·åˆšåˆšè¯·æ±‚å°†å›¾è¡¨æ‹†åˆ†ï¼ˆè¯´"{'æˆ– '.join(CHART_SPLIT_KEYWORDS)}"ï¼‰ã€‚{chart_count_instruction}

**ä½ å¿…é¡»æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼Œä¸èƒ½åªè¾“å‡ºæ–‡æœ¬ï¼š**

1. **ç¬¬1æ­¥**ï¼šè°ƒç”¨ `query` å·¥å…·æ‰§è¡ŒSQLæŸ¥è¯¢è·å–æ•°æ®
2. **ç¬¬2æ­¥**ï¼šæ ¹æ®æ•°æ®ç‰¹å¾å’Œç”¨æˆ·è¦æ±‚ï¼Œè°ƒç”¨å¯¹åº”æ•°é‡çš„å›¾è¡¨å·¥å…·
   - æ—¶é—´è¶‹åŠ¿æ•°æ® â†’ generate_line_chartï¼ˆæŠ˜çº¿å›¾ï¼‰
   - åˆ†ç±»å¯¹æ¯”æ•°æ® â†’ generate_bar_chartï¼ˆæŸ±çŠ¶å›¾ï¼‰
   - å æ¯”åˆ†å¸ƒæ•°æ® â†’ generate_pie_chartï¼ˆé¥¼å›¾ï¼‰
   - åŒä¸€æ•°æ®å¯ä»¥ç”¨å¤šç§å›¾è¡¨ç±»å‹å±•ç¤ºï¼

**ç¦æ­¢è¡Œä¸º**ï¼š
- âŒ åªè¾“å‡ºSQLè¯­å¥è€Œä¸è°ƒç”¨ query å·¥å…·
- âŒ åªè¾“å‡ºJSONé…ç½®è€Œä¸è°ƒç”¨å›¾è¡¨å·¥å…·
- âŒ è§£é‡ŠSQLè€Œä¸æ‰§è¡Œ
- âŒ ç”Ÿæˆçš„å›¾è¡¨æ•°é‡å°‘äºç”¨æˆ·è¦æ±‚ï¼

**æ­£ç¡®å“åº”ç¤ºä¾‹**ï¼š
```
ç”¨æˆ·è¯´ï¼šæŠŠé”€å”®é¢å’Œè®¢å•æ•°æ‹†æˆå››ä¸ª
ä½ çš„å“åº”ï¼š
1. è°ƒç”¨ query å·¥å…·æ‰§è¡Œ SQL è·å–æ•°æ®
2. è°ƒç”¨ generate_line_chart(é”€å”®é¢è¶‹åŠ¿)
3. è°ƒç”¨ generate_bar_chart(é”€å”®é¢å¯¹æ¯”)
4. è°ƒç”¨ generate_line_chart(è®¢å•æ•°é‡è¶‹åŠ¿)
5. è°ƒç”¨ generate_bar_chart(è®¢å•æ•°é‡å¯¹æ¯”)
```

ç°åœ¨è¯·æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œç”Ÿæˆç”¨æˆ·è¦æ±‚æ•°é‡çš„å›¾è¡¨ï¼
"""
        elif is_merge_request:
            enhanced_system_prompt = f"""{system_prompt}

## ğŸš¨ğŸš¨ğŸš¨ã€å½“å‰è¯·æ±‚ç‰¹æ®ŠæŒ‡ä»¤ - å›¾è¡¨åˆå¹¶ã€‘ğŸš¨ğŸš¨ğŸš¨

ç”¨æˆ·åˆšåˆšè¯·æ±‚å°†å›¾è¡¨åˆå¹¶ï¼ˆè¯´"{'æˆ– '.join(CHART_MERGE_KEYWORDS)}"ï¼‰ã€‚

**ä½ å¿…é¡»æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š**

1. **åˆ†æå†å²å¯¹è¯**ï¼šä»å¯¹è¯å†å²ä¸­æ‰¾å‡ºä¹‹å‰ç”Ÿæˆçš„æ‰€æœ‰å›¾è¡¨é…ç½®
2. **æå–å›¾è¡¨æ•°æ®**ï¼šæå–æ¯ä¸ªå›¾è¡¨çš„ xAxisã€yAxisã€series ç­‰é…ç½®
3. **ç”Ÿæˆåˆå¹¶å›¾è¡¨**ï¼šè°ƒç”¨ `generate_echarts` å·¥å…·ç”ŸæˆåŒYè½´åˆå¹¶å›¾è¡¨

**åˆå¹¶è§„åˆ™**ï¼š
- æ•°å€¼é‡çº§å·®å¼‚>10å€çš„åˆ†é…åˆ°ä¸åŒYè½´
- é‡‘é¢ç±»æŒ‡æ ‡ï¼ˆé”€å”®é¢ã€æ”¶å…¥ï¼‰â†’ å·¦Yè½´ï¼ˆyAxisIndex: 0ï¼‰
- æ•°é‡ç±»æŒ‡æ ‡ï¼ˆè®¢å•æ•°ã€äººæ•°ï¼‰â†’ å³Yè½´ï¼ˆyAxisIndex: 1ï¼‰
- ä½¿ç”¨ä¸åŒå›¾è¡¨ç±»å‹åŒºåˆ†ï¼ˆæŠ˜çº¿å›¾è¡¨ç¤ºè¶‹åŠ¿ï¼ŒæŸ±çŠ¶å›¾è¡¨ç¤ºæ•°é‡ï¼‰

**ç¦æ­¢è¡Œä¸º**ï¼š
- âŒ åªè¾“å‡ºæ–‡æœ¬è¯´æ˜è€Œä¸ç”Ÿæˆå›¾è¡¨
- âŒ è¦æ±‚ç”¨æˆ·æ‰‹åŠ¨é€‰æ‹©å›¾è¡¨
- âŒ è§£é‡Šå¦‚ä½•åˆå¹¶è€Œä¸å®é™…æ‰§è¡Œ

**æ­£ç¡®å“åº”ç¤ºä¾‹**ï¼š
```
ç”¨æˆ·è¯´ï¼šæŠŠå®ƒä»¬åˆå¹¶åœ¨ä¸€èµ·
ä½ çš„å“åº”ï¼š
1. ä»å†å²ä¸­æå–ä¹‹å‰ç”Ÿæˆçš„å›¾è¡¨é…ç½®
2. è°ƒç”¨ generate_echarts å·¥å…·ï¼Œä¼ å…¥åˆå¹¶åçš„åŒYè½´å›¾è¡¨é…ç½®
```

**è¾“å‡ºæ ¼å¼**ï¼šå¿…é¡»ä½¿ç”¨ [CHART_START]...[CHART_END] æ ¼å¼è¾“å‡ºå®Œæ•´çš„å›¾è¡¨é…ç½®ã€‚

ç°åœ¨è¯·æ‰§è¡Œå·¥å…·è°ƒç”¨ç”Ÿæˆåˆå¹¶å›¾è¡¨ï¼
"""

        # ğŸ”§ ä¼˜åŒ–ä¸Šä¸‹æ–‡çª—å£ï¼šæ ¹æ®è¯·æ±‚ç±»å‹é™åˆ¶å†å²æ¶ˆæ¯æ•°é‡
        # è¿™æœ‰åŠ©äºæé«˜ LLM å¯¹é‡è¦ä¿¡æ¯çš„å…³æ³¨åº¦ï¼Œé¿å…è¢«è¿‡å¤šå†å²å¹²æ‰°
        MAX_CONTEXT_MESSAGES = 20  # é»˜è®¤ä¿ç•™æœ€è¿‘20æ¡æ¶ˆæ¯
        if is_merge_request:
            # åˆå¹¶è¯·æ±‚éœ€è¦æ›´å¤šä¸Šä¸‹æ–‡æ¥æŸ¥æ‰¾ä¹‹å‰çš„å›¾è¡¨é…ç½®
            MAX_CONTEXT_MESSAGES = 30
            print(f"ğŸ“Š [åˆå¹¶è¯·æ±‚] æ‰©å±•ä¸Šä¸‹æ–‡çª—å£åˆ° {MAX_CONTEXT_MESSAGES} æ¡æ¶ˆæ¯")
        elif is_split_request:
            # æ‹†åˆ†è¯·æ±‚éœ€è¦ä¸­ç­‰ä¸Šä¸‹æ–‡
            MAX_CONTEXT_MESSAGES = 15
            print(f"ğŸ“Š [æ‹†åˆ†è¯·æ±‚] è®¾ç½®ä¸Šä¸‹æ–‡çª—å£åˆ° {MAX_CONTEXT_MESSAGES} æ¡æ¶ˆæ¯")

        # æˆªæ–­å†å²æ¶ˆæ¯ï¼Œä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯ï¼ˆä½†ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ï¼‰
        system_messages = [m for m in messages if isinstance(m, SystemMessage)]
        other_messages = [m for m in messages if not isinstance(m, SystemMessage)]

        if len(other_messages) > MAX_CONTEXT_MESSAGES:
            print(f"ğŸ“Š [ä¸Šä¸‹æ–‡ä¼˜åŒ–] åŸå§‹æ¶ˆæ¯æ•°: {len(other_messages)}, æˆªæ–­åˆ°: {MAX_CONTEXT_MESSAGES}")
            # ğŸ”§ æ™ºèƒ½æˆªæ–­ï¼šä¿ç•™ AIMessage-ToolMessage é…å¯¹å…³ç³»
            # ä»åå¾€å‰æ‰«æï¼Œç¡®ä¿æ¯æ¡ AIMessage åé¢æœ‰å®Œæ•´çš„ ToolMessage å“åº”
            from langchain_core.messages import AIMessage
            selected_messages = []
            tool_call_ids_to_include = set()

            # é¦–å…ˆæ‰¾åˆ°æœ€è¿‘çš„ MAX_CONTEXT_MESSAGES æ¡æ¶ˆæ¯
            temp_selected = other_messages[-MAX_CONTEXT_MESSAGES:]

            # ä»åå¾€å‰æ‰«æï¼Œæ‰¾å‡ºæ‰€æœ‰éœ€è¦ä¿ç•™çš„ tool_call_id
            for msg in reversed(temp_selected):
                selected_messages.insert(0, msg)
                if isinstance(msg, AIMessage) and hasattr(msg, 'tool_calls') and msg.tool_calls:
                    # è®°å½•è¿™ä¸ª AIMessage çš„æ‰€æœ‰ tool_call_id
                    for tc in msg.tool_calls:
                        tool_call_ids_to_include.add(tc.get('id', ''))

            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥ selected_messages ä¸­æ˜¯å¦æœ‰ ToolMessage çš„ tool_call_id
            # ä¸åœ¨ tool_call_ids_to_include ä¸­ï¼Œå¦‚æœæ˜¯çš„è¯ï¼Œè¿™è¡¨ç¤ºæˆªæ–­ç ´åäº†é…å¯¹
            # éœ€è¦æ‰¾åˆ°å®Œæ•´çš„æ¶ˆæ¯ç»„é‡æ–°æ„å»º
            clean_messages = []
            pending_tool_calls = {}  # tool_call_id -> AIMessage

            for msg in selected_messages:
                if isinstance(msg, AIMessage) and hasattr(msg, 'tool_calls') and msg.tool_calls:
                    # è®°å½•å¾…åŒ¹é…çš„å·¥å…·è°ƒç”¨
                    for tc in msg.tool_calls:
                        pending_tool_calls[tc.get('id', '')] = msg
                    clean_messages.append(msg)
                elif isinstance(msg, ToolMessage):
                    # æ£€æŸ¥è¿™ä¸ª ToolMessage æ˜¯å¦æœ‰å¯¹åº”çš„ AIMessage
                    if msg.tool_call_id in pending_tool_calls:
                        clean_messages.append(msg)
                        del pending_tool_calls[msg.tool_call_id]
                    # å¦‚æœ ToolMessage çš„ tool_call_id ä¸åœ¨ pending_tool_calls ä¸­ï¼Œ
                    # è¯´æ˜å®ƒçš„ AIMessage è¢«æˆªæ–­äº†ï¼Œè¿™ä¸ª ToolMessage ä¹Ÿè¦è·³è¿‡
                else:
                    clean_messages.append(msg)

            other_messages = clean_messages
            messages = system_messages + other_messages

        if not any(isinstance(m, SystemMessage) for m in messages):
            messages = [SystemMessage(content=enhanced_system_prompt)] + messages
            print(f"ğŸ“ [ç³»ç»Ÿæç¤ºè¯] æ·»åŠ æ–°çš„ç³»ç»Ÿæ¶ˆæ¯")
        elif is_split_request or is_merge_request:
            # æ›¿æ¢å·²æœ‰çš„ç³»ç»Ÿæ¶ˆæ¯
            old_system_count = len([m for m in messages if isinstance(m, SystemMessage)])
            messages = [SystemMessage(content=enhanced_system_prompt)] + [m for m in messages if not isinstance(m, SystemMessage)]
            print(f"ğŸ“ [ç³»ç»Ÿæç¤ºè¯] æ›¿æ¢ç³»ç»Ÿæ¶ˆæ¯ (åŸæœ‰: {old_system_count} ä¸ª)")
            # æ‰“å°å¢å¼ºæç¤ºè¯çš„å…³é”®éƒ¨åˆ†ç”¨äºè°ƒè¯•
            if chart_count:
                print(f"ğŸ“ [å¢å¼ºæç¤ºè¯] åŒ…å«å›¾è¡¨æ•°é‡æŒ‡ä»¤: {chart_count} ä¸ªå›¾è¡¨")
            else:
                print(f"ğŸ“ [å¢å¼ºæç¤ºè¯] åŒ…å«æ‹†åˆ†æŒ‡ä»¤ (æ— å…·ä½“æ•°é‡)")

        # ğŸ”§ æ ‡å‡†åŒ–æ¶ˆæ¯å†…å®¹ï¼šå°† ToolMessage çš„ list æ ¼å¼è½¬æ¢ä¸º string
        # MCP æœåŠ¡å™¨è¿”å›çš„ ToolMessage.content å¯èƒ½æ˜¯ list æ ¼å¼
        # ä½† LLM API åªæ¥å— string æ ¼å¼
        normalized_messages = []
        for msg in messages:
            if isinstance(msg, ToolMessage) and isinstance(msg.content, list):
                # æå– list ä¸­çš„ text å†…å®¹
                text_parts = []
                image_count = 0
                for item in msg.content:
                    if isinstance(item, dict):
                        item_type = item.get('type', '')
                        if item_type == 'image':
                            # å›¾è¡¨æˆåŠŸç”Ÿæˆï¼Œè®°å½•ä½†ä¸åŒ…å«å®Œæ•´ base64 æ•°æ®
                            image_count += 1
                            text_parts.append(f"[å›¾è¡¨å·²ç”Ÿæˆ: image/{item.get('id', 'unknown')}]")
                        else:
                            text = item.get('text', '')
                            if text:
                                # æˆªæ–­è¿‡é•¿çš„æ–‡æœ¬
                                if len(text) > 10000:
                                    text = text[:10000] + "...[å†…å®¹è¿‡é•¿å·²æˆªæ–­]"
                                text_parts.append(text)
                    elif isinstance(item, str):
                        if len(item) > 10000:
                            item = item[:10000] + "...[å†…å®¹è¿‡é•¿å·²æˆªæ–­]"
                        text_parts.append(item)
                # åˆ›å»ºæ–°çš„ ToolMessageï¼Œcontent ä¸ºå­—ç¬¦ä¸²
                from langchain_core.messages import ToolMessage as TM
                normalized_content = '\n'.join(text_parts) if text_parts else f"[å·¥å…·è¿”å›äº† {image_count} ä¸ªå›¾åƒ]"
                normalized_messages.append(TM(content=normalized_content, tool_call_id=msg.tool_call_id))
            else:
                normalized_messages.append(msg)
        messages = normalized_messages

        response = await llm_with_tools.ainvoke(messages)

        # ğŸ”´ è®°å½•å·¥å…·è°ƒç”¨æ•°é‡
        if response.tool_calls:
            tool_names = [tc.get('name') for tc in response.tool_calls]
            chart_tools = [t for t in tool_names if 'chart' in t.lower()]
            print(f"ğŸ”§ [å·¥å…·è°ƒç”¨] æ€»è®¡: {len(response.tool_calls)} ä¸ª, å›¾è¡¨å·¥å…·: {len(chart_tools)} ä¸ª -> {chart_tools}")
            if is_split_request and chart_count:
                if len(chart_tools) < chart_count:
                    print(f"âš ï¸ [è­¦å‘Š] ç”¨æˆ·è¦æ±‚ {chart_count} ä¸ªå›¾è¡¨ï¼Œä½† LLM åªè°ƒç”¨äº† {len(chart_tools)} ä¸ªå›¾è¡¨å·¥å…·ï¼")
        else:
            print(f"ğŸ”§ [å·¥å…·è°ƒç”¨] æœ¬æ¬¡ LLM è°ƒç”¨æ²¡æœ‰å·¥å…·è°ƒç”¨")

        # ğŸ”§ å¦‚æœæ˜¯æ‹†åˆ†è¯·æ±‚ä½†LLMæ²¡æœ‰è°ƒç”¨å·¥å…·ï¼Œå¼ºåˆ¶æå–SQLå¹¶åˆ›å»ºå·¥å…·è°ƒç”¨
        if is_split_request and not response.tool_calls:
            print("ğŸ”´ æ£€æµ‹åˆ°æ‹†åˆ†è¯·æ±‚ä½†LLMæœªè°ƒç”¨å·¥å…·ï¼Œå°è¯•æå–SQLå¼ºåˆ¶æ‰§è¡Œ...")
            content = response.content or ""

            # å°è¯•æå–SQLï¼ˆä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼‰
            import re
            sql_pattern = r'```sql\s*([\s\S]*?)\s*```'
            sql_matches = re.findall(sql_pattern, str(content))

            if sql_matches:
                extracted_sql = sql_matches[0].strip()
                print(f"âœ… æå–åˆ°SQL: {extracted_sql[:100]}...")

                # éªŒè¯SQLå®‰å…¨æ€§
                is_safe, error_msg = SQLValidator.validate(extracted_sql)
                if not is_safe:
                    print(f"âŒ æå–çš„SQLä¸å®‰å…¨: {error_msg}")
                    return {"messages": [response]}

                # åˆ›å»ºå¼ºåˆ¶å·¥å…·è°ƒç”¨
                import uuid

                # ğŸ”§ ä½¿ç”¨ LangChain æ ‡å‡†çš„å·¥å…·è°ƒç”¨æ ¼å¼
                # å¿…é¡»åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µï¼šname, args, id, type
                forced_tool_call = {
                    "name": "query",
                    "args": {"sql": extracted_sql},
                    "id": str(uuid.uuid4()),
                    "type": "tool_call"  # ğŸ”´ å¿…éœ€å­—æ®µï¼Œç”¨äº LangChain è¯†åˆ«
                }

                # ğŸ”´ åˆ›å»ºæ–°çš„å“åº”ï¼Œå¸¦æœ‰å·¥å…·è°ƒç”¨å’Œæ˜ç¡®çš„åç»­æŒ‡ä»¤
                from langchain_core.messages import AIMessage

                # ğŸ”´ğŸ”´ğŸ”´ å…³é”®ä¿®å¤ï¼šåœ¨ content ä¸­æ˜ç¡®å‘Šè¯‰ LLM åœ¨çœ‹åˆ°æŸ¥è¯¢ç»“æœåè¦åšä»€ä¹ˆ
                # è¿™æ ·å½“æŸ¥è¯¢ç»“æœè¿”å›æ—¶ï¼ŒLLM ä¼šç»§ç»­è°ƒç”¨å›¾è¡¨å·¥å…·
                forced_instruction = f"""å¥½çš„ï¼Œæˆ‘æ¥æ‰§è¡ŒæŸ¥è¯¢æ‹†åˆ†å›¾è¡¨ã€‚

**ã€é‡è¦ã€‘æŸ¥è¯¢æ‰§è¡Œåï¼Œä½ å¿…é¡»ï¼š**

1. åˆ†ææŸ¥è¯¢ç»“æœä¸­çš„æ•°æ®
2. æ ¹æ®æ•°æ®ç‰¹å¾ï¼Œä¸ºæ¯ä¸ªæŒ‡æ ‡è°ƒç”¨**å•ç‹¬çš„å›¾è¡¨å·¥å…·**ï¼š
   - æ—¶é—´è¶‹åŠ¿æ•°æ® â†’ è°ƒç”¨ `generate_line_chart`
   - åˆ†ç±»å¯¹æ¯”æ•°æ® â†’ è°ƒç”¨ `generate_bar_chart`
   - å æ¯”åˆ†å¸ƒæ•°æ® â†’ è°ƒç”¨ `generate_pie_chart`

3. **å¿…é¡»è°ƒç”¨å·¥å…·ç”Ÿæˆå›¾è¡¨**ï¼Œä¸è¦åªè§£é‡Šæ•°æ®ï¼

æ‰§è¡ŒSQLï¼š
```sql
{extracted_sql}
```
"""
                enhanced_response = AIMessage(
                    content=forced_instruction,
                    tool_calls=[forced_tool_call]
                )
                print("ğŸ”§ å·²åˆ›å»ºå¼ºåˆ¶å·¥å…·è°ƒç”¨ï¼ŒåŒ…å«æ˜ç¡®çš„åç»­æŒ‡ä»¤")
                print(f"   å·¥å…·è°ƒç”¨æ ¼å¼: {forced_tool_call}")
                return {"messages": [enhanced_response]}
            else:
                print("âš ï¸ æœªèƒ½ä»å“åº”ä¸­æå–SQL")

        return {"messages": [response]}

    def should_continue(state: MessagesState) -> Literal["tools", "agent", END]:
        """
        å¢å¼ºçš„è·¯ç”±é€»è¾‘ï¼š
        - æ£€æµ‹å·¥å…·é”™è¯¯å¹¶è·¯ç”±å› Agent è¿›è¡Œè‡ªæˆ‘ä¿®æ­£
        - æ£€æµ‹ SQL å®‰å…¨é—®é¢˜å¹¶é˜»æ­¢æ‰§è¡Œ
        - é™åˆ¶ä¿®å¤æ¬¡æ•°é˜²æ­¢æ— é™å¾ªç¯
        - ğŸ”¥ ä¿®å¤ï¼šå¼ºåˆ¶å·¥å…·æ‰§è¡Œåå›åˆ° agent èŠ‚ç‚¹ç”Ÿæˆæœ€ç»ˆåˆ†æç­”æ¡ˆ
        """
        messages = state["messages"]
        last_message = messages[-1]

        # æ–°å¢: æ£€æŸ¥ä¿®å¤æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯
        tool_message_count = sum(1 for m in messages if isinstance(m, ToolMessage))
        if tool_message_count > 10:  # å¢åŠ åˆ°10æ¬¡ä»¥æ”¯æŒåŒè½´å›¾ç­‰å¤æ‚åœºæ™¯
            print(f"âš ï¸ è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶ ({tool_message_count})ï¼Œç»“æŸæ‰§è¡Œ")
            return END

        # A. æ£€æŸ¥å·¥å…·æ‰§è¡Œç»“æœæ˜¯å¦å‡ºé”™ï¼ˆToolMessage è¿”å›é”™è¯¯æ—¶è·¯ç”±å› Agent ä¿®å¤ï¼‰
        if isinstance(last_message, ToolMessage):
            content_str = str(last_message.content).lower()
            # å¸¸è§çš„ SQL/æ•°æ®åº“é”™è¯¯å…³é”®è¯
            error_indicators = [
                "error", "exception", "failed", "invalid",
                "relation does not exist", "column does not exist",
                "syntax error", "permission denied", "does not exist",
                "no such table", "undefined column", "ambiguous column",
                # DuckDB ç±»å‹ä¸åŒ¹é…é”™è¯¯ (å¦‚ SUBSTRING ç”¨äº TIMESTAMP åˆ—)
                "no function matches", "argument types", "binder error",
                "cannot be applied to", "type mismatch"
            ]
            for indicator in error_indicators:
                if indicator in content_str:
                    # æ–°å¢: å¦‚æœå·²ç»å¤šæ¬¡ä¿®å¤ä»ç„¶å‡ºé”™ï¼Œç›´æ¥ç»“æŸ
                    if tool_message_count >= 3:
                        print(f"âŒ ä¿®å¤æ¬¡æ•°å·²è¾¾ä¸Šé™ ({tool_message_count})ï¼Œåœæ­¢å°è¯•")
                        return END
                    print(f"ğŸš¨ æ£€æµ‹åˆ°å·¥å…·æ‰§è¡Œé”™è¯¯ï¼Œè·¯ç”±å› Agent è¿›è¡Œè‡ªæˆ‘ä¿®æ­£...")
                    return "agent"

            # ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šå·¥å…·æ‰§è¡ŒæˆåŠŸåï¼Œå¼ºåˆ¶å›åˆ° agent è®© LLM ç”Ÿæˆæœ€ç»ˆåˆ†æç­”æ¡ˆ
            # è¿™è§£å†³äº†"å·¥å…·è°ƒç”¨ååªè¿”å›åŸå§‹æ•°æ®è€Œä¸ç”Ÿæˆåˆ†ææ–‡æœ¬"çš„é—®é¢˜
            if tool_message_count < 5:  # ç¡®ä¿ä¸ä¼šæ— é™å¾ªç¯
                print(f"âœ… å·¥å…·æ‰§è¡Œå®Œæˆï¼Œè·¯ç”±å› Agent ç”Ÿæˆæœ€ç»ˆåˆ†æç­”æ¡ˆ...")
                return "agent"

        # B. æ£€æŸ¥ AI æ˜¯å¦è¦è°ƒç”¨å·¥å…·
        if isinstance(last_message, AIMessage) and last_message.tool_calls:
            # ğŸ”’ SQL å®‰å…¨æ‹¦æˆªï¼šåœ¨å·¥å…·æ‰§è¡Œå‰æ ¡éªŒ SQLï¼ˆä½¿ç”¨ç‹¬ç«‹çš„ SQLValidator æ¨¡å—ï¼‰
            for tc in last_message.tool_calls:
                if tc.get('name') == 'query':
                    sql = tc.get('args', {}).get('sql', '')
                    is_safe, error_msg = SQLValidator.validate(sql)
                    if not is_safe:
                        # è®°å½•è¢«æ‹¦æˆªçš„ SQLï¼ˆæˆªæ–­ä»¥ä¿æŠ¤æ—¥å¿—ï¼‰
                        sanitized_sql = SQLValidator.sanitize_for_logging(sql, 100)
                        print(f"ğŸ›‘ SQL å®‰å…¨æ‹¦æˆª: {error_msg}")
                        print(f"   è¢«æ‹¦æˆªçš„ SQL: {sanitized_sql}")
                        # æ³¨æ„ï¼šè¿™é‡Œè¿”å› "tools" è®© SafeToolNode å¤„ç†ï¼Œå®ƒä¼šè¿”å›é”™è¯¯æ¶ˆæ¯ç»™ Agent
                        # è¿™æ · Agent å¯ä»¥çœ‹åˆ°é”™è¯¯å¹¶å°è¯•ä¿®æ­£
            return "tools"

        # ğŸ”¥ æ–°å¢ï¼šå¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯æ˜¯ AIMessage ä½†æ²¡æœ‰æœ‰æ„ä¹‰çš„ contentï¼Œç»§ç»­ç”Ÿæˆ
        if isinstance(last_message, AIMessage):
            content = last_message.content
            # æ£€æŸ¥æ˜¯å¦æ²¡æœ‰ content æˆ– content å¤ªçŸ­ï¼ˆå°‘äº20ä¸ªå­—ç¬¦ï¼‰
            if not content or len(content.strip()) < 20:
                print(f"âš ï¸ AIMessage æ²¡æœ‰æœ‰æ„ä¹‰çš„ content (é•¿åº¦: {len(content) if content else 0})ï¼Œéœ€è¦ç»§ç»­ç”Ÿæˆ...")
                # ä½†è¦é¿å…æ— é™å¾ªç¯ï¼Œæ£€æŸ¥å‰é¢æ˜¯å¦å·²ç»æœ‰å¤šæ¬¡å°è¯•
                empty_content_count = sum(
                    1 for m in messages
                    if isinstance(m, AIMessage) and (not m.content or len(m.content.strip()) < 20)
                )
                if empty_content_count < 3:  # æœ€å¤šå…è®¸3æ¬¡ç©ºå†…å®¹å°è¯•
                    return "agent"
                else:
                    print(f"âŒ ç©ºå†…å®¹å°è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™ ({empty_content_count})ï¼Œç»“æŸæ‰§è¡Œ")

        return END

    # ğŸ”’ åˆ›å»ºå¸¦å®‰å…¨æ ¡éªŒçš„å·¥å…·èŠ‚ç‚¹ï¼ˆä½¿ç”¨ç‹¬ç«‹çš„ SQLValidator æ¨¡å—ï¼‰
    class SafeToolNode:
        """
        å¸¦ SQL å®‰å…¨æ ¡éªŒçš„å·¥å…·èŠ‚ç‚¹åŒ…è£…å™¨

        å½“ Agent å°è¯•æ‰§è¡Œå±é™© SQL æ—¶ï¼Œä¸ä¼šçœŸæ­£æ‰§è¡Œï¼Œ
        è€Œæ˜¯è¿”å›ä¸€ä¸ªé”™è¯¯æ¶ˆæ¯ï¼Œè®© Agent æœ‰æœºä¼šä¿®æ­£å¹¶é‡è¯•ã€‚
        """
        def __init__(self, tools):
            self._tool_node = ToolNode(tools)

        async def __call__(self, state: MessagesState):
            messages = state["messages"]
            last_message = messages[-1]

            # åœ¨æ‰§è¡Œ query å·¥å…·å‰è¿›è¡Œå®‰å…¨æ ¡éªŒ
            if isinstance(last_message, AIMessage) and last_message.tool_calls:
                for tc in last_message.tool_calls:
                    if tc.get('name') == 'query':
                        sql = tc.get('args', {}).get('sql', '')
                        is_safe, error_msg = SQLValidator.validate(sql)
                        if not is_safe:
                            # è¿”å›ä¸€ä¸ªé”™è¯¯æ¶ˆæ¯ï¼Œè€Œä¸æ˜¯æ‰§è¡Œå±é™©çš„ SQL
                            # è¿™è®© Agent çŸ¥é“è¢«æ‹¦æˆªäº†ï¼Œå¯ä»¥å°è¯•ç”Ÿæˆå®‰å…¨çš„æŸ¥è¯¢
                            return {
                                "messages": [
                                    ToolMessage(
                                        content=f"ğŸš« SQL æ‰§è¡Œè¢«å®‰å…¨ç³»ç»Ÿæ‹¦æˆª: {error_msg}\n\n"
                                                f"è¯·åªç”Ÿæˆ SELECT æŸ¥è¯¢è¯­å¥ï¼Œä¸è¦å°è¯•ä¿®æ”¹æˆ–åˆ é™¤æ•°æ®ã€‚",
                                        tool_call_id=tc.get('id', 'unknown')
                                    )
                                ]
                            }

            # å®‰å…¨æ ¡éªŒé€šè¿‡ï¼Œæ‰§è¡ŒåŸå§‹å·¥å…·
            return await self._tool_node.ainvoke(state)

    tool_node = SafeToolNode(_cached_tools)

    # ğŸ”§ SQL è´¨é‡æ£€æŸ¥èŠ‚ç‚¹ï¼ˆåœ¨å·¥å…·æ‰§è¡Œåæ£€æŸ¥å¹¶ä¿®å¤SQLï¼‰
    async def sql_quality_check_node(state: MessagesState):
        """
        SQL è´¨é‡æ£€æŸ¥èŠ‚ç‚¹ - åœ¨å·¥å…·æ‰§è¡Œåæ£€æŸ¥ SQL è´¨é‡

        åŠŸèƒ½ï¼š
        1. æ£€æµ‹å¹¶ä¿®å¤é‡å¤çš„ WHERE æ¡ä»¶
        2. è®°å½•è´¨é‡é—®é¢˜ä¾›åç»­åˆ†æ
        3. è¿”å›ä¿®å¤å»ºè®®ç»™ Agent
        """
        messages = state["messages"]
        last_message = messages[-1]

        # åªæ£€æŸ¥ ToolMessageï¼ˆå·¥å…·æ‰§è¡Œç»“æœï¼‰
        if not isinstance(last_message, ToolMessage):
            return {"messages": []}

        # è·å–åŸå§‹é—®é¢˜ï¼ˆç”¨äºä¸Šä¸‹æ–‡ï¼‰
        original_question = ""
        for msg in messages:
            if isinstance(msg, HumanMessage):
                original_question = msg.content
                break

        # æ£€æŸ¥æœ€è¿‘çš„ query å·¥å…·è°ƒç”¨
        for msg in reversed(messages):
            if isinstance(msg, AIMessage) and msg.tool_calls:
                for tc in msg.tool_calls:
                    if tc.get('name') == 'query':
                        original_sql = tc.get('args', {}).get('sql', '')

                        # æ‰§è¡Œ SQL è´¨é‡æ£€æŸ¥
                        fixed_sql, issues = SQLQualityOptimizer.detect_and_fix_duplicate_conditions(original_sql)

                        if issues:
                            # å‘ç°é—®é¢˜ï¼Œè¿”å›ä¿®å¤å»ºè®®
                            issue_summary = "\n".join(issues)
                            suggestion = f"""ğŸ”§ SQL è´¨é‡æ£€æŸ¥å‘ç°é—®é¢˜ï¼š

{issue_summary}

å»ºè®®ä¿®å¤åçš„ SQLï¼š
```sql
{fixed_sql}
```

è¯·ä½¿ç”¨ä¿®å¤åçš„ SQL é‡æ–°æŸ¥è¯¢ã€‚"""

                            print(f"ğŸ”§ [SQLè´¨é‡æ£€æŸ¥] æ£€æµ‹åˆ°é—®é¢˜å¹¶å·²ä¿®å¤")
                            for issue in issues:
                                print(f"  - {issue}")

                            # è¿”å›é”™è¯¯æ¶ˆæ¯ï¼Œè®© Agent çœ‹åˆ°å¹¶ä¿®æ­£
                            return {
                                "messages": [
                                    ToolMessage(
                                        content=suggestion,
                                        tool_call_id=tc.get('id', 'unknown')
                                    )
                                ]
                            }

        # æ²¡æœ‰å‘ç°é—®é¢˜ï¼Œç›´æ¥è¿”å›
        return {"messages": []}

    # ================================================================
    # ğŸ”§ æ–°å¢ï¼šä¼ä¸šçº§å¯ä¿¡æ™ºèƒ½æ•°æ®ä½“èŠ‚ç‚¹
    # ================================================================

    # åˆ›å»ºèŠ‚ç‚¹å®ä¾‹
    planning_node = create_planning_node(enable_logging=True, min_confidence=0.6)
    reflection_node = create_reflection_node(max_retries=3, enable_logging=True)
    clarification_node = create_clarification_node(confidence_threshold=0.6, enable_logging=True)

    # Planning èŠ‚ç‚¹åŒ…è£…
    async def planning_node_wrapper(state: MessagesState) -> Dict:
        """Planning èŠ‚ç‚¹åŒ…è£…å™¨"""
        return planning_node(state)

    # Reflection èŠ‚ç‚¹åŒ…è£…
    async def reflection_node_wrapper(state: MessagesState) -> Dict:
        """Reflection èŠ‚ç‚¹åŒ…è£…å™¨"""
        return reflection_node(state)

    # Clarification èŠ‚ç‚¹åŒ…è£…
    async def clarification_node_wrapper(state: MessagesState) -> Dict:
        """Clarification èŠ‚ç‚¹åŒ…è£…å™¨"""
        return clarification_node(state)

    # è·¯ç”±å‡½æ•°ï¼šå†³å®šæ˜¯å¦éœ€è¦æ¾„æ¸…
    def should_clarify(state: MessagesState) -> Literal["clarification", "agent"]:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦æ¾„æ¸…"""
        messages = state["messages"]

        # æ£€æŸ¥æ˜¯å¦æœ‰æ¾„æ¸…ç»“æœ
        for msg in reversed(messages):
            if isinstance(msg, AIMessage) and hasattr(msg, 'content'):
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ¾„æ¸…æ¶ˆæ¯
                if "éœ€è¦æ¾„æ¸…" in str(msg.content) or "ğŸ¤”" in str(msg.content):
                    return "clarification"

        # æ£€æŸ¥æ˜¯å¦æœ‰æ‰§è¡Œè®¡åˆ’ä¸­çš„ä½ç½®ä¿¡åº¦
        if "__execution_plan__" in state:
            plan = state["__execution_plan__"]
            if plan.get("confidence", 1.0) < 0.6:
                return "clarification"

        return "agent"

    # è·¯ç”±å‡½æ•°ï¼šå†³å®šæ˜¯å¦é‡è¯•
    def should_retry_after_reflection(state: MessagesState) -> Literal["agent", END]:
        """åæ€åå†³å®šæ˜¯å¦é‡è¯•æˆ–ç»§ç»­æ‰§è¡Œ"""
        messages = state["messages"]

        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦å·²ç»æ‰§è¡Œäº†SQLæŸ¥è¯¢
        has_query_result = False
        has_sql_data = False
        has_chart = False  # ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦å·²ç”Ÿæˆå›¾è¡¨

        for msg in reversed(messages):
            if isinstance(msg, ToolMessage):
                content = str(msg.content)
                # æ£€æŸ¥æ˜¯å¦æ˜¯SQLæŸ¥è¯¢è¿”å›çš„æ•°æ®ï¼ˆæœ‰åˆ—åå’Œè¡Œï¼‰
                if '"columns"' in content or '"rows"' in content:
                    has_sql_data = True
                    break
                # ğŸ”§ æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†å›¾è¡¨ï¼ˆimageç±»å‹å†…å®¹ï¼‰
                if isinstance(msg.content, list):
                    for item in msg.content:
                        if isinstance(item, dict) and item.get('type') == 'image':
                            has_chart = True
                            break
                elif 'image' in content.lower() or 'å›¾è¡¨å·²ç”Ÿæˆ' in content:
                    has_chart = True
                    break
                # æ£€æŸ¥æ˜¯å¦æ˜¯queryå·¥å…·çš„è°ƒç”¨
                for earlier_msg in messages:
                    if isinstance(earlier_msg, AIMessage) and earlier_msg.tool_calls:
                        for tc in earlier_msg.tool_calls:
                            if tc.get('name') == 'query':
                                has_query_result = True
                                break

        # æ£€æŸ¥åæ€ç»“æœ
        for msg in reversed(messages):
            if isinstance(msg, AIMessage):
                content = str(msg.content)
                # å¦‚æœæœ‰é”™è¯¯ä¸”é‡è¯•æ¬¡æ•°æœªè¶…é™
                if "ğŸ”„ æ‰§è¡Œå¤±è´¥" in content and "æ­£åœ¨é‡æ–°ç”ŸæˆæŸ¥è¯¢" in content:
                    retry_count = state.get("__retry_count__", 0)
                    if retry_count < 3:
                        return "agent"
                    return END

                if "âŒ æ£€æµ‹åˆ°é”™è¯¯" in content:
                    retry_count = state.get("__retry_count__", 0)
                    if retry_count < 3:
                        return "agent"
                    return END

                # å¦‚æœæ‰§è¡ŒæˆåŠŸä½†è¿˜æ²¡æœ‰SQLæ•°æ®ï¼Œç»§ç»­æ‰§è¡Œ
                if "âœ… æ‰§è¡ŒæˆåŠŸ" in content or "æŸ¥è¯¢å·²æˆåŠŸæ‰§è¡Œ" in content:
                    # ğŸ”§ æ£€æŸ¥åˆ†ææ˜¯å¦å®Œæ•´ï¼ˆè‡³å°‘100å­—ï¼‰
                    analysis_length = len(content)
                    if has_chart and analysis_length >= 100:
                        print(f"âœ… å·²ç”Ÿæˆå›¾è¡¨ä¸”åˆ†æå®Œæ•´({analysis_length}å­—)ï¼Œç»“æŸæ‰§è¡Œ")
                        return END
                    elif has_chart:
                        print(f"ğŸ”„ å·²ç”Ÿæˆå›¾è¡¨ä½†åˆ†æè¿‡çŸ­({analysis_length}å­—)ï¼Œç»§ç»­ç”Ÿæˆåˆ†æ...")
                        return "agent"
                    if not has_sql_data:
                        print("ğŸ”„ å·¥å…·æ‰§è¡ŒæˆåŠŸï¼Œä½†è¿˜æ²¡æœ‰SQLæŸ¥è¯¢ç»“æœï¼Œç»§ç»­æ‰§è¡Œ...")
                        return "agent"
                    # æœ‰SQLæ•°æ®äº†ï¼Œå¯ä»¥ç»“æŸ
                    print("âœ… å·²è·å–SQLæŸ¥è¯¢ç»“æœï¼Œç»“æŸæ‰§è¡Œ")
                    return END

        # å¦‚æœè¿˜æ²¡æœ‰SQLæ•°æ®ä¸”æ²¡æœ‰é”™è¯¯ï¼Œç»§ç»­æ‰§è¡Œ
        if not has_sql_data:
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•queryå·¥å…·è°ƒç”¨
            query_called = False
            for msg in messages:
                if isinstance(msg, AIMessage) and msg.tool_calls:
                    for tc in msg.tool_calls:
                        if tc.get('name') == 'query':
                            query_called = True
                            break

            if not query_called:
                print("ğŸ”„ è¿˜æ²¡æœ‰æ‰§è¡ŒSQLæŸ¥è¯¢ï¼Œç»§ç»­æ‰§è¡Œ...")
                return "agent"

        return END

    # æ„å»ºå›¾
    builder = StateGraph(MessagesState)

    # æ·»åŠ èŠ‚ç‚¹
    builder.add_node("agent", call_model)
    builder.add_node("tools", tool_node)
    builder.add_node("sql_quality_check", sql_quality_check_node)
    builder.add_node("planning", planning_node_wrapper)    # ğŸ”§ æ–°å¢ï¼šè®¡åˆ’èŠ‚ç‚¹
    builder.add_node("reflection", reflection_node_wrapper)  # ğŸ”§ æ–°å¢ï¼šåæ€èŠ‚ç‚¹
    builder.add_node("clarification", clarification_node_wrapper)  # ğŸ”§ æ–°å¢ï¼šæ¾„æ¸…èŠ‚ç‚¹

    # æ„å»ºè¾¹ï¼ˆæ–°çš„å·¥ä½œæµï¼‰
    # START â†’ planning â†’ [needs_clarification?] â†’ clarification â†’ agent â†’ tools â†’ reflection â†’ [should_retry?] â†’ agent/END
    builder.add_edge(START, "planning")
    builder.add_conditional_edges("planning", should_clarify)
    builder.add_edge("clarification", "agent")
    builder.add_conditional_edges("agent", should_continue)
    builder.add_edge("tools", "reflection")  # ğŸ”§ ä¿®æ”¹ï¼šå·¥å…·æ‰§è¡Œåè¿›å…¥åæ€èŠ‚ç‚¹
    builder.add_conditional_edges("reflection", should_retry_after_reflection)  # ğŸ”§ æ–°å¢ï¼šåæ€åè·¯ç”±
    builder.add_edge("sql_quality_check", END)  # ğŸ”§ ä¿®æ”¹ï¼šè´¨é‡æ£€æŸ¥åç»“æŸï¼ˆè¿›å…¥reflectionå¤„ç†ï¼‰

    # æŒä¹…åŒ– checkpointer
    _cached_checkpointer = MemorySaver()
    _cached_agent = builder.compile(checkpointer=_cached_checkpointer)

    print("âœ… Agent åˆå§‹åŒ–å®Œæˆï¼")
    print("ğŸ“‹ å·¥ä½œæµ: START â†’ planning â†’ clarification â†’ agent â†’ tools â†’ reflection â†’ agent/END")

    return _cached_agent, _cached_mcp_client


async def reset_agent():
    """é‡ç½® Agent ç¼“å­˜ï¼ˆç”¨äºé‡æ–°è¿æ¥æˆ–é…ç½®å˜æ›´ï¼‰"""
    global _cached_agent, _cached_mcp_client, _cached_tools, _cached_checkpointer, _cached_db_type

    # ğŸ”¥ å…³é—­ MCP å®¢æˆ·ç«¯è¿æ¥
    if _cached_mcp_client is not None:
        try:
            # å°è¯•å…³é—­ MCP å®¢æˆ·ç«¯
            if hasattr(_cached_mcp_client, 'close'):
                await _cached_mcp_client.close()
            elif hasattr(_cached_mcp_client, '__aenter__'):
                # å¦‚æœæ˜¯ async context managerï¼Œå°è¯•æ¸…ç†
                await _cached_mcp_client.__aexit__(None, None, None)
            print("ğŸ”„ MCP å®¢æˆ·ç«¯å·²å…³é—­")
        except Exception as e:
            print(f"âš ï¸ å…³é—­MCPå®¢æˆ·ç«¯æ—¶å‡ºé”™: {e}")

    _cached_agent = None
    _cached_mcp_client = None
    _cached_tools = None
    _cached_checkpointer = None
    _cached_db_type = "postgresql"  # é‡ç½®ä¸ºé»˜è®¤å€¼
    print("ğŸ”„ Agent ç¼“å­˜å·²é‡ç½®")


async def run_agent(question: str, thread_id: str = "1", verbose: bool = True, db_type: str = "postgresql") -> VisualizationResponse:
    """Run the SQL Agent with a question

    Args:
        question: ç”¨æˆ·é—®é¢˜
        thread_id: ä¼šè¯ID
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†è¿‡ç¨‹
        db_type: æ•°æ®åº“ç±»å‹ï¼ˆpostgresql, mysql, sqlite, xlsx, csvç­‰ï¼‰

    Returns:
        VisualizationResponse: ç»“æ„åŒ–çš„å¯è§†åŒ–å“åº”
    """
    # ğŸš€ ä½¿ç”¨æŒä¹…åŒ–çš„ Agentï¼ˆä¼ é€’ db_type å‚æ•°ï¼‰
    agent, mcp_client = await _get_or_create_agent(db_type=db_type)

    # Run the agent
    config_dict = {"configurable": {"thread_id": thread_id}}

    if verbose:
        print(f"\n{'='*60}")
        print(f"é—®é¢˜: {question}")
        print(f"{'='*60}\n")

    step_count = 0
    all_messages = []  # æ”¶é›†æ‰€æœ‰æ¶ˆæ¯
    final_content = ""

    # ä½¿ç”¨ stream_mode="updates" åªè·å–å¢é‡æ›´æ–°
    async for step in agent.astream(
        {"messages": [HumanMessage(content=question)]},
        config_dict,
        stream_mode="updates",
    ):
        step_count += 1

        if verbose:
            print(f"\n{'â”€'*60}")
            print(f"ï¿½ ç¬¬ {step_count} æ­¥")
            print(f"{'â”€'*60}")

        for node_name, node_output in step.items():
            if verbose:
                print(f"\nğŸ”¹ èŠ‚ç‚¹åç§°: {node_name}")

            if "messages" in node_output:
                messages = node_output["messages"]
                # ğŸ”§ å¤„ç† LangGraph Overwrite å¯¹è±¡å’Œ None å€¼
                if messages is not None:
                    if hasattr(messages, 'value'):
                        messages = messages.value
                    all_messages.extend(messages)  # æ”¶é›†æ¶ˆæ¯

                    for msg in messages:
                        if verbose:
                            print(f"  ğŸ“¨ æ¶ˆæ¯ç±»å‹: {type(msg).__name__}")

                        # æ ¹æ®æ¶ˆæ¯ç±»å‹å¤„ç†
                        if isinstance(msg, AIMessage):
                            if msg.content:
                                final_content = msg.content  # ä¿å­˜æœ€åçš„AIå›å¤
                                if verbose:
                                    preview = msg.content[:200] + ('...' if len(msg.content) > 200 else '')
                                    print(f"     ğŸ¤– AI: {preview}")
                            if msg.tool_calls and verbose:
                                for tc in msg.tool_calls:
                                    print(f"     ğŸ”§ è°ƒç”¨å·¥å…·: {tc['name']}")

                        elif isinstance(msg, ToolMessage) and verbose:
                            preview = str(msg.content)[:200] + ('...' if len(str(msg.content)) > 200 else '')
                            print(f"     ğŸ“¦ å·¥å…·è¿”å›: {preview}")

    # æ„å»ºå¯è§†åŒ–å“åº”ï¼ˆå¼‚æ­¥ï¼Œæ”¯æŒ mcp-echarts å›¾è¡¨ç”Ÿæˆï¼‰
    viz_response = await build_visualization_response(all_messages, final_content)
    
    if verbose:
        print(f"\n{'='*60}")
        print(f"âœ… å®Œæˆ! å…± {step_count} æ­¥")
        print(f"{'='*60}")
        
        # æ‰“å°ç»“æ„åŒ–æ•°æ®æ‘˜è¦
        print(f"\nğŸ“Š ç»“æ„åŒ–æ•°æ®æ‘˜è¦:")
        print(f"   - SQL: {viz_response.sql[:50]}..." if viz_response.sql else "   - SQL: æ— ")
        print(f"   - æ•°æ®è¡Œæ•°: {viz_response.data.row_count}")
        print(f"   - æ¨èå›¾è¡¨: {viz_response.chart.chart_type.value}")
        print(f"   - å›¾è¡¨æ ‡é¢˜: {viz_response.chart.title or 'æ— '}")
    
    return viz_response


# ===============================================
# ğŸ” å¸¦é”™è¯¯è¿½è¸ªçš„åŒ…è£…å‡½æ•°ï¼ˆè´¨é‡ä¿è¯ï¼‰
# ===============================================

async def run_agent_with_tracking(
    question: str,
    thread_id: str = "1",
    verbose: bool = True,
    db_type: str = "postgresql",
    context: Optional[Dict[str, Any]] = None
) -> VisualizationResponse:
    """
    å¸¦é”™è¯¯è¿½è¸ªçš„run_agentåŒ…è£…å‡½æ•°

    åœ¨åŸæœ‰run_agentåŸºç¡€ä¸Šæ·»åŠ ï¼š
    - æ€§èƒ½ç›‘æ§ï¼ˆæ‰§è¡Œæ—¶é—´ï¼‰
    - é”™è¯¯è‡ªåŠ¨è®°å½•å’Œåˆ†ç±»
    - æˆåŠŸç‡ç»Ÿè®¡
    - å¤±è´¥æ¡ˆä¾‹æ”¶é›†

    Args:
        question: ç”¨æˆ·é—®é¢˜
        thread_id: ä¼šè¯ID
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†è¿‡ç¨‹
        db_type: æ•°æ®åº“ç±»å‹
        context: é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆç”¨æˆ·IDã€ç§Ÿæˆ·IDç­‰ï¼‰

    Returns:
        VisualizationResponse: ä¸run_agentç›¸åŒçš„è¿”å›å€¼
    """
    import time

    if not ERROR_TRACKING_ENABLED:
        # å¦‚æœé”™è¯¯è¿½è¸ªæœªå¯ç”¨ï¼Œç›´æ¥è°ƒç”¨åŸå‡½æ•°
        return await run_agent(question, thread_id, verbose, db_type)

    start_time = time.time()
    response = None

    try:
        # è°ƒç”¨åŸå§‹run_agentå‡½æ•°
        response = await run_agent(question, thread_id, verbose, db_type)

        # è®°å½•æˆåŠŸ
        elapsed = time.time() - start_time
        error_tracker.log_success(
            question=question,
            response=response.answer[:500] if response.answer else "æ— å›å¤",
            context={
                **(context or {}),
                "thread_id": thread_id,
                "db_type": db_type,
                "sql": response.sql[:200] if response.sql else None,
                "chart_type": response.chart.chart_type.value if response.chart else None,
            },
            execution_time=elapsed
        )

        return response

    except Exception as e:
        # è®°å½•é”™è¯¯
        elapsed = time.time() - start_time

        # è‡ªåŠ¨æ¨æ–­é”™è¯¯ç±»åˆ«
        error_category = _categorize_error(e, question)

        log_agent_error(
            question=question,
            error=e,
            category=error_category,
            context={
                **(context or {}),
                "thread_id": thread_id,
                "db_type": db_type,
                "execution_time": elapsed,
            }
        )

        # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼ˆä¿æŒåŸæœ‰è¡Œä¸ºï¼‰
        raise


def _categorize_error(error: Exception, question: str) -> ErrorCategory:
    """
    æ ¹æ®é”™è¯¯ç±»å‹å’Œç”¨æˆ·é—®é¢˜è‡ªåŠ¨åˆ†ç±»é”™è¯¯

    Args:
        error: å¼‚å¸¸å¯¹è±¡
        question: ç”¨æˆ·é—®é¢˜

    Returns:
        ErrorCategory: é”™è¯¯ç±»åˆ«
    """
    error_str = str(error).lower()
    error_type = type(error).__name__

    # å±é™©æ“ä½œæ£€æµ‹
    dangerous_keywords = ["drop", "delete", "update", "insert", "truncate", "alter"]
    if any(kw in question.lower() for kw in dangerous_keywords):
        return ErrorCategory.DANGEROUS_OPERATION

    # SQLæ³¨å…¥å°è¯•
    if "injection" in error_str or "malicious" in error_str:
        return ErrorCategory.SQL_INJECTION_ATTEMPT

    # æ•°æ®åº“è¿æ¥é—®é¢˜
    if "connection" in error_str or "connect" in error_str or "timeout" in error_str:
        return ErrorCategory.DATABASE_CONNECTION

    # LLM APIé”™è¯¯
    if "api" in error_str or "openai" in error_str or "deepseek" in error_str:
        return ErrorCategory.LLM_API_ERROR

    # Schemaä¸å­˜åœ¨
    if "not found" in error_str or "does not exist" in error_str or "unknown" in error_str:
        return ErrorCategory.SCHEMA_NOT_FOUND

    # ç©ºç»“æœ
    if "empty" in error_str or "no data" in error_str or "no result" in error_str:
        return ErrorCategory.EMPTY_RESULT

    # æ•°æ®ç±»å‹ä¸åŒ¹é…
    if error_type in ["ValueError", "TypeError"] or "type" in error_str:
        return ErrorCategory.DATA_TYPE_MISMATCH

    # MCPå·¥å…·å¤±è´¥
    if "mcp" in error_str or "tool" in error_str:
        return ErrorCategory.MCP_TOOL_FAILURE

    # æ¨¡ç³Šé—®é¢˜
    if len(question.strip()) < 5:
        return ErrorCategory.AMBIGUOUS_QUERY

    # é»˜è®¤ä¸ºæœªçŸ¥é”™è¯¯
    return ErrorCategory.UNKNOWN


async def interactive_mode():
    """Run the agent in interactive mode"""
    print("\n" + "="*60)
    print("ğŸ¤– SQL Agent äº¤äº’æ¨¡å¼ï¼ˆå¯è§†åŒ–ç‰ˆï¼‰")
    print("="*60)
    print("å‘½ä»¤:")
    print("  exit/quit - é€€å‡ºç¨‹åº")
    print("  debug     - åˆ‡æ¢è°ƒè¯•æ¨¡å¼")
    print("  reset     - é‡ç½®è¿æ¥ï¼ˆå¦‚é‡è¿æ¥é—®é¢˜ï¼‰")
    print("="*60)
    print("\nğŸ’¡ æç¤º: é¦–æ¬¡æŸ¥è¯¢éœ€è¦åˆå§‹åŒ–è¿æ¥ï¼ˆçº¦5-10ç§’ï¼‰ï¼Œåç»­æŸ¥è¯¢å°†å¾ˆå¿«ï¼\n")

    thread_id = "interactive_session"
    verbose = False  # é»˜è®¤å…³é—­è¯¦ç»†è¾“å‡ºï¼Œåªæ˜¾ç¤ºæ¼‚äº®çš„å¯è§†åŒ–ç»“æœ

    while True:
        try:
            question = input("\nğŸ“ è¯·è¾“å…¥ä½ çš„é—®é¢˜: ").strip()

            if question.lower() in ["exit", "quit", "q"]:
                print("\nğŸ‘‹ å†è§!")
                break

            if question.lower() == "debug":
                verbose = not verbose
                print(f"\nğŸ”§ è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if verbose else 'å…³é—­'}")
                continue

            if question.lower() == "reset":
                await reset_agent()
                continue

            if not question:
                continue

            # è®¡æ—¶
            import time
            start_time = time.time()

            # è¿è¡ŒAgentå¹¶è·å–ç»“æ„åŒ–å“åº”
            viz_response = await run_agent(question, thread_id, verbose=verbose)

            # è®¡ç®—è€—æ—¶
            elapsed = time.time() - start_time

            # ä½¿ç”¨æ¼‚äº®çš„å¯è§†åŒ–æ¸²æŸ“
            if not verbose:  # éè°ƒè¯•æ¨¡å¼ä¸‹æ˜¾ç¤ºæ¼‚äº®è¾“å‡º
                render_response(viz_response)

            print(f"\nâ±ï¸  å“åº”æ—¶é—´: {elapsed:.2f} ç§’")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§!")
            break
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            print("ğŸ’¡ æç¤º: è¾“å…¥ 'reset' å¯é‡ç½®è¿æ¥")


if __name__ == "__main__":
    # Validate configuration
    config.validate_config()

    # Run interactive mode
    asyncio.run(interactive_mode())

